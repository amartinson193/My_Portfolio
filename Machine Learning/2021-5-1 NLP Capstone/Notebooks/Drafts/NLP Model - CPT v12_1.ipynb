{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "built-romance",
   "metadata": {},
   "source": [
    "# Changes from v11\n",
    "* Use UMLS to train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-alabama",
   "metadata": {},
   "source": [
    "\n",
    "# Import the MIMIC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dominant-smile",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amartins\\onedrive - intermountain healthcare\\python_pycharm_virt_env\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (4,5,7,11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "c:\\users\\amartins\\onedrive - intermountain healthcare\\python_pycharm_virt_env\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (4,5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "dataset_dictionary = {}\n",
    "\n",
    "for file_path in glob.glob('.\\\\Data\\\\MIMIC Files\\*'):\n",
    "    file_name = file_path.split('\\\\')[3].split('.')[0]\n",
    "    with gzip.open(file_path, mode='r') as file:\n",
    "        dataset_dictionary[file_name] = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-desert",
   "metadata": {},
   "source": [
    "# Join the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "grateful-tracker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset to join together -----\n",
    "\n",
    "# Create note_events table -----\n",
    "\n",
    "# Combine text for each subject and encounter\n",
    "note_events_base = dataset_dictionary['NOTEEVENTS'][dataset_dictionary['NOTEEVENTS'].loc[:,'CATEGORY'] == 'Discharge summary']\n",
    "note_events = note_events_base.groupby(['SUBJECT_ID', 'HADM_ID'], as_index=False)['TEXT'].agg(sum)\n",
    "\n",
    "# Create CPT table -----\n",
    "\n",
    "cpt_events_base = dataset_dictionary['CPTEVENTS']\n",
    "cpt_events_base = cpt_events_base[cpt_events_base['TICKET_ID_SEQ'] == 1]\n",
    "cpt_events_base = cpt_events_base.loc[:, ['SUBJECT_ID','HADM_ID', 'CPT_CD']]\n",
    "cpt_events = cpt_events_base.drop_duplicates()\n",
    "cpt_events\n",
    "\n",
    "# Join the datasets -----\n",
    "\n",
    "note_cpt = note_events.merge(cpt_events, on = ['SUBJECT_ID','HADM_ID'])\n",
    "# print(note_cpt.shape, note_events.shape, cpt_events.shape) # (223,150, 4) (52,726, 3) (227,510, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transparent-citation",
   "metadata": {},
   "source": [
    "# Filter the dataset to those CPT codes over 200 notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "laden-favor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "\n",
    "df = note_cpt['CPT_CD'].astype(str).value_counts()\n",
    "top_200 = list((df[df > 200]).index.values)\n",
    "note_cpt_200 = note_cpt[note_cpt['CPT_CD'].astype(str).isin(top_200)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-september",
   "metadata": {},
   "source": [
    "# Filter the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "unable-minimum",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amartins\\onedrive - intermountain healthcare\\python_pycharm_virt_env\\.venv\\lib\\site-packages\\pandas\\core\\indexing.py:1676: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def clean_data(text_series):\n",
    "    \n",
    "    # Replace \\n \n",
    "    text_series = text_series.str.replace('\\\\n',' ', regex=True)    \n",
    "\n",
    "    # Remove dates and locations\n",
    "    text_series = text_series.str.replace('\\[\\*\\*(.*?)\\*\\*\\]', ' ', regex=True)\n",
    "    \n",
    "    # Remove topics\n",
    "    data = text_series.str.split('([A-Z\\s]+:)')\n",
    "    for row_num, value in enumerate(data):\n",
    "        text_chunks = [x.strip().replace(':','').replace('\\n', '') for x in value]\n",
    "        for i, x in enumerate(text_chunks):\n",
    "            if 'MEDICATION' in x or 'SOCIAL HISTORY' in x or 'FAMILY HISTORY' in x:\n",
    "                text_chunks[i] = ' '\n",
    "                try:\n",
    "                    text_chunks[i + 1] = ' '\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "        text_series.iloc[row_num] = ' '.join(text_chunks)\n",
    "    \n",
    "    # Replace punctuation\n",
    "    text_series = text_series.str.replace('[' + string.punctuation + ']', ' ', regex=True)\n",
    "    \n",
    "    # Convert to lowercase \n",
    "    text_series = text_series.str.lower()\n",
    "    \n",
    "    # Remove all digits\n",
    "    text_series = text_series.str.replace('\\d',' ', regex=True)\n",
    "    \n",
    "    # Replace plurals, endings with ing, endings with ed, endings with ly\n",
    "#     text_series = text_series.str.replace('s(?=\\s)', ' ', regex=True)\n",
    "#     text_series = text_series.str.replace('ing(?=\\s)', ' ', regex=True)\n",
    "#     text_series = text_series.str.replace('ed(?=\\s)', ' ', regex=True)\n",
    "#     text_series = text_series.str.replace('ly(?=\\s)', ' ', regex=True)\n",
    "    \n",
    "    return text_series\n",
    "\n",
    "# Update Text Column\n",
    "\n",
    "note_cpt_200.loc[:, 'TEXT'] = clean_data(note_cpt_200['TEXT']).values\n",
    "\n",
    "# for i in Sample_Metamap.keys():\n",
    "#     Sample_Metamap[i]['TEXT'] = clean_data(Sample_Metamap[i]['TEXT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "suburban-release",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19935"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(note_cpt_200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-connecticut",
   "metadata": {},
   "source": [
    "# Loop through and Create Txt Files from Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "planned-omaha",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "note_cpt_200 = note_cpt_200.reset_index()\n",
    "for index in range(len(note_cpt_200)):\n",
    "    with open('CPT Text Files\\\\' + str(note_cpt_200.loc[index, 'CPT_CD']) + '_' + str(index) + '.txt', \"w\") as text_file:\n",
    "        text_file.write(note_cpt_200.loc[index, 'TEXT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ethical-alfred",
   "metadata": {},
   "source": [
    "# Import All the XMI Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-bronze",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "\n",
    "procedure_ls = []\n",
    "\n",
    "proc_regex = re.compile('(?<=\"T061\"\\spreferredText=\")[\\w+\\s,]*')\n",
    "\n",
    "for i in glob.glob('.\\\\*.xmi'):\n",
    "    with open(i) as file:\n",
    "        file_contents = file.read()\n",
    "        procedures = proc_regex.findall(file_contents)\n",
    "        procedure_ls.append(list(set(procedures)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-dealing",
   "metadata": {},
   "source": [
    "# Filter the data to CPT over 200 samples + Resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "pursuant-thumbnail",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99291    7860\n",
      "99223    2851\n",
      "99222    1736\n",
      "99254    1242\n",
      "99255     882\n",
      "         ... \n",
      "33542       1\n",
      "22630       1\n",
      "26418       1\n",
      "63103       1\n",
      "56620       1\n",
      "Name: CPT_CD, Length: 707, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Value Counts\n",
    "print(note_cpt['CPT_CD'].astype(str).value_counts())\n",
    "\n",
    "# Filter to CPT with over 200 notes\n",
    "df = note_cpt['CPT_CD'].astype(str).value_counts()\n",
    "top_200 = list((df[df > 200]).index.values)\n",
    "note_cpt_4 = note_cpt[note_cpt['CPT_CD'].astype(str).isin(top_200)]\n",
    "\n",
    "# Resample minority groups -----\n",
    "\n",
    "# Remove largest group\n",
    "top_200.remove('99291')\n",
    "'99291' in top_200\n",
    "\n",
    "minority_ls = top_200\n",
    "# minority_ls = ['99223','99222','99254']\n",
    "\n",
    "minority_df = []\n",
    "for i in minority_ls:\n",
    "    test_resampled = resample(note_cpt[note_cpt['CPT_CD'].astype(str) == i], replace=True, n_samples=7860, random_state=123)\n",
    "    minority_df.append(test_resampled)\n",
    "\n",
    "minority_df.append(note_cpt[note_cpt['CPT_CD'].astype(str) == '99291'])\n",
    "new_df = pd.concat(minority_df)\n",
    "\n",
    "new_df['CPT_CD'] = new_df['CPT_CD'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-steering",
   "metadata": {},
   "source": [
    "# Check for Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "altered-lucas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99252    7860\n",
       "33508    7860\n",
       "99222    7860\n",
       "99291    7860\n",
       "99253    7860\n",
       "99233    7860\n",
       "99254    7860\n",
       "99231    7860\n",
       "33405    7860\n",
       "99292    7860\n",
       "33533    7860\n",
       "99255    7860\n",
       "36556    7860\n",
       "99221    7860\n",
       "99232    7860\n",
       "99223    7860\n",
       "Name: CPT_CD, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.hist(note_cpt['CPT_CD'].astype(str))\n",
    "# plt.show()\n",
    "\n",
    "new_df['CPT_CD'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "deadly-southeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in Sample_Metamap.keys():\n",
    "    Sample_Metamap[i].to_csv(i + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-bracket",
   "metadata": {},
   "source": [
    "# Shuffle the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "surprised-jacob",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.sample(n = len(new_df), random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-devil",
   "metadata": {},
   "source": [
    "# Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "extensive-characterization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages -----\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "my_stop_words = list(set(stopwords.words('english'))) \\\n",
    "                + ['admission', 'date', 'sex'] \\\n",
    "                + ['needed', 'every', 'seen', 'weeks', 'please', 'ml', 'unit', 'small', 'year', 'old', 'cm', 'non', 'mm', 'however']\n",
    "                # Got the above from my top 100 most predictive words that I wanted to remove\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Split the data -----\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(z[z['CPT_CD'].astype(str).isin(['99221','36556', '99291'])][2].values, z[z['CPT_CD'].astype(str).isin(['99221','36556', '33518'])]['CPT_CD'].astype(str), test_size = .1, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-comment",
   "metadata": {},
   "source": [
    "# Tokenize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "determined-waters",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the data -----\n",
    "\n",
    "# Import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=my_stop_words)\n",
    "\n",
    "# Transform the training data\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-grenada",
   "metadata": {},
   "source": [
    "# Run Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "cultural-india",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Naive Bayes model -----\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "nb_classifier = MultinomialNB(alpha=.7)\n",
    "\n",
    "# Fit and check accuracy\n",
    "nb_classifier.fit(tfidf_train, y_train)\n",
    "pred = nb_classifier.predict(tfidf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colonial-geneva",
   "metadata": {},
   "source": [
    "# Looking at Feature Names and Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "decent-lotus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['citizenship',\n",
       " 'inutbag',\n",
       " 'reamin',\n",
       " 'taspe',\n",
       " 'traycan',\n",
       " 'eleveat',\n",
       " 'interscapular',\n",
       " 'stenossis',\n",
       " 'spp',\n",
       " 'tct',\n",
       " 'resectable',\n",
       " 'throacotomy',\n",
       " 'evisiting',\n",
       " 'nannulu',\n",
       " 'tplt',\n",
       " 'arthrotec',\n",
       " 'asberger',\n",
       " 'nnor',\n",
       " 'sttw',\n",
       " 'inconssitent',\n",
       " 'contemplate',\n",
       " 'whofelt',\n",
       " 'nreporttemporal',\n",
       " 'femaile',\n",
       " 'nbengay',\n",
       " 'synoviti',\n",
       " 'flie',\n",
       " 'controls',\n",
       " 'navalide',\n",
       " 'nlipomatosi',\n",
       " 'endeavour',\n",
       " 'tractor',\n",
       " 'expectorated',\n",
       " 'tegretal',\n",
       " 'nvalproate',\n",
       " 'walnut',\n",
       " 'ncarie',\n",
       " 'fulminan',\n",
       " 'nrole',\n",
       " 'shariro',\n",
       " 'duckbill',\n",
       " 'nviridan',\n",
       " 'supression',\n",
       " 'mwt',\n",
       " 'pseudobulbar',\n",
       " 'propecia',\n",
       " 'nqpm',\n",
       " 'kindey',\n",
       " 'narrowed',\n",
       " 'maex',\n",
       " 'inheritable',\n",
       " 'speculum',\n",
       " 'intracran',\n",
       " 'otsc',\n",
       " 'chornical',\n",
       " 'nvetriculography',\n",
       " 'nhycodan',\n",
       " 'abcces',\n",
       " 'hypotenion',\n",
       " 'blank',\n",
       " 'nfile',\n",
       " 'herniorrhaphie',\n",
       " 'nklonipin',\n",
       " 'ntelapivir',\n",
       " 'sfebrile',\n",
       " 'nafld',\n",
       " 'nkiss',\n",
       " 'falumouth',\n",
       " 'hematoemesi',\n",
       " 'wrote',\n",
       " 'nspecgr',\n",
       " 'npostoop',\n",
       " 'repond',\n",
       " 'nnwh',\n",
       " 'reliever',\n",
       " 'nresultant',\n",
       " 'nmeasures',\n",
       " 'digibind',\n",
       " 'nankles',\n",
       " 'nconclusive',\n",
       " 'fse',\n",
       " 'disinhibition',\n",
       " 'thoughts',\n",
       " 'grzymish',\n",
       " 'neoformans',\n",
       " 'profolol',\n",
       " 'bloodly',\n",
       " 'inspired',\n",
       " 'dialyze',\n",
       " 'ncontiguou',\n",
       " 'transspatial',\n",
       " 'nrestroom',\n",
       " 'ninstillation',\n",
       " 'nsatisfi',\n",
       " 'sudafed',\n",
       " 'residuals',\n",
       " 'du',\n",
       " 'ncandidacy',\n",
       " 'equine',\n",
       " 'diffcult',\n",
       " 'ntobb',\n",
       " 'nsork',\n",
       " 'slhazy',\n",
       " 'hyperdnamic',\n",
       " 'morphologies',\n",
       " 'nslept',\n",
       " 'nvano',\n",
       " 'nleni',\n",
       " 'fortaz',\n",
       " 'keratopathy',\n",
       " 'corgard',\n",
       " 'neosinophilia',\n",
       " 'tied',\n",
       " 'heliax',\n",
       " 'hypercaoguable',\n",
       " 'nlen',\n",
       " 'nenroll',\n",
       " 'perifissural',\n",
       " 'ninvestigate',\n",
       " 'entamoeba',\n",
       " 'catheterizes',\n",
       " 'category',\n",
       " 'nylon',\n",
       " 'rrecent',\n",
       " 'melitu',\n",
       " 'signifant',\n",
       " 'nentirely',\n",
       " 'ndribbl',\n",
       " 'nceftazidine',\n",
       " 'functioningn',\n",
       " 'pasado',\n",
       " 'portacath',\n",
       " 'periumbilically',\n",
       " 'nsterotatic',\n",
       " 'nyha',\n",
       " 'lcta',\n",
       " 'acclerat',\n",
       " 'midbody',\n",
       " 'cornea',\n",
       " 'nhomemaker',\n",
       " 'agencie',\n",
       " 'invaive',\n",
       " 'ncurrrent',\n",
       " 'donnatal',\n",
       " 'hydrosalpinx',\n",
       " 'ntrash',\n",
       " 'conceivable',\n",
       " 'reshoot',\n",
       " 'npubi',\n",
       " 'religion',\n",
       " 'esomeprazole',\n",
       " 'supranormal',\n",
       " 'amazing',\n",
       " 'nunchangedwith',\n",
       " 'electrocardiograms',\n",
       " 'palvix',\n",
       " 'angiom',\n",
       " 'concur',\n",
       " 'nhemetology',\n",
       " 'zocar',\n",
       " 'dph',\n",
       " 'ntachybrady',\n",
       " 'cannualt',\n",
       " 'fwb',\n",
       " 'nsentinel',\n",
       " 'ganglial',\n",
       " 'ndeliriou',\n",
       " 'pyruvate',\n",
       " 'dhft',\n",
       " 'methodone',\n",
       " 'nclarinex',\n",
       " 'upsiz',\n",
       " 'npharygeal',\n",
       " 'angiogaphy',\n",
       " 'preferrence',\n",
       " 'tgrip',\n",
       " 'seoncadry',\n",
       " 'qweekly',\n",
       " 'petroleum',\n",
       " 'evalaution',\n",
       " 'nsorbitol',\n",
       " 'berenstein',\n",
       " 'nosteopetrosis',\n",
       " 'chvostek',\n",
       " 'indurated',\n",
       " 'npulmonolgist',\n",
       " 'nstippl',\n",
       " 'ndevelp',\n",
       " 'isoniazid',\n",
       " 'booking',\n",
       " 'npsychiarty',\n",
       " 'dstopp',\n",
       " 'nerod',\n",
       " 'ankylosi',\n",
       " 'reanastamosi',\n",
       " 'nmacrosteatosi',\n",
       " 'nax',\n",
       " 'stabhle',\n",
       " 'noveruse',\n",
       " 'riverwalk',\n",
       " 'sarafem',\n",
       " 'gangia',\n",
       " 'idio',\n",
       " 'resistence',\n",
       " 'anonymous',\n",
       " 'beers',\n",
       " 'nvegitation',\n",
       " 'definate',\n",
       " 'agencies',\n",
       " 'nick',\n",
       " 'elemental',\n",
       " 'ages',\n",
       " 'furosamide',\n",
       " 'snap',\n",
       " 'dps',\n",
       " 'nguaifenisin',\n",
       " 'xerofoam',\n",
       " 'amongst',\n",
       " 'nmonocryl',\n",
       " 'npreventative',\n",
       " 'nencephalopathie',\n",
       " 'nprovocation',\n",
       " 'nchoos',\n",
       " 'advsi',\n",
       " 'talonavicular',\n",
       " 'nhyperchloremic',\n",
       " 'budjet',\n",
       " 'intervascular',\n",
       " 'qntbiotic',\n",
       " 'smal',\n",
       " 'neigbor',\n",
       " 'preferred',\n",
       " 'caco',\n",
       " 'dyasrthia',\n",
       " 'nargon',\n",
       " 'differentiated',\n",
       " 'nslower',\n",
       " 'podrome',\n",
       " 'ntheatre',\n",
       " 'anesthia',\n",
       " 'ncarcinamotosi',\n",
       " 'tinpatient',\n",
       " 'sensaory',\n",
       " 'parnechymal',\n",
       " 'vacuolat',\n",
       " 'npneumo',\n",
       " 'peerla',\n",
       " 'atraumatice',\n",
       " 'cleard',\n",
       " 'woozy',\n",
       " 'nparaumbilical',\n",
       " 'tnot',\n",
       " 'erh',\n",
       " 'lexa',\n",
       " 'onychocryptosis',\n",
       " 'nhypertropy',\n",
       " 'distl',\n",
       " 'nmoniter',\n",
       " 'nuncu',\n",
       " 'nbreakpoints',\n",
       " 'remin',\n",
       " 'nmgmt',\n",
       " 'nleukostasi',\n",
       " 'paraverterbral',\n",
       " 'dicus',\n",
       " 'nupholsterer',\n",
       " 'namerican',\n",
       " 'nregime',\n",
       " 'crotch',\n",
       " 'acidez',\n",
       " 'kristalose',\n",
       " 'nbreathsound',\n",
       " 'supplies',\n",
       " 'metatarsu',\n",
       " 'pencil',\n",
       " 'naxilla',\n",
       " 'expanding',\n",
       " 'meatbolic',\n",
       " 'faithfully',\n",
       " 'nrvr',\n",
       " 'pneumatocele',\n",
       " 'abj',\n",
       " 'sterotactic',\n",
       " 'easlier',\n",
       " 'ntoco',\n",
       " 'thryoid',\n",
       " 'vasculitis',\n",
       " 'nmut',\n",
       " 'hyperchlesterolemia',\n",
       " 'reinsertion',\n",
       " 'nablify',\n",
       " 'scistosomiasi',\n",
       " 'occupant',\n",
       " 'meropenam',\n",
       " 'nglucometer',\n",
       " 'naura',\n",
       " 'forewarm',\n",
       " 'engine',\n",
       " 'nregiment',\n",
       " 'concenr',\n",
       " 'underwnet',\n",
       " 'octrotide',\n",
       " 'bilatereal',\n",
       " 'nglomerulosclerosis',\n",
       " 'monitorr',\n",
       " 'pencillin',\n",
       " 'nfxn',\n",
       " 'fremitu',\n",
       " 'nroxanol',\n",
       " 'nhemosiderosi',\n",
       " 'nallopruinol',\n",
       " 'npsychological',\n",
       " 'nzn',\n",
       " 'flaky',\n",
       " 'uhold',\n",
       " 'nextremety',\n",
       " 'interoperative',\n",
       " 'nindirect',\n",
       " 'nindbili',\n",
       " 'nangiomata',\n",
       " 'nmeniscal',\n",
       " 'retart',\n",
       " 'ncolonoscopie',\n",
       " 'prominant',\n",
       " 'insufficeny',\n",
       " 'esto',\n",
       " 'interdisciplinary',\n",
       " 'pairs',\n",
       " 'anerobic',\n",
       " 'mvrepair',\n",
       " 'menigioma',\n",
       " 'ncasperfungin',\n",
       " 'duret',\n",
       " 'nmultiloculat',\n",
       " 'mcgiv',\n",
       " 'nmicrobial',\n",
       " 'nantidepressant',\n",
       " 'nrcc',\n",
       " 'nbmt',\n",
       " 'appoitnement',\n",
       " 'metop',\n",
       " 'overeat',\n",
       " 'ntimeframe',\n",
       " 'primaquine',\n",
       " 'kidd',\n",
       " 'ehrlichieae',\n",
       " 'nhamburger',\n",
       " 'jersey',\n",
       " 'distractibility',\n",
       " 'downgrade',\n",
       " 'scoped',\n",
       " 'visualis',\n",
       " 'pressurew',\n",
       " 'satu',\n",
       " 'flushes',\n",
       " 'nthumbnail',\n",
       " 'lithotrpsie',\n",
       " 'bpbpr',\n",
       " 'novacaine',\n",
       " 'carvidopa',\n",
       " 'ncervicomedullary',\n",
       " 'nfractures',\n",
       " 'nadduction',\n",
       " 'iavp',\n",
       " 'nlovsatstain',\n",
       " 'assumed',\n",
       " 'nbandages',\n",
       " 'nacquisition',\n",
       " 'options',\n",
       " 'nfl',\n",
       " 'ocugh',\n",
       " 'nbell',\n",
       " 'discharges',\n",
       " 'breakfasst',\n",
       " 'kayexolate',\n",
       " 'coaptation',\n",
       " 'partical',\n",
       " 'perphenazine',\n",
       " 'tbr',\n",
       " 'ndysphasia',\n",
       " 'pavix',\n",
       " 'nventolin',\n",
       " 'shocks',\n",
       " 'cariomyopathy',\n",
       " 'dh',\n",
       " 'naortoenteric',\n",
       " 'rubbing',\n",
       " 'ndorsiflexor',\n",
       " 'contraindicated',\n",
       " 'nmyopathy',\n",
       " 'demarginalization',\n",
       " 'anagrelide',\n",
       " 'nerrors',\n",
       " 'olopatadine',\n",
       " 'phyiology',\n",
       " 'subarchnoid',\n",
       " 'nlessen',\n",
       " 'coaxial',\n",
       " 'ginger',\n",
       " 'extemitie',\n",
       " 'termninal',\n",
       " 'addend',\n",
       " 'ncrest',\n",
       " 'ngravid',\n",
       " 'enrolled',\n",
       " 'residence',\n",
       " 'neurooncologist',\n",
       " 'hyalin',\n",
       " 'binding',\n",
       " 'hepatocytes',\n",
       " 'acure',\n",
       " 'nmetatsarsal',\n",
       " 'nverifi',\n",
       " 'gte',\n",
       " 'sctarche',\n",
       " 'nrobust',\n",
       " 'ncatapre',\n",
       " 'craniotomies',\n",
       " 'nadanc',\n",
       " 'exotic',\n",
       " 'nfindid',\n",
       " 'nreanast',\n",
       " 'pnx',\n",
       " 'sandwiche',\n",
       " 'insidiou',\n",
       " 'azathiorpine',\n",
       " 'nhtxn',\n",
       " 'pathogenic',\n",
       " 'nleukoencephalopathy',\n",
       " 'striated',\n",
       " 'npreponderance',\n",
       " 'mobiltiy',\n",
       " 'attendings',\n",
       " 'maxide',\n",
       " 'nvegetative',\n",
       " 'tendinitis',\n",
       " 'leukocytoclastic',\n",
       " 'florastore',\n",
       " 'woundvac',\n",
       " 'anneurysm',\n",
       " 'debalk',\n",
       " 'stenet',\n",
       " 'folds',\n",
       " 'cdc',\n",
       " 'nconfident',\n",
       " 'pharyngiti',\n",
       " 'hypoperfus',\n",
       " 'conjugat',\n",
       " 'flows',\n",
       " 'meninge',\n",
       " 'nhepatopathy',\n",
       " 'intraventicular',\n",
       " 'enxyme',\n",
       " 'nreminiscent',\n",
       " 'vanv',\n",
       " 'nsnor',\n",
       " 'obta',\n",
       " 'notd',\n",
       " 'spare',\n",
       " 'autodirues',\n",
       " 'fusions',\n",
       " 'bosniak',\n",
       " 'nneomycin',\n",
       " 'pancreaiti',\n",
       " 'tquiet',\n",
       " 'arttery',\n",
       " 'nfremitu',\n",
       " 'nspell',\n",
       " 'paroxitene',\n",
       " 'nvault',\n",
       " 'elastase',\n",
       " 'ncyclophosphamide',\n",
       " 'sorethroat',\n",
       " 'nalphagin',\n",
       " 'midlung',\n",
       " 'resuming',\n",
       " 'transbroncheal',\n",
       " 'noccational',\n",
       " 'embolized',\n",
       " 'perisurgical',\n",
       " 'nlaparoscopy',\n",
       " 'coolness',\n",
       " 'ninstance',\n",
       " 'nwallet',\n",
       " 'diphragmatic',\n",
       " 'ambulated',\n",
       " 'nnorpace',\n",
       " 'nhypercapneic',\n",
       " 'nbovine',\n",
       " 'cefzil',\n",
       " 'flexed',\n",
       " 'atrail',\n",
       " 'temporoparieto',\n",
       " 'nsulfamethoxazole',\n",
       " 'restraine',\n",
       " 'tfick',\n",
       " 'epilepitform',\n",
       " 'gingko',\n",
       " 'prrl',\n",
       " 'nrecogniz',\n",
       " 'xweek',\n",
       " 'nadjunctive',\n",
       " 'profusion',\n",
       " 'possilbe',\n",
       " 'snore',\n",
       " 'extraventricular',\n",
       " 'whereupon',\n",
       " 'nestimate',\n",
       " 'fumigatus',\n",
       " 'originates',\n",
       " 'nshorten',\n",
       " 'nnonexertional',\n",
       " 'dyskinesia',\n",
       " 'nrasagaline',\n",
       " 'ncardiologust',\n",
       " 'substitution',\n",
       " 'compaint',\n",
       " 'tgc',\n",
       " 'gible',\n",
       " 'ntoal',\n",
       " 'anticoagulatn',\n",
       " 'pseudocapsule',\n",
       " 'nsse',\n",
       " 'acidic',\n",
       " 'patriot',\n",
       " 'ntherapuetic',\n",
       " 'leaking',\n",
       " 'abullic',\n",
       " 'miotic',\n",
       " 'nmulitple',\n",
       " 'lymphandopathy',\n",
       " 'ncauduet',\n",
       " 'nnafld',\n",
       " 'disruptive',\n",
       " 'nsib',\n",
       " 'anagiography',\n",
       " 'nasoenteric',\n",
       " 'radiocarpal',\n",
       " 'cardiolo',\n",
       " 'ventillation',\n",
       " 'interstial',\n",
       " 'ribaviron',\n",
       " 'nquinapril',\n",
       " 'ndysconjugate',\n",
       " 'attractive',\n",
       " 'nmohter',\n",
       " 'casofungin',\n",
       " 'nacetabula',\n",
       " 'streaky',\n",
       " 'doxyclycline',\n",
       " 'shakes',\n",
       " 'npresumtive',\n",
       " 'nusing',\n",
       " 'hemangiomatosi',\n",
       " 'macrophag',\n",
       " 'hospitilization',\n",
       " 'leptomeningiti',\n",
       " 'ospital',\n",
       " 'jiroveci',\n",
       " 'episoe',\n",
       " 'esophagectomy',\n",
       " 'identif',\n",
       " 'nsacrospinou',\n",
       " 'minitran',\n",
       " 'blushe',\n",
       " 'cytopenias',\n",
       " 'testicles',\n",
       " 'nmethylene',\n",
       " 'sundowning',\n",
       " 'decubitus',\n",
       " 'stc',\n",
       " 'nheterogenic',\n",
       " 'vagotomy',\n",
       " 'silicon',\n",
       " 'ndecubiti',\n",
       " 'nvisib',\n",
       " 'ngyburide',\n",
       " 'nsymptoms',\n",
       " 'hematobillia',\n",
       " 'ncgy',\n",
       " 'tulip',\n",
       " 'thrombogenic',\n",
       " 'unresponsibe',\n",
       " 'ausculation',\n",
       " 'rosc',\n",
       " 'hemotology',\n",
       " 'npresuure',\n",
       " 'noophorectomy',\n",
       " 'nicoderm',\n",
       " 'ndysplastic',\n",
       " 'gastrointesinal',\n",
       " 'dificult',\n",
       " 'bicapp',\n",
       " 'transeferd',\n",
       " 'tightly',\n",
       " 'nzesteretic',\n",
       " 'transbronchial',\n",
       " 'intr',\n",
       " 'npinch',\n",
       " 'nsuprapancreatic',\n",
       " 'vasculitide',\n",
       " 'nleiomyoma',\n",
       " 'hypogastrum',\n",
       " 'nmetaphysi',\n",
       " 'indurat',\n",
       " 'confinement',\n",
       " 'nwwp',\n",
       " 'nperle',\n",
       " 'attentuation',\n",
       " 'nchantil',\n",
       " 'hammock',\n",
       " 'poc',\n",
       " 'thrombosu',\n",
       " 'schizaffcetive',\n",
       " 'pseudoaa',\n",
       " 'akpop',\n",
       " 'tenacious',\n",
       " 'nstrictur',\n",
       " 'antiocagulation',\n",
       " 'nsobriety',\n",
       " 'spoon',\n",
       " 'alveoli',\n",
       " 'gsw',\n",
       " 'sido',\n",
       " 'choledocholiathiasis',\n",
       " 'nbreakup',\n",
       " 'tion',\n",
       " 'rape',\n",
       " 'surestep',\n",
       " 'ncarri',\n",
       " 'tih',\n",
       " 'exposing',\n",
       " 'calluse',\n",
       " 'interactine',\n",
       " 'ngranulocytic',\n",
       " 'avonex',\n",
       " 'keen',\n",
       " 'nroofer',\n",
       " 'npericolic',\n",
       " 'survery',\n",
       " 'dissapear',\n",
       " 'duty',\n",
       " 'nversion',\n",
       " 'noccassional',\n",
       " 'rmg',\n",
       " 'pneumovac',\n",
       " 'atacand',\n",
       " 'erratic',\n",
       " 'nephrostomie',\n",
       " 'thymus',\n",
       " 'crohns',\n",
       " 'nbronchioliti',\n",
       " 'chm',\n",
       " 'profilnine',\n",
       " 'nther',\n",
       " 'diruesis',\n",
       " 'nervosa',\n",
       " 'amterior',\n",
       " 'ntapazole',\n",
       " 'yor',\n",
       " 'colonsocopy',\n",
       " 'busulfan',\n",
       " 'ndialysate',\n",
       " 'supervene',\n",
       " 'aerosolized',\n",
       " 'arachnoiditi',\n",
       " 'lense',\n",
       " 'pindolol',\n",
       " 'nredundancy',\n",
       " 'weds',\n",
       " 'eustachian',\n",
       " 'eucerin',\n",
       " 'improvemetn',\n",
       " 'ronchorou',\n",
       " 'leuko',\n",
       " 'extertion',\n",
       " 'npateint',\n",
       " 'ndetoxification',\n",
       " 'cranially',\n",
       " 'tranfusion',\n",
       " 'ndevelopp',\n",
       " 'eoemi',\n",
       " 'subaxial',\n",
       " 'nmatche',\n",
       " 'cuasing',\n",
       " 'absorbtion',\n",
       " 'samarium',\n",
       " 'nibs',\n",
       " 'gentlamen',\n",
       " 'stared',\n",
       " 'nferrex',\n",
       " 'nrecentcypher',\n",
       " 'cou',\n",
       " 'sperm',\n",
       " 'nmalignancie',\n",
       " 'nmeropenum',\n",
       " 'nantecubital',\n",
       " 'feldburg',\n",
       " 'percentile',\n",
       " 'nifn',\n",
       " 'nsinusitis',\n",
       " 'sevice',\n",
       " 'nvertebrobasilar',\n",
       " 'experiences',\n",
       " 'confabulation',\n",
       " 'protuberance',\n",
       " 'ls',\n",
       " 'nneulasta',\n",
       " 'thush',\n",
       " 'stunned',\n",
       " 'glascow',\n",
       " 'demosntrat',\n",
       " 'npeerl',\n",
       " 'thyroglobulin',\n",
       " 'ngroom',\n",
       " 'gprs',\n",
       " 'actres',\n",
       " 'renall',\n",
       " 'hematemsi',\n",
       " 'pavilion',\n",
       " 'peaking',\n",
       " 'osmostat',\n",
       " 'armpit',\n",
       " 'mandatory',\n",
       " 'words',\n",
       " 'sulcralfate',\n",
       " 'artee',\n",
       " 'lligation',\n",
       " 'nalufosin',\n",
       " 'nfeversv',\n",
       " 'perforate',\n",
       " 'branched',\n",
       " 'nnonemergent',\n",
       " 'excell',\n",
       " 'utt',\n",
       " 'downgrad',\n",
       " 'nplacment',\n",
       " 'preciptins',\n",
       " 'nmath',\n",
       " 'reticulation',\n",
       " 'bingo',\n",
       " 'tol',\n",
       " 'nperibronchovascular',\n",
       " 'adluscent',\n",
       " 'swisha',\n",
       " 'nperclose',\n",
       " 'nonreative',\n",
       " 'npseudomonal',\n",
       " 'bv',\n",
       " 'nthiazides',\n",
       " 'ndishwasher',\n",
       " 'seratonergic',\n",
       " 'posi',\n",
       " 'npainles',\n",
       " 'rechecked',\n",
       " 'suppressive',\n",
       " 'lisionpril',\n",
       " 'wnc',\n",
       " 'intially',\n",
       " 'nfight',\n",
       " 'regenerat',\n",
       " 'nzenker',\n",
       " 'nglomeruli',\n",
       " 'trbc',\n",
       " 'nmaintainance',\n",
       " 'nrectu',\n",
       " 'corticated',\n",
       " 'nspondylophyte',\n",
       " 'tfluid',\n",
       " 'nrelaxant',\n",
       " 'prh',\n",
       " 'lightened',\n",
       " 'ndilaysi',\n",
       " 'marijuan',\n",
       " 'tryptase',\n",
       " 'nhemodynamics',\n",
       " 'procaine',\n",
       " 'vascularized',\n",
       " 'cellept',\n",
       " 'augmantin',\n",
       " 'ophth',\n",
       " 'janumet',\n",
       " 'rechallenge',\n",
       " 'nsepta',\n",
       " 'hairpin',\n",
       " 'laotian',\n",
       " 'chronotropy',\n",
       " 'tths',\n",
       " 'lingual',\n",
       " 'ndroplet',\n",
       " 'nnotdone',\n",
       " 'noncalcified',\n",
       " 'lscta',\n",
       " 'aps',\n",
       " 'superintedant',\n",
       " 'undercooked',\n",
       " 'dily',\n",
       " 'nnod',\n",
       " 'abstience',\n",
       " 'nseventy',\n",
       " 'regulate',\n",
       " 'lobotomy',\n",
       " 'ndt',\n",
       " 'comprised',\n",
       " 'amino',\n",
       " 'ntransfalcine',\n",
       " 'democracy',\n",
       " 'ivac',\n",
       " 'ndizzynes',\n",
       " 'decleration',\n",
       " 'nmol',\n",
       " 'ntoes',\n",
       " 'temporize',\n",
       " 'sacroliiti',\n",
       " 'noverhydration',\n",
       " 'erythropoiesis',\n",
       " 'rcm',\n",
       " 'collagen',\n",
       " 'gii',\n",
       " 'nhypertriglyceridemia',\n",
       " 'nnitrostat',\n",
       " 'psap',\n",
       " 'deeply',\n",
       " 'appos',\n",
       " 'abdomninal',\n",
       " 'nbracelet',\n",
       " 'hyperproteinemia',\n",
       " 'nbank',\n",
       " 'nunpleasant',\n",
       " 'errla',\n",
       " 'hyperlipdemia',\n",
       " 'nfought',\n",
       " 'pincare',\n",
       " 'subsalicy',\n",
       " 'admssion',\n",
       " 'fk',\n",
       " 'classifier',\n",
       " 'petoxiphylline',\n",
       " 'eneter',\n",
       " 'nrsca',\n",
       " 'upslop',\n",
       " 'intermuscular',\n",
       " 'nindpendent',\n",
       " 'seconary',\n",
       " 'ndeform',\n",
       " 'reveiw',\n",
       " 'filgastrim',\n",
       " 'nephrotoxicity',\n",
       " 'acidose',\n",
       " 'nhaptoglob',\n",
       " 'mpcwp',\n",
       " 'ntriglycer',\n",
       " 'oreient',\n",
       " 'talar',\n",
       " 'tiban',\n",
       " 'endemic',\n",
       " 'nhamartoma',\n",
       " 'remedicine',\n",
       " 'ndiscretion',\n",
       " 'nifediac',\n",
       " 'exerted',\n",
       " 'intermedia',\n",
       " 'tcd',\n",
       " 'fdi',\n",
       " 'nauseau',\n",
       " 'understands',\n",
       " 'diliatem',\n",
       " 'fuel',\n",
       " 'negx',\n",
       " 'nshigella',\n",
       " 'tnad',\n",
       " 'cleaning',\n",
       " 'customer',\n",
       " 'ncrisp',\n",
       " 'nsixth',\n",
       " 'ncholecystecomy',\n",
       " 'npeforat',\n",
       " 'partime',\n",
       " 'gridiron',\n",
       " 'gastointestinal',\n",
       " 'nregret',\n",
       " 'opthamology',\n",
       " 'midol',\n",
       " 'cramping',\n",
       " 'subhepatic',\n",
       " 'phencyclidine',\n",
       " 'perpheral',\n",
       " 'referal',\n",
       " 'vaccinated',\n",
       " 'ngrunt',\n",
       " 'asvd',\n",
       " 'outpouching',\n",
       " 'intracondylar',\n",
       " 'untoward',\n",
       " 'nsmallest',\n",
       " 'malleate',\n",
       " 'negativ',\n",
       " 'nanticoagulaiton',\n",
       " 'parecentesi',\n",
       " 'npreferr',\n",
       " 'njejunostomy',\n",
       " 'spam',\n",
       " 'tempature',\n",
       " 'bivalirudin',\n",
       " 'drianage',\n",
       " 'npushbutton',\n",
       " 'ncefotetan',\n",
       " 'nsubcorneal',\n",
       " 'scx',\n",
       " 'parece',\n",
       " 'nbillroth',\n",
       " 'nabrasive',\n",
       " 'labe',\n",
       " 'compartement',\n",
       " 'nsphincterotomize',\n",
       " 'corporate',\n",
       " 'professional',\n",
       " 'nbecoming',\n",
       " 'nangigoraphical',\n",
       " 'usu',\n",
       " 'hypercoag',\n",
       " 'hrct',\n",
       " 'nbulge',\n",
       " 'diastoic',\n",
       " 'tcp',\n",
       " 'deambulate',\n",
       " 'eunatremic',\n",
       " 'golytely',\n",
       " 'heimlich',\n",
       " 'sohendra',\n",
       " 'nthreat',\n",
       " 'pradaxa',\n",
       " 'auricular',\n",
       " 'nwan',\n",
       " 'nprofunda',\n",
       " 'roast',\n",
       " 'fluorescence',\n",
       " 'zoysn',\n",
       " 'admin',\n",
       " 'chilled',\n",
       " 'ndevot',\n",
       " 'oligouria',\n",
       " 'yf',\n",
       " 'nfibroproliferative',\n",
       " 'nassocaiat',\n",
       " 'worried',\n",
       " 'folfiri',\n",
       " 'hind',\n",
       " 'regularity',\n",
       " 'nanteriorly',\n",
       " 'elongated',\n",
       " 'imipenan',\n",
       " 'phsyician',\n",
       " 'nthrombophlebitis',\n",
       " 'nhypoechogenicity',\n",
       " 'therpay',\n",
       " 'nhuge',\n",
       " 'palms',\n",
       " 'multile',\n",
       " 'nheadahce',\n",
       " 'nqfri',\n",
       " 'bood',\n",
       " 'interfere',\n",
       " 'nautoregulation',\n",
       " 'ndebri',\n",
       " 'headedness',\n",
       " 'colapse',\n",
       " 'nvodka',\n",
       " 'topogram',\n",
       " 'inflatable',\n",
       " 'vsurg',\n",
       " 'hypercapneic',\n",
       " 'patientwould',\n",
       " 'nmenopausal',\n",
       " 'nrad',\n",
       " 'npasse',\n",
       " 'qmowefr',\n",
       " 'rehabe',\n",
       " 'supports',\n",
       " 'ndisk',\n",
       " 'cochlear',\n",
       " 'neastern',\n",
       " 'copay',\n",
       " 'treate',\n",
       " 'nbacteremic',\n",
       " 'tnarcotic',\n",
       " 'triamtrine',\n",
       " 'aneurysem',\n",
       " 'gammma',\n",
       " 'transmittyed',\n",
       " 'fork',\n",
       " 'nsalpingectomy',\n",
       " 'nmsm',\n",
       " 'durign',\n",
       " 'ndiscernable',\n",
       " 'nanticoaqgulationi',\n",
       " 'hypotenstion',\n",
       " 'oculi',\n",
       " 'nsimplify',\n",
       " 'unlcear',\n",
       " ...]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notes\n",
    "# sum([np.exp(1)** x for x in nb_classifier.coef_[0]]) # The probability of all the words equals one\n",
    "# # Taken from here: * https://stackoverflow.com/questions/61586946/how-to-calculate-feature-log-prob-in-the-naive-bayes-multinomialnb\n",
    "\n",
    "# ------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_feature_rank(tfidf_vectorizer, y_no, nb_classifier):\n",
    "    \n",
    "    # Get the feature names\n",
    "    feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "    # Zip together the first CPT weights with feature names\n",
    "    feat_with_weights =  sorted(zip(nb_classifier.coef_[y_no], feature_names))\n",
    "    \n",
    "    # Print words most responsible for the prediction\n",
    "#     print('Top 100 \\n\\n\\n\\n')\n",
    "#     top_100_ls = []\n",
    "    for i in range(100):\n",
    "        x = feat_with_weights[-i-1]\n",
    "#         top_100_ls.append(x[1])\n",
    "#         print(nb_classifier.classes_[y_no], i, round((np.exp(1) ** x[0]),4), x[1])\n",
    "\n",
    "#     print('\\n\\n\\n\\n Bottom 100 \\n\\n\\n\\n')\n",
    "    for i in range(100):\n",
    "        x = feat_with_weights[i]\n",
    "#         print(nb_classifier.classes_[y_no], i, round((np.exp(1) ** x[0]),4), x[1])\n",
    "    \n",
    "#     min_weight = min([i[0] for i in feat_with_weights])\n",
    "    \n",
    "    x = [i[0] for i in feat_with_weights]\n",
    "    \n",
    "    median_pred = np.median(x)\n",
    "          \n",
    "    return [i[1] for i in feat_with_weights if i[0] <= median_pred] # Minimum weight words\n",
    "#     return top_100_ls\n",
    "\n",
    "# Find the least predictive words\n",
    "def least_pred_words(nb_classifier, tfidf_vectorizer):\n",
    "    low_wt_stop_ls = []\n",
    "\n",
    "    for i in range(len(nb_classifier.classes_)):\n",
    "        low_wt_stop_ls += get_feature_rank(tfidf_vectorizer, i, nb_classifier)\n",
    "\n",
    "    low_wt_stop_ls = list(set(low_wt_stop_ls))\n",
    "    return low_wt_stop_ls\n",
    "    \n",
    "low_wt_stop_ls = least_pred_words(nb_classifier, tfidf_vectorizer)\n",
    "\n",
    "# Find top 100 words - doesn't seem to improve the model\n",
    "def highest_pred_words(nb_classifier, tfidf_vectorizer):\n",
    "    top_100_ls = []\n",
    "    for i in range(len(nb_classifier.classes_)):\n",
    "        top_100_ls += get_feature_rank(tfidf_vectorizer, i, nb_classifier)\n",
    "\n",
    "    top_100_ls = list(set(top_100_ls))\n",
    "    return top_100_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-kenya",
   "metadata": {},
   "source": [
    "# Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "optimum-turkish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 2, does not match size of target_names, 3. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-368-713b4419513d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mclass_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnb_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Training'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\amartins\\onedrive - intermountain healthcare\\python_pycharm_virt_env\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\amartins\\onedrive - intermountain healthcare\\python_pycharm_virt_env\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   1985\u001b[0m             )\n\u001b[0;32m   1986\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1987\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m   1988\u001b[0m                 \u001b[1;34m\"Number of classes, {0}, does not match size of \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1989\u001b[0m                 \u001b[1;34m\"target_names, {1}. Try specifying the labels \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of classes, 2, does not match size of target_names, 3. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "# Create classification report taken from here: https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "print('Test')\n",
    "class_labels = nb_classifier.classes_\n",
    "print(classification_report(y_test, pred,target_names=class_labels))\n",
    "\n",
    "print('Training')\n",
    "pred_x = nb_classifier.predict(tfidf_train)\n",
    "print(classification_report(y_train, pred_x,target_names=class_labels))\n",
    "\n",
    "print(y_test)\n",
    "print(pred)\n",
    "print(y_train)\n",
    "\n",
    "print(metrics.accuracy_score(y_test, pred))\n",
    "print(y_test, pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

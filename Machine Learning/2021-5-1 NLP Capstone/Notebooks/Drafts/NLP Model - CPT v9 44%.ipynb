{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "built-romance",
   "metadata": {},
   "source": [
    "# Changes from v8\n",
    "* Shuffled the data\n",
    "* Added these parameters to my vectorizer:  min_df = 3, sublinear_tf=True\n",
    "* Accuracy is 43.283%\n",
    "* Updated stop words\n",
    "* Accuracy is 43.288%\n",
    "* Removed lowest level of predicted words == min\n",
    "* Accuracy is 43.708%\n",
    "* Removed bottom half of the lowest level of predicted words \n",
    "* Accuracy is 44.37%\n",
    "* Running only the top 100 words for each CPT code decreased accuracy back to 43%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-alabama",
   "metadata": {},
   "source": [
    "\n",
    "# Import the MIMIC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dominant-smile",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amartins\\onedrive - intermountain healthcare\\python_pycharm_virt_env\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (4,5,7,11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "c:\\users\\amartins\\onedrive - intermountain healthcare\\python_pycharm_virt_env\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (4,5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "dataset_dictionary = {}\n",
    "\n",
    "for file_path in glob.glob('.\\\\Data\\\\MIMIC Files\\*'):\n",
    "    file_name = file_path.split('\\\\')[3].split('.')[0]\n",
    "    with gzip.open(file_path, mode='r') as file:\n",
    "        dataset_dictionary[file_name] = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-desert",
   "metadata": {},
   "source": [
    "# Join the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "grateful-tracker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset to join together -----\n",
    "\n",
    "# Create note_events table -----\n",
    "\n",
    "# Combine text for each subject and encounter\n",
    "note_events_base = dataset_dictionary['NOTEEVENTS'][dataset_dictionary['NOTEEVENTS'].loc[:,'CATEGORY'] == 'Discharge summary']\n",
    "note_events = note_events_base.groupby(['SUBJECT_ID', 'HADM_ID'], as_index=False)['TEXT'].agg(sum)\n",
    "\n",
    "# Create CPT table -----\n",
    "\n",
    "cpt_events_base = dataset_dictionary['CPTEVENTS'].loc[:, ['SUBJECT_ID','HADM_ID', 'CPT_CD']]\n",
    "cpt_events = cpt_events_base.drop_duplicates()\n",
    "\n",
    "# Join the datasets -----\n",
    "\n",
    "note_cpt = note_events.merge(cpt_events, on = ['SUBJECT_ID','HADM_ID'])\n",
    "# print(note_cpt.shape, note_events.shape, cpt_events.shape) # (223,150, 4) (52,726, 3) (227,510, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-dealing",
   "metadata": {},
   "source": [
    "# Filter the data to just 3 CPT codes: 99291, 99232, 94003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pursuant-thumbnail",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_cpt_4 = note_cpt[note_cpt['CPT_CD'].astype(str).isin(['99291', '99232', '94003'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-steering",
   "metadata": {},
   "source": [
    "# Check for Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "altered-lucas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 3 artists>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAQwElEQVR4nO3df6xfdX3H8efLVohOSQutXdd2K9O6rJqJ0EEXN+cgKwWXFJU5yCIdEGsmJJiYzOqWYUQSyKImLIqpoaEkDiQqoWq1VkLmTAZyQSiUH/aKZbRDuNIqTjJJ3Xt/fD83Huv3trf33t5v2/t8JCffc97nc873c/pp7+ueH99vU1VIkma2lw26A5KkwTMMJEmGgSTJMJAkYRhIkoDZg+7ARM2bN6+WLl066G5I0jHl/vvv/3FVzT+wfsyGwdKlSxkaGhp0NyTpmJLkqX51LxNJkgwDSZJhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJIlj+BPIk7F0/dcG3YXj1q7r3j7oLkiaAM8MJEmGgSTJMJAkYRhIkhhHGCRZkuTuJI8m2ZHkqlb/aJI9SR5s0/mdbT6cZDjJE0nO7dRXt9pwkvWd+qlJ7m31LyQ5YaoPVJI0tvGcGewHPlhVy4GVwBVJlrd1n6qq09q0BaCtuwh4A7Aa+EySWUlmAZ8GzgOWAxd39nN929frgH3A5VN0fJKkcThkGFTVM1X1QJv/GfAYsOggm6wBbquqX1TVD4Fh4Mw2DVfVk1X1EnAbsCZJgLOBL7btNwEXTPB4JEkTcFj3DJIsBd4M3NtKVybZnmRjkrmttgh4urPZ7lYbq34K8JOq2n9Avd/7r0sylGRoZGTkcLouSTqIcYdBklcBXwI+UFUvADcCrwVOA54BPnEkOthVVRuqakVVrZg//zf+C09J0gSN6xPISV5OLwg+X1VfBqiqZzvrPwd8tS3uAZZ0Nl/caoxRfx6Yk2R2OzvotpckTYPxPE0U4Cbgsar6ZKe+sNPsHcAjbX4zcFGSE5OcCiwDvgvcByxrTw6dQO8m8+aqKuBu4MK2/VrgzskdliTpcIznzOAtwHuAh5M82Gofofc00GlAAbuA9wFU1Y4ktwOP0nsS6Yqq+iVAkiuBrcAsYGNV7Wj7+xBwW5KPA9+jFz6SpGlyyDCoqu8A6bNqy0G2uRa4tk99S7/tqupJek8bSZIGwE8gS5Jm5ldY69jj144fOX7tuMAzA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEliHGGQZEmSu5M8mmRHkqta/eQk25LsbK9zWz1JbkgynGR7ktM7+1rb2u9MsrZTPyPJw22bG5LkSBysJKm/8ZwZ7Ac+WFXLgZXAFUmWA+uBu6pqGXBXWwY4D1jWpnXAjdALD+Bq4CzgTODq0QBpbd7b2W715A9NkjRehwyDqnqmqh5o8z8DHgMWAWuATa3ZJuCCNr8GuKV67gHmJFkInAtsq6q9VbUP2AasbutOqqp7qqqAWzr7kiRNg8O6Z5BkKfBm4F5gQVU901b9CFjQ5hcBT3c2291qB6vv7lOXJE2TcYdBklcBXwI+UFUvdNe13+hrivvWrw/rkgwlGRoZGTnSbydJM8a4wiDJy+kFweer6sut/Gy7xEN7fa7V9wBLOpsvbrWD1Rf3qf+GqtpQVSuqasX8+fPH03VJ0jiM52miADcBj1XVJzurNgOjTwStBe7s1C9pTxWtBH7aLidtBVYlmdtuHK8CtrZ1LyRZ2d7rks6+JEnTYPY42rwFeA/wcJIHW+0jwHXA7UkuB54C3t3WbQHOB4aBF4FLAapqb5JrgPtau49V1d42/37gZuAVwNfbJEmaJocMg6r6DjDWc//n9GlfwBVj7GsjsLFPfQh446H6Ikk6MvwEsiTJMJAkGQaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJAmYPugOSjj9L139t0F04bu267u1HZL+eGUiSDANJkmEgScIwkCRhGEiSMAwkSRgGkiTGEQZJNiZ5LskjndpHk+xJ8mCbzu+s+3CS4SRPJDm3U1/dasNJ1nfqpya5t9W/kOSEqTxASdKhjefM4GZgdZ/6p6rqtDZtAUiyHLgIeEPb5jNJZiWZBXwaOA9YDlzc2gJc3/b1OmAfcPlkDkiSdPgOGQZV9W1g7zj3twa4rap+UVU/BIaBM9s0XFVPVtVLwG3AmiQBzga+2LbfBFxweIcgSZqsydwzuDLJ9nYZaW6rLQKe7rTZ3Wpj1U8BflJV+w+o95VkXZKhJEMjIyOT6LokqWuiYXAj8FrgNOAZ4BNT1aGDqaoNVbWiqlbMnz9/Ot5SkmaECX1RXVU9Ozqf5HPAV9viHmBJp+niVmOM+vPAnCSz29lBt70kaZpM6MwgycLO4juA0SeNNgMXJTkxyanAMuC7wH3Asvbk0An0bjJvrqoC7gYubNuvBe6cSJ8kSRN3yDODJLcCbwPmJdkNXA28LclpQAG7gPcBVNWOJLcDjwL7gSuq6pdtP1cCW4FZwMaq2tHe4kPAbUk+DnwPuGmqDk6SND6HDIOqurhPecwf2FV1LXBtn/oWYEuf+pP0njaSJA2In0CWJBkGkiTDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJjCMMkmxM8lySRzq1k5NsS7Kzvc5t9SS5Iclwku1JTu9ss7a135lkbad+RpKH2zY3JMlUH6Qk6eDGc2ZwM7D6gNp64K6qWgbc1ZYBzgOWtWkdcCP0wgO4GjgLOBO4ejRAWpv3drY78L0kSUfYIcOgqr4N7D2gvAbY1OY3ARd06rdUzz3AnCQLgXOBbVW1t6r2AduA1W3dSVV1T1UVcEtnX5KkaTLRewYLquqZNv8jYEGbXwQ83Wm3u9UOVt/dp95XknVJhpIMjYyMTLDrkqQDTfoGcvuNvqagL+N5rw1VtaKqVsyfP3863lKSZoSJhsGz7RIP7fW5Vt8DLOm0W9xqB6sv7lOXJE2jiYbBZmD0iaC1wJ2d+iXtqaKVwE/b5aStwKokc9uN41XA1rbuhSQr21NEl3T2JUmaJrMP1SDJrcDbgHlJdtN7Kug64PYklwNPAe9uzbcA5wPDwIvApQBVtTfJNcB9rd3Hqmr0pvT76T2x9Arg622SJE2jQ4ZBVV08xqpz+rQt4Iox9rMR2NinPgS88VD9kCQdOX4CWZJkGEiSDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJDHJMEiyK8nDSR5MMtRqJyfZlmRne53b6klyQ5LhJNuTnN7Zz9rWfmeStZM7JEnS4ZqKM4O/qKrTqmpFW14P3FVVy4C72jLAecCyNq0DboReeABXA2cBZwJXjwaIJGl6HInLRGuATW1+E3BBp35L9dwDzEmyEDgX2FZVe6tqH7ANWH0E+iVJGsNkw6CAbya5P8m6VltQVc+0+R8BC9r8IuDpzra7W22s+m9Isi7JUJKhkZGRSXZdkjRq9iS3/9Oq2pPkNcC2JI93V1ZVJalJvkd3fxuADQArVqyYsv1K0kw3qTODqtrTXp8D7qB3zf/ZdvmH9vpca74HWNLZfHGrjVWXJE2TCYdBkt9K8urReWAV8AiwGRh9ImgtcGeb3wxc0p4qWgn8tF1O2gqsSjK33The1WqSpGkymctEC4A7kozu59+q6htJ7gNuT3I58BTw7tZ+C3A+MAy8CFwKUFV7k1wD3Nfafayq9k6iX5KkwzThMKiqJ4E39ak/D5zTp17AFWPsayOwcaJ9kSRNjp9AliQZBpIkw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRxFYZBkdZInkgwnWT/o/kjSTHJUhEGSWcCngfOA5cDFSZYPtleSNHMcFWEAnAkMV9WTVfUScBuwZsB9kqQZY/agO9AsAp7uLO8GzjqwUZJ1wLq2+D9JnpiGvg3aPODHg+7EeOX6QffgqOCYHXuOmTGbgvH6vX7FoyUMxqWqNgAbBt2P6ZRkqKpWDLofGj/H7NjjmB09l4n2AEs6y4tbTZI0DY6WMLgPWJbk1CQnABcBmwfcJ0maMY6Ky0RVtT/JlcBWYBawsap2DLhbR4sZdVnsOOGYHXtm/JilqgbdB0nSgB0tl4kkSQNkGEiSDIPpkuSqJI8k2ZHkA632piT/meThJF9JclKr/2WS+1v9/iRnd/bzN0m2t/1c36m/NckDSfYnuXDaD/A4NIVj9o0kD7X9fLZ94p4k/5Lk8TaedySZM4jjPJ70G7POug8mqSTz2nKS3NC+Amd7ktM7bdcm2dmmtZ1637E8LlSV0xGegDcCjwCvpHfT/lvA6+g9RfXnrc1lwDVt/s3A73S23dPmTwH+C5jfljcB57T5pcAfAbcAFw76mI/1aarGrC2f1F4DfAm4qC2vAma3+euB6wd93MfyNNaYtXVL6D2g8hQwr9XOB77exmUlcG+rnww82V7ntvm5BxvL42HyzGB6/CG9v2gvVtV+4N+BdwKvB77d2mwD3gVQVd+rqv9u9R3AK5KcCPw+sLOqRtq6b3W22VVV24H/m44DmgGmasyoqhdafTZwAlCt/s22b4B76H2+RhM31pgBfAr4B9qffbMGuKV67gHmJFkInAtsq6q9VbWP3jivhrHH8nhgGEyPR4A/S3JKklfS+41kCb0fGqPfwfTX/PoH70a9C3igqn4BDAN/kGRpktnABWNso8mbqjEDIMlW4DngZ8AX+2xzGb3fUjVxfccsyRp6Z2oPHdC+39fgLDpIHRjXWB6TDINpUFWP0bsM8E3gG8CDwC/p/QB4f5L7gVcDL3W3S/KGtt372n72AX8PfAH4D2BX24+m2FSNWWd/5wILgROBsw/Y5h+B/cDnj8ChzBhjjNmJwEeAf57C9xlzLI9lhsE0qaqbquqMqnorsA/4flU9XlWrquoM4FbgB6PtkywG7gAuqaofdPbzlao6q6r+BHgC+P70HsnMMVVj1tnf/wJ30vlG3iR/B/wV8LfVLkZr4vqM2Q7gVOChJLvoXYp7IMlvM/bX4Bzy63H6jeUxb9A3LWbKBLymvf4u8Dgwp1N7Gb0bv5e15TnAQ8A7D7KfufR+83n9AetvxhvIR82YAa8CFrb52fTO6q5sy6uBR2kPBDgdmTE7YP0ufnUD+e38+g3k77b6ycAP27+xuW3+5ION5fEwDbwDM2Wid1nn0fYDY/QJoKvo/Wb/feA6fvWJ8H8Cft5+2I9Oo3/Jb237eZTOkwzAH9O7tvlz4Hlgx6CP+VifpmLMgAX0nkDaTu+a9r/yqyeIhuldmx5t/9lBH/OxPvUbswPWd8Mg9P5TrR8ADwMrOu0ua+MzDFzaamOO5fEw+XUUkiTvGUiSDANJEoaBJAnDQJKEYSBJwjCQJGEYSJKA/wfUDGWHZ6A7KAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = note_cpt_4['CPT_CD'].astype(str).value_counts()\n",
    "\n",
    "plt.bar(x.index, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-september",
   "metadata": {},
   "source": [
    "# Filter the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "unable-minimum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1         admission date        discharge date     date ...\n",
       "4         admission date        discharge date     date ...\n",
       "10        admission date          discharge date     dat...\n",
       "11        admission date          discharge date     dat...\n",
       "13        admission date          discharge date    date...\n",
       "                                ...                        \n",
       "223123    admission date                 discharge date ...\n",
       "223124    admission date                 discharge date ...\n",
       "223130    admission date                 discharge date ...\n",
       "223134    admission date                 discharge date ...\n",
       "223135    admission date                 discharge date ...\n",
       "Name: TEXT, Length: 66480, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def clean_data(text_series):\n",
    "    \n",
    "    # Replace \\n \n",
    "    text_series = text_series.str.replace('\\\\n',' ', regex=True)    \n",
    "\n",
    "    # Remove dates and locations\n",
    "    text_series = text_series.str.replace('\\[\\*\\*(.*?)\\*\\*\\]', ' ', regex=True)\n",
    "    \n",
    "    # Remove topics\n",
    "    data = text_series.str.split('([A-Z\\s]+:)')\n",
    "    for row_num, value in enumerate(data):\n",
    "        text_chunks = [x.strip().replace(':','').replace('\\n', '') for x in value]\n",
    "        for i, x in enumerate(text_chunks):\n",
    "            if 'MEDICATION' in x or 'SOCIAL HISTORY' in x or 'FAMILY HISTORY' in x:\n",
    "                text_chunks[i] = ' '\n",
    "                try:\n",
    "                    text_chunks[i + 1] = ' '\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "        text_series.iloc[row_num] = ' '.join(text_chunks)\n",
    "    \n",
    "    # Replace punctuation\n",
    "    text_series = text_series.str.replace('[' + string.punctuation + ']', ' ', regex=True)\n",
    "    \n",
    "    # Convert to lowercase \n",
    "    text_series = text_series.str.lower()\n",
    "    \n",
    "    # Remove all digits\n",
    "    text_series = text_series.str.replace('\\d',' ', regex=True)\n",
    "    \n",
    "    return text_series\n",
    "\n",
    "note_cpt_4_clean = clean_data(note_cpt_4['TEXT'])\n",
    "note_cpt_4_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuous-measure",
   "metadata": {},
   "source": [
    "# Update text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "behind-texture",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amartins\\onedrive - intermountain healthcare\\python_pycharm_virt_env\\.venv\\lib\\site-packages\\pandas\\core\\indexing.py:1676: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "note_cpt_4.loc[:, 'TEXT'] = note_cpt_4_clean.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-bracket",
   "metadata": {},
   "source": [
    "# Shuffle the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "surprised-jacob",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_cpt_4 = note_cpt_4.sample(n = len(note_cpt_4), random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-devil",
   "metadata": {},
   "source": [
    "# Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "extensive-characterization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages -----\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "my_stop_words = list(set(stopwords.words('english'))) \\\n",
    "                + ['admission', 'date', 'sex'] \\\n",
    "                + ['needed', 'every', 'seen', 'weeks', 'please', 'ml', 'unit', 'small', 'year', 'old', 'cm', 'non', 'mm', 'however']\n",
    "                # Got the above from my top 100 most predictive words that I wanted to remove\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Split the data -----\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(note_cpt_4['TEXT'].values, note_cpt_4['CPT_CD'].astype(str), test_size = .33, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-comment",
   "metadata": {},
   "source": [
    "# Tokenize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "determined-waters",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the data -----\n",
    "\n",
    "# Import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=my_stop_words, min_df = 3, max_df = .7, sublinear_tf=True)\n",
    "\n",
    "# Transform the training data\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-grenada",
   "metadata": {},
   "source": [
    "# Run Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cultural-india",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Naive Bayes model -----\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "nb_classifier = MultinomialNB(alpha=.7)\n",
    "\n",
    "# Fit and check accuracy\n",
    "nb_classifier.fit(tfidf_train, y_train)\n",
    "pred = nb_classifier.predict(tfidf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-decrease",
   "metadata": {},
   "source": [
    "# Tune NB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "sexual-mexico",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.421076621541547\n",
      "0.1\n",
      "0.421076621541547\n",
      "0.2\n",
      "0.421076621541547\n",
      "0.30000000000000004\n",
      "0.421076621541547\n",
      "0.4\n",
      "0.421076621541547\n",
      "0.5\n",
      "0.421076621541547\n",
      "0.6000000000000001\n",
      "0.421076621541547\n",
      "0.7000000000000001\n",
      "0.421076621541547\n",
      "0.8\n",
      "0.421076621541547\n",
      "0.9\n",
      "0.421076621541547\n",
      "1.0\n",
      "0.421076621541547\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def hyperparam_tuning(tfidf_train, y_train, tfidf_test, y_test, nb_classifier):\n",
    "    for i in np.arange(0,1.1,.1):\n",
    "        nb_classifier = MultinomialNB()\n",
    "        nb_classifier.fit(tfidf_train, y_train)\n",
    "        pred = nb_classifier.predict(tfidf_test)\n",
    "        print(i)\n",
    "        print(metrics.accuracy_score(y_test, pred))\n",
    "\n",
    "hyperparam_tuning(tfidf_train, y_train, tfidf_test, y_test, nb_classifier)  \n",
    "\n",
    "# Looks like .6-.7 are the best alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-guess",
   "metadata": {},
   "source": [
    "# Run Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "under-ministry",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amartins\\onedrive - intermountain healthcare\\python_pycharm_virt_env\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_logist = LogisticRegression(C=.001, random_state = 42, multi_class = 'multinomial', penalty='l2')\n",
    "clf_logist.fit(tfidf_train, y_train)\n",
    "logist_pred = clf_logist.predict(tfidf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-ultimate",
   "metadata": {},
   "source": [
    "# Looking at Feature Names and Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "decent-lotus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33442"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notes\n",
    "# sum([np.exp(1)** x for x in nb_classifier.coef_[0]]) # The probability of all the words equals one\n",
    "# # Taken from here: * https://stackoverflow.com/questions/61586946/how-to-calculate-feature-log-prob-in-the-naive-bayes-multinomialnb\n",
    "\n",
    "# ------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_feature_rank(tfidf_vectorizer, y_no, nb_classifier):\n",
    "    \n",
    "    # Get the feature names\n",
    "    feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "    # Zip together the first CPT weights with feature names\n",
    "    feat_with_weights =  sorted(zip(nb_classifier.coef_[y_no], feature_names))\n",
    "    \n",
    "    # Print words most responsible for the prediction\n",
    "#     print('Top 100 \\n\\n\\n\\n')\n",
    "#     top_100_ls = []\n",
    "    for i in range(100):\n",
    "        x = feat_with_weights[-i-1]\n",
    "#         top_100_ls.append(x[1])\n",
    "#         print(nb_classifier.classes_[y_no], i, round((np.exp(1) ** x[0]),4), x[1])\n",
    "\n",
    "#     print('\\n\\n\\n\\n Bottom 100 \\n\\n\\n\\n')\n",
    "    for i in range(100):\n",
    "        x = feat_with_weights[i]\n",
    "#         print(nb_classifier.classes_[y_no], i, round((np.exp(1) ** x[0]),4), x[1])\n",
    "    \n",
    "#     min_weight = min([i[0] for i in feat_with_weights])\n",
    "    \n",
    "    x = [i[0] for i in feat_with_weights]\n",
    "    \n",
    "    median_pred = np.median(x)\n",
    "          \n",
    "    return [i[1] for i in feat_with_weights if i[0] <= median_pred] # Minimum weight words\n",
    "#     return top_100_ls\n",
    "\n",
    "# Find the least predictive words\n",
    "def least_pred_words(nb_classifier, tfidf_vectorizer):\n",
    "    low_wt_stop_ls = []\n",
    "\n",
    "    for i in range(len(nb_classifier.classes_)):\n",
    "        low_wt_stop_ls += get_feature_rank(tfidf_vectorizer, i, nb_classifier)\n",
    "\n",
    "    low_wt_stop_ls = list(set(low_wt_stop_ls))\n",
    "    return low_wt_stop_ls\n",
    "    \n",
    "low_wt_stop_ls = least_pred_words(nb_classifier, tfidf_vectorizer)\n",
    "\n",
    "# Find top 100 words - doesn't seem to improve the model\n",
    "def highest_pred_words(nb_classifier, tfidf_vectorizer):\n",
    "    top_100_ls = []\n",
    "    for i in range(len(nb_classifier.classes_)):\n",
    "        top_100_ls += get_feature_rank(tfidf_vectorizer, i, nb_classifier)\n",
    "\n",
    "    top_100_ls = list(set(top_100_ls))\n",
    "    return top_100_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endangered-summit",
   "metadata": {},
   "source": [
    "# Update stop words and tokenize again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "intense-public",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stop_words += low_wt_stop_ls\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=my_stop_words, min_df = 3, max_df = .7, sublinear_tf=True)\n",
    "\n",
    "# Transform the training data\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-surface",
   "metadata": {},
   "source": [
    "# Create Vocab with top words and tokenize again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-college",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It reduced test accuracy back to 43% and training went from 50% to 44%\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(vocabulary=top_100_ls, stop_words=my_stop_words, min_df = 3, max_df = .7, sublinear_tf=True)\n",
    "\n",
    "# Transform the training data\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-remove",
   "metadata": {},
   "source": [
    "# Run Naive Bayes again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "painted-glasgow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Naive Bayes model -----\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "nb_classifier = MultinomialNB(alpha=.7)\n",
    "\n",
    "# Fit and check accuracy\n",
    "nb_classifier.fit(tfidf_train, y_train)\n",
    "pred = nb_classifier.predict(tfidf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-kenya",
   "metadata": {},
   "source": [
    "# Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "optimum-turkish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       94003       0.47      0.48      0.47      5484\n",
      "       99232       0.42      0.29      0.34      7842\n",
      "       99291       0.44      0.56      0.49      8613\n",
      "\n",
      "    accuracy                           0.44     21939\n",
      "   macro avg       0.44      0.44      0.44     21939\n",
      "weighted avg       0.44      0.44      0.44     21939\n",
      "\n",
      "Training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       94003       0.49      0.51      0.50     10948\n",
      "       99232       0.51      0.34      0.41     16196\n",
      "       99291       0.48      0.62      0.54     17397\n",
      "\n",
      "    accuracy                           0.49     44541\n",
      "   macro avg       0.49      0.49      0.48     44541\n",
      "weighted avg       0.49      0.49      0.48     44541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create classification report taken from here: https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print('Test')\n",
    "class_labels = nb_classifier.classes_\n",
    "print(classification_report(y_test, pred,target_names=class_labels))\n",
    "\n",
    "print('Training')\n",
    "pred_x = nb_classifier.predict(tfidf_train)\n",
    "print(classification_report(y_train, pred_x,target_names=class_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "italian-serum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44368476229545556"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, pred)\n",
    "\n",
    "# \"\"\"\n",
    "# V1 NLP Model Accuracy: 0.117\n",
    "# Wow, I've got a long way to go to improve accuracy\n",
    "# V2 NLP Model Accuracy: 0.14\n",
    "# V3 NLP Model Accuracy: .40\n",
    "# \"\"\"\n",
    "\n",
    "# Confusion matrix \n",
    "# confusion_mtrx = metrics.confusion_matrix(y_test.astype(str), pred) # 1380, 1380\n",
    "# confusion_mtrx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "quantitative-leadership",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3560782168740599"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistical Model accuracy\n",
    "metrics.accuracy_score(y_test, logist_pred)\n",
    "# .39\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-wages",
   "metadata": {},
   "source": [
    "# Vectorize Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "objective-registrar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (1, 2)\t1\n",
      "  (2, 2)\t1\n",
      "  (3, 2)\t1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vocab = ['love', 'happy', 'run']\n",
    "count_vectorizer = CountVectorizer(vocabulary = vocab)\n",
    "x = count_vectorizer.fit_transform(['happy', 'run', 'run', 'run'])\n",
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

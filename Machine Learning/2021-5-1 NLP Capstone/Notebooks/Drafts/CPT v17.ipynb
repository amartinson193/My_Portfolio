{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "built-romance",
   "metadata": {},
   "source": [
    "# Changes from v16\n",
    "* Combining ICD and CPT models, but still providing options to run everything quickly\n",
    "\n",
    "# Next Steps\n",
    "* Try some different models - supervised & unsupervised\n",
    "* Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-basis",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "## Questions\n",
    "* Run the data for each category with only no filter, one, and three CPT codes for each discharge summary\n",
    "    * ANSWER: It performs better with only 1 CPT per note and 3 had a decrease of 3% in accuracy\n",
    "* Does including all notes/CPT sections improve accuracy?\n",
    "    * ANSWER: No, it decreased the accuracy\n",
    "* Does including some sections improve accuracy when included with discharge summary?\n",
    "    * No, accuracy went from 80% to 71%- at least for the E/M category\n",
    "* Does accuracy improve when there are more notes per CPT code?\n",
    "    * Yes\n",
    "* What is the lowest threshold I can use without decreasing accuracy?\n",
    "    * It seems like I don't need a threshold\n",
    "* Does imbalance correction improve model accuracy?\n",
    "    * Yes, it makes a huge difference\n",
    "* Is undersampling or over-sampling a better method for imbalance correction?\n",
    "    * Oversampling since the lowest records only contain one note - could also try SMOTE and see if that gives better results or not\n",
    "* Use label encoder for the CPT codes\n",
    "    * Does the accuracy improve when using labelencoder?\n",
    "* Is limiting CPT codes to just one excluding CPT codes?\n",
    "    * No\n",
    "* Can I use the descriptions in the CPT table to help improve my analysis?\n",
    "    * Yes, only for 94002 and 94003\n",
    "* Do a greater variety of CPT scores improve CPT f-scores?\n",
    "    * No, they slightly change, but probably only b/c what goes in train and test changes\n",
    "* Does the accuracy improve when filtered to each CPT section individually?\n",
    "    * Yes\n",
    "\n",
    "\n",
    "\n",
    "# Next Steps\n",
    "\n",
    "* Adjust model so it can be run in smaller chunks\n",
    "* Check the accuracy for those CPT codes in v13 and see if accuracy decreased when looking at individual sections\n",
    "    * Add option to run the code without stratifying by section\n",
    "* Complete model to predict CPT and ICD codes with their probabilities\n",
    "* Serialize the model to be used in streamlit\n",
    "* Add loading statements with time it module times for how long each section takes to run\n",
    "* Add HCC code that suggests HCC's based on the output\n",
    "* Add descriptions for the ICD and CPT code predictions\n",
    "* Add top most predictive feature names for the model in the output\n",
    "* Use label encoder and then reverse transform the encoded values\n",
    "\n",
    "Extra:\n",
    "* Add K-Means clustering to add suggested codes based on CPT and ICD code output\n",
    "* Add the model to a class with functions as methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-sharing",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "answering-retro",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import glob\n",
    "import string\n",
    "from sklearn.utils import resample\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-alabama",
   "metadata": {},
   "source": [
    "\n",
    "# Import the MIMIC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "environmental-character",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amartins\\onedrive - intermountain healthcare\\python_pycharm_virt_env\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (4,5,7,11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "c:\\users\\amartins\\onedrive - intermountain healthcare\\python_pycharm_virt_env\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (4,5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "dataset_dictionary = {}\n",
    "\n",
    "for file_path in glob.glob('.\\\\Data\\\\MIMIC Files\\*'):\n",
    "    file_name = file_path.split('\\\\')[3].split('.')[0]\n",
    "    with gzip.open(file_path, mode='r') as file:\n",
    "        dataset_dictionary[file_name] = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-literature",
   "metadata": {},
   "source": [
    "# Assign Datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "delayed-moscow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['CPTEVENTS', 'DIAGNOSES_ICD', 'D_CPT', 'D_ICD_DIAGNOSES', 'D_ICD_PROCEDURES', 'NOTEEVENTS', 'PATIENTS', 'PROCEDURES_ICD'])\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 573146 entries, 0 to 573145\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   ROW_ID            573146 non-null  int64  \n",
      " 1   SUBJECT_ID        573146 non-null  int64  \n",
      " 2   HADM_ID           573146 non-null  int64  \n",
      " 3   COSTCENTER        573146 non-null  object \n",
      " 4   CHARTDATE         101545 non-null  object \n",
      " 5   CPT_CD            573146 non-null  object \n",
      " 6   CPT_NUMBER        573128 non-null  float64\n",
      " 7   CPT_SUFFIX        22 non-null      object \n",
      " 8   TICKET_ID_SEQ     471601 non-null  float64\n",
      " 9   SECTIONHEADER     573125 non-null  object \n",
      " 10  SUBSECTIONHEADER  573125 non-null  object \n",
      " 11  DESCRIPTION       101545 non-null  object \n",
      "dtypes: float64(2), int64(3), object(7)\n",
      "memory usage: 52.5+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 651047 entries, 0 to 651046\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   ROW_ID      651047 non-null  int64  \n",
      " 1   SUBJECT_ID  651047 non-null  int64  \n",
      " 2   HADM_ID     651047 non-null  int64  \n",
      " 3   SEQ_NUM     651000 non-null  float64\n",
      " 4   ICD9_CODE   651000 non-null  object \n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 24.8+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 134 entries, 0 to 133\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   ROW_ID               134 non-null    int64 \n",
      " 1   CATEGORY             134 non-null    int64 \n",
      " 2   SECTIONRANGE         134 non-null    object\n",
      " 3   SECTIONHEADER        134 non-null    object\n",
      " 4   SUBSECTIONRANGE      134 non-null    object\n",
      " 5   SUBSECTIONHEADER     134 non-null    object\n",
      " 6   CODESUFFIX           11 non-null     object\n",
      " 7   MINCODEINSUBSECTION  134 non-null    int64 \n",
      " 8   MAXCODEINSUBSECTION  134 non-null    int64 \n",
      "dtypes: int64(4), object(5)\n",
      "memory usage: 9.5+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14567 entries, 0 to 14566\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   ROW_ID       14567 non-null  int64 \n",
      " 1   ICD9_CODE    14567 non-null  object\n",
      " 2   SHORT_TITLE  14567 non-null  object\n",
      " 3   LONG_TITLE   14567 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 455.3+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3882 entries, 0 to 3881\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   ROW_ID       3882 non-null   int64 \n",
      " 1   ICD9_CODE    3882 non-null   int64 \n",
      " 2   SHORT_TITLE  3882 non-null   object\n",
      " 3   LONG_TITLE   3882 non-null   object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 121.4+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2083180 entries, 0 to 2083179\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Dtype  \n",
      "---  ------       -----  \n",
      " 0   ROW_ID       int64  \n",
      " 1   SUBJECT_ID   int64  \n",
      " 2   HADM_ID      float64\n",
      " 3   CHARTDATE    object \n",
      " 4   CHARTTIME    object \n",
      " 5   STORETIME    object \n",
      " 6   CATEGORY     object \n",
      " 7   DESCRIPTION  object \n",
      " 8   CGID         float64\n",
      " 9   ISERROR      float64\n",
      " 10  TEXT         object \n",
      "dtypes: float64(3), int64(2), object(6)\n",
      "memory usage: 174.8+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 46520 entries, 0 to 46519\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   ROW_ID       46520 non-null  int64 \n",
      " 1   SUBJECT_ID   46520 non-null  int64 \n",
      " 2   GENDER       46520 non-null  object\n",
      " 3   DOB          46520 non-null  object\n",
      " 4   DOD          15759 non-null  object\n",
      " 5   DOD_HOSP     9974 non-null   object\n",
      " 6   DOD_SSN      13378 non-null  object\n",
      " 7   EXPIRE_FLAG  46520 non-null  int64 \n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 2.8+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 240095 entries, 0 to 240094\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count   Dtype\n",
      "---  ------      --------------   -----\n",
      " 0   ROW_ID      240095 non-null  int64\n",
      " 1   SUBJECT_ID  240095 non-null  int64\n",
      " 2   HADM_ID     240095 non-null  int64\n",
      " 3   SEQ_NUM     240095 non-null  int64\n",
      " 4   ICD9_CODE   240095 non-null  int64\n",
      "dtypes: int64(5)\n",
      "memory usage: 9.2 MB\n",
      "None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'to_datetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-1384668da6e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# CPTEVENTS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mdataset_dictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CPTEVENTS'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SECTIONHEADER'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'CPT_CD'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_dictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CPTEVENTS'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SECTIONHEADER'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'CPT_CD'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mdataset_dictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CPTEVENTS'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CHARTDATE'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_dictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CPTEVENTS'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CHARTDATE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\amartins\\onedrive - intermountain healthcare\\python_pycharm_virt_env\\.venv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5460\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5461\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5462\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5464\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'to_datetime'"
     ]
    }
   ],
   "source": [
    "# Check all the datasets exist in the dictionary \n",
    "print(dataset_dictionary.keys())\n",
    "\n",
    "# Check the datatypes and information for each table \n",
    "for i in dataset_dictionary.keys():\n",
    "    print(dataset_dictionary[i].info())\n",
    "\n",
    "# Correct any datatype issues #####\n",
    "\n",
    "# CPTEVENTS\n",
    "dataset_dictionary['CPTEVENTS'].loc[:,['SECTIONHEADER','CPT_CD']] = dataset_dictionary['CPTEVENTS'].loc[:,['SECTIONHEADER','CPT_CD']].astype(str)\n",
    "dataset_dictionary['CPTEVENTS']['CHARTDATE'] = dataset_dictionary['CPTEVENTS']['CHARTDATE'].to_datetime()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-desert",
   "metadata": {},
   "source": [
    "# Join the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "grateful-tracker",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_tables(dataset_dictionary, category=['Discharge summary'], all_notes=False):\n",
    "\n",
    "    # Define tables\n",
    "    note_events_base = dataset_dictionary['NOTEEVENTS']\n",
    "    cpt_events_base = dataset_dictionary['CPTEVENTS']\n",
    "    icd_events_base = dataset_dictionary['DIAGNOSES_ICD']\n",
    "\n",
    "    # Combine text for each subject and encounter\n",
    "    if all_notes == False:\n",
    "        note_events_base = note_events_base[note_events_base.loc[:,'CATEGORY'].isin(category)]\n",
    "    \n",
    "    # Filter out the addendums and restrict notes only to reports\n",
    "    note_events_base = note_events_base[note_events_base['DESCRIPTION'] == 'Report']\n",
    "    \n",
    "    # Aggregate text by Subject and HADM ID's\n",
    "    note_events = note_events_base.groupby(['SUBJECT_ID', 'HADM_ID'], as_index=False)['TEXT'].agg(sum)\n",
    "    \n",
    "    # Create CPT table\n",
    "    cpt_events_base = cpt_events_base.loc[:, ['SUBJECT_ID','HADM_ID', 'CPT_CD', 'SECTIONHEADER', 'DESCRIPTION']]\n",
    "    cpt_events = cpt_events_base.drop_duplicates()\n",
    "    \n",
    "    # Create ICD table\n",
    "    icd_events_base = icd_events_base[icd_events_base['SEQ_NUM'] == 1]\n",
    "    icd_events_base = icd_events_base.loc[:, ['SUBJECT_ID','HADM_ID', 'ICD9_CODE']]\n",
    "    icd_events = icd_events_base.drop_duplicates()\n",
    "    \n",
    "    # Join the datasets\n",
    "    note_cpt = note_events.merge(cpt_events, on = ['SUBJECT_ID','HADM_ID'])\n",
    "    note_icd = note_events.merge(icd_events, on = ['SUBJECT_ID', 'HADM_ID'])\n",
    "    \n",
    "    # Replace any nulls with blanks\n",
    "    x = note_cpt[note_cpt['DESCRIPTION'].isnull()].copy()\n",
    "    x.loc[:,'DESCRIPTION'] = ''\n",
    "    y = note_cpt[note_cpt['DESCRIPTION'].notnull()].copy()\n",
    "    note_cpt = pd.concat([x,y])\n",
    "    \n",
    "    # Combine description and text columns\n",
    "    note_cpt['TEXT'] = note_cpt['TEXT'] + note_cpt['DESCRIPTION']\n",
    "    note_cpt = note_cpt.drop('DESCRIPTION', axis=1)\n",
    "    \n",
    "    return note_cpt, note_icd\n",
    "\n",
    "# Run the function\n",
    "note_cpt, note_icd = join_tables(dataset_dictionary)\n",
    "\n",
    "# Drop notes with the nan sectionheader\n",
    "drop_ls = note_cpt[note_cpt['SECTIONHEADER'] == 'nan']\n",
    "note_cpt = note_cpt.drop(drop_ls.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-dealing",
   "metadata": {},
   "source": [
    "# Filter the data - CPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pursuant-thumbnail",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(combined_df, threshold):\n",
    "\n",
    "    # Print value counts original\n",
    "    print('Value Counts for the original data:\\n\\n', combined_df['CPT_CD'].value_counts().head(25))\n",
    "\n",
    "    # Filter based on count limit\n",
    "    df = combined_df['CPT_CD'].value_counts()\n",
    "    filtered_ls = list((df[df >= threshold]).index.values)\n",
    "    filtered_df = combined_df[combined_df['CPT_CD'].isin(filtered_ls)]\n",
    "    \n",
    "    # Print value counts filtered\n",
    "    print('Value Counts for the filtered data:\\n\\n', combined_df['CPT_CD'].value_counts().head(25))\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "# Find Counts of CPT Codes per Patient Encounter and filter df\n",
    "def cpt_count_filter(df, og_df, cpt_section_hadm_limit, cpt_hadm_limit):\n",
    "    \n",
    "    # Filter based on limit per SECTIONHEADER & merge\n",
    "    df1 = og_df.groupby(['HADM_ID', 'SECTIONHEADER'])['CPT_CD'].count()\n",
    "    filtered_encntrs = df1[df1 <= cpt_section_hadm_limit]\n",
    "    final_df = df.merge(filtered_encntrs, on=['HADM_ID', 'SECTIONHEADER'])\n",
    "    final_df.drop('CPT_CD_y', axis=1, inplace=True)\n",
    "    \n",
    "    # Filter dataset again based on total number of CPT codes per HADM\n",
    "    df2 = og_df.groupby(['HADM_ID'])['CPT_CD'].count()\n",
    "    filtered_encntrs = df2[df2 <= cpt_hadm_limit]\n",
    "    final_df = final_df.merge(filtered_encntrs, on=['HADM_ID'])\n",
    "    final_df.drop('CPT_CD', axis=1, inplace=True)\n",
    "    \n",
    "    # Rename columns\n",
    "    final_df.columns = ['SUBJECT_ID', 'HADM_ID', 'TEXT', 'CPT_CD', 'SECTIONHEADER']\n",
    "    \n",
    "    print('Value Counts for the filtered data:\\n\\n', final_df['CPT_CD'].value_counts().head(50))\n",
    "\n",
    "    return final_df\n",
    "    \n",
    "# Filter DataFrame to a set amount of CPT codes in each section header #####\n",
    "def cpt_per_section_filter(df, section_limit, sections=['Emerging technology'], all_sections=False):\n",
    "    \n",
    "    # Create list for dataframes\n",
    "    df_ls = []\n",
    "\n",
    "    # Group by and count the number of CPT codes\n",
    "    cts_by_cpt = df.groupby(['SECTIONHEADER', 'CPT_CD'])['CPT_CD'].count()\n",
    "    cts_by_cpt.index.names = ['SECTIONHEADER', 'CPT_CDS']\n",
    "    cts_by_cpt = cts_by_cpt.reset_index()\n",
    "    cts_by_cpt.columns = ['SECTIONHEADER', 'CPT_CD', 'COUNT']\n",
    "\n",
    "    # Sort values by section and CPT code count\n",
    "    cts_by_cpt_s = cts_by_cpt.sort_values(by=['SECTIONHEADER','COUNT'], ascending=False)\n",
    "\n",
    "    # Filter based on the limit of CPT codes wanted for each category\n",
    "    if all_sections == True:\n",
    "        sections = list(set(df['SECTIONHEADER']))\n",
    "        \n",
    "    for i in sections:\n",
    "        top_cts = cts_by_cpt_s[cts_by_cpt_s['SECTIONHEADER'] == i].iloc[:section_limit,:]\n",
    "\n",
    "        # Append to list\n",
    "        df_ls.append(top_cts)\n",
    "\n",
    "    # Combine DataFrames\n",
    "    df_combo = pd.concat(df_ls)\n",
    "\n",
    "    # Join back to source data\n",
    "    final_df = df.merge(df_combo, on=['SECTIONHEADER','CPT_CD'])\n",
    "    \n",
    "    print('\\nThe length of the initial dataset was {} and the new dataset is {}\\n\\n'.format(len(df), len(final_df)))\n",
    "\n",
    "    return final_df\n",
    "\n",
    "def show_section_counts(df):\n",
    "    # Print count of CPT codes by section\n",
    "    cts_by_cpt = df.groupby(['SECTIONHEADER', 'CPT_CD'])['CPT_CD'].count()\n",
    "    cts_by_section = cts_by_cpt.groupby('SECTIONHEADER').count()\n",
    "    print('\\nHere are the counts by section:\\n\\n', cts_by_section)\n",
    "\n",
    "def show_cpt_counts_by_section(df):\n",
    "    cts_by_cpt = df.groupby(['SECTIONHEADER', 'CPT_CD'])['CPT_CD'].count()\n",
    "    print('\\nHere are the counts by CPT by section\\n\\n:')\n",
    "#     print(pd.DataFrame(cts_by_cpt.rename('Count')).reset_index())\n",
    "    for i, x in pd.DataFrame(cts_by_cpt.rename('Count')).reset_index().iterrows():\n",
    "        print(x['SECTIONHEADER'], x['CPT_CD'], x['Count'])\n",
    "        \n",
    "def filter_cpt_ct(df, section, ct):\n",
    "    df = df[df['SECTIONHEADER'] == section]\n",
    "    top_codes = list(df['CPT_CD'].value_counts().head(ct).index)\n",
    "    df = df[df.CPT_CD.isin(top_codes)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "encouraging-music",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Counts for the filtered data:\n",
      "\n",
      " 94003    12871\n",
      "94002     8206\n",
      "99291     4758\n",
      "99232     2385\n",
      "99233     1924\n",
      "36556     1788\n",
      "99254     1170\n",
      "99231     1078\n",
      "99223     1035\n",
      "90935     1027\n",
      "99222      970\n",
      "99253      865\n",
      "99255      700\n",
      "36620      661\n",
      "99238      485\n",
      "31624      469\n",
      "76942      447\n",
      "33405      436\n",
      "76937      352\n",
      "31645      342\n",
      "99252      334\n",
      "31622      315\n",
      "99292      313\n",
      "99239      312\n",
      "99221      268\n",
      "90801      238\n",
      "62270      225\n",
      "31500      194\n",
      "01996      178\n",
      "99024      169\n",
      "90945      154\n",
      "90937      150\n",
      "36489      145\n",
      "32002      140\n",
      "49080      128\n",
      "61312      124\n",
      "99251      111\n",
      "43246      108\n",
      "33427      107\n",
      "93503      107\n",
      "31600      105\n",
      "33430       93\n",
      "33533       91\n",
      "92960       90\n",
      "47135       89\n",
      "33860       86\n",
      "54150       84\n",
      "32422       83\n",
      "27245       80\n",
      "32000       75\n",
      "Name: CPT_CD, dtype: int64\n",
      "Available sections:\n",
      "\n",
      " {'Surgery', 'Medicine', 'Emerging technology', 'Radiology', 'Evaluation and management', 'Pathology and laboratory', 'Anesthesia'}\n",
      "\n",
      "The length of the initial dataset was 52743 and the new dataset is 44402\n",
      "\n",
      "\n",
      "Value Counts for the original data:\n",
      "\n",
      " 94003    12871\n",
      "94002     8206\n",
      "99291     4758\n",
      "99232     2385\n",
      "99233     1924\n",
      "36556     1788\n",
      "99254     1170\n",
      "99231     1078\n",
      "99223     1035\n",
      "90935     1027\n",
      "99222      970\n",
      "99253      865\n",
      "99255      700\n",
      "36620      661\n",
      "99238      485\n",
      "31624      469\n",
      "76942      447\n",
      "33405      436\n",
      "76937      352\n",
      "31645      342\n",
      "31622      315\n",
      "90801      238\n",
      "62270      225\n",
      "31500      194\n",
      "01996      178\n",
      "Name: CPT_CD, dtype: int64\n",
      "Value Counts for the filtered data:\n",
      "\n",
      " 94003    12871\n",
      "94002     8206\n",
      "99291     4758\n",
      "99232     2385\n",
      "99233     1924\n",
      "36556     1788\n",
      "99254     1170\n",
      "99231     1078\n",
      "99223     1035\n",
      "90935     1027\n",
      "99222      970\n",
      "99253      865\n",
      "99255      700\n",
      "36620      661\n",
      "99238      485\n",
      "31624      469\n",
      "76942      447\n",
      "33405      436\n",
      "76937      352\n",
      "31645      342\n",
      "31622      315\n",
      "90801      238\n",
      "62270      225\n",
      "31500      194\n",
      "01996      178\n",
      "Name: CPT_CD, dtype: int64\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'filtered_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-fe6f562f586d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Show some dataset stats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mshow_section_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mshow_cpt_counts_by_section\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filtered_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Filter the number of CPT occurrences by section and CPT\n",
    "filtered_df1 = cpt_count_filter(note_cpt, note_cpt, 2, 10)\n",
    "\n",
    "# Show available sections\n",
    "print('Available sections:\\n\\n', set(filtered_df1['SECTIONHEADER']))\n",
    "\n",
    "# Filter to a set amount of CPT codes for each section header - only here to make the code run faster when testing\n",
    "filtered_df2 = cpt_per_section_filter(filtered_df1, 10, all_sections=True)\n",
    "\n",
    "# Filter to those CPT codes that have at least 100 notes or more\n",
    "filtered_df_cpt = filter_df(filtered_df2, 100)\n",
    "\n",
    "# Filter total number of CPT codes in the dataset by section\n",
    "# filtered_df_cpt = filter_cpt_ct(filtered_df_cpt, 'Evaluation and management', 3)\n",
    "\n",
    "# Show some dataset stats\n",
    "show_section_counts(filtered_df)\n",
    "show_cpt_counts_by_section(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-memorial",
   "metadata": {},
   "source": [
    "# Filter the Data - ICD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "spoken-alberta",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df_icd(df, threshold):\n",
    "\n",
    "    x = df['ICD9_CODE'].value_counts() > threshold\n",
    "    y = list(x[x == 1].index)\n",
    "\n",
    "    z = df[df['ICD9_CODE'].isin(y)]\n",
    "\n",
    "    return z\n",
    "\n",
    "def filter_icd_ct(df,ct):\n",
    "    top_codes = list(df['ICD9_CODE'].value_counts().head(ct).index)\n",
    "    df = df[df.ICD9_CODE.isin(top_codes)]\n",
    "    return df\n",
    "\n",
    "filtered_df_icd = filter_df_icd(note_icd, 100)\n",
    "# filtered_df_icd = filter_icd_ct(filtered_df_icd, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-september",
   "metadata": {},
   "source": [
    "# Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "unable-minimum",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amartins\\onedrive - intermountain healthcare\\python_pycharm_virt_env\\.venv\\lib\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "c:\\users\\amartins\\onedrive - intermountain healthcare\\python_pycharm_virt_env\\.venv\\lib\\site-packages\\pandas\\core\\indexing.py:692: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value, self.name)\n",
      "<ipython-input-56-20c3e3db6ba4>:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df_cpt['TEXT'] = clean_data(filtered_df_cpt['TEXT'], True)\n",
      "<ipython-input-56-20c3e3db6ba4>:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df_icd['TEXT'] = clean_data(filtered_df_icd['TEXT'], True)\n"
     ]
    }
   ],
   "source": [
    "def clean_data(text_series, remove_sections):\n",
    "  \n",
    "    # Remove topics\n",
    "    data = text_series.str.lower() # lowercase all letters\n",
    "    data = data.str.split(r'(\\n\\n)')\n",
    "    if remove_sections:\n",
    "        for row_num, value in enumerate(data):\n",
    "            text_chunks = [x.split(':', maxsplit=1) for x in value]\n",
    "            ls = []\n",
    "            for i, x in enumerate(text_chunks):\n",
    "                try:\n",
    "                    if x[0] != 'social history' or x[0] != 'family history' or 'medication' not in x[0]:\n",
    "                        ls.append(x[1])\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "            text_series.iloc[row_num] = ' '.join(ls)\n",
    "\n",
    "        \n",
    "    # Remove dates and locations\n",
    "    text_series = text_series.str.replace('\\[\\*\\*(.*?)\\*\\*\\]', ' ', regex=True)\n",
    "    \n",
    "    # Replace \\n \n",
    "    text_series = text_series.str.replace('\\\\n',' ', regex=True)  \n",
    "    \n",
    "    # Replace punctuation\n",
    "    text_series = text_series.str.replace('[' + string.punctuation + ']', ' ', regex=True)\n",
    "    \n",
    "    # Remove all digits\n",
    "    text_series = text_series.str.replace('\\d',' ', regex=True)\n",
    "    \n",
    "    # Replace plurals, endings with ing, endings with ed, endings with ly\n",
    "#     text_series = text_series.str.replace('s(?=\\s)', ' ', regex=True)\n",
    "#     text_series = text_series.str.replace('ing(?=\\s)', ' ', regex=True)\n",
    "#     text_series = text_series.str.replace('ed(?=\\s)', ' ', regex=True)\n",
    "#     text_series = text_series.str.replace('ly(?=\\s)', ' ', regex=True)\n",
    "    \n",
    "    return text_series\n",
    "\n",
    "# Update Text Column -----\n",
    "filtered_df_cpt['TEXT'] = clean_data(filtered_df_cpt['TEXT'], True)\n",
    "filtered_df_icd['TEXT'] = clean_data(filtered_df_icd['TEXT'], True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-mixer",
   "metadata": {},
   "source": [
    "# Label Encode the Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cooked-cloud",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "filtered_df['CPT_CD'] = le.fit_transform(filtered_df['CPT_CD'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "awful-strike",
   "metadata": {},
   "source": [
    "# Check the Counts for Each Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "amended-router",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94003    12871\n",
       "94002     8206\n",
       "99291     4758\n",
       "99232     2385\n",
       "99233     1924\n",
       "36556     1788\n",
       "99254     1170\n",
       "99231     1078\n",
       "99223     1035\n",
       "90935     1027\n",
       "99222      970\n",
       "99253      865\n",
       "99255      700\n",
       "36620      661\n",
       "99238      485\n",
       "31624      469\n",
       "76942      447\n",
       "33405      436\n",
       "76937      352\n",
       "31645      342\n",
       "31622      315\n",
       "90801      238\n",
       "62270      225\n",
       "31500      194\n",
       "01996      178\n",
       "99024      169\n",
       "90945      154\n",
       "90937      150\n",
       "36489      145\n",
       "32002      140\n",
       "93503      107\n",
       "Name: CPT_CD, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df_cpt['CPT_CD'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coupled-nerve",
   "metadata": {},
   "source": [
    "# Select CPT sections to Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "documented-coordinate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Surgery', 'Medicine', 'Radiology', 'Evaluation and management', 'Anesthesia']\n",
      "['Evaluation and management', 'Surgery', 'Medicine']\n"
     ]
    }
   ],
   "source": [
    "sections = list(set(filtered_df_cpt['SECTIONHEADER']))\n",
    "print(sections)\n",
    "sections = ['Evaluation and management', 'Surgery', 'Medicine']\n",
    "print(sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-devil",
   "metadata": {},
   "source": [
    "# Split the Data - CPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "double-islam",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_dict = {} \n",
    "\n",
    "def split_stratify_df(df, sections, combine_others=False, all_=False):\n",
    "    \n",
    "    # Train test split for each section selected\n",
    "    if all_:\n",
    "        sections.clear()\n",
    "    else:\n",
    "        for i in sections:\n",
    "            df_x = df[df['SECTIONHEADER'] == i]['TEXT'].values\n",
    "            df_y = df[df['SECTIONHEADER'] == i]['CPT_CD']\n",
    "            tt_dict['X_train_' + i], tt_dict['X_test_' + i], tt_dict['y_train_' + i], tt_dict['y_test_' + i], \\\n",
    "            tt_dict['index_train_' + i], tt_dict['index_test_' + i] = \\\n",
    "            train_test_split(df_x, df_y, range(len(df_y)), test_size = .3, random_state = 42, shuffle=True)\n",
    "        \n",
    "    # Group other sections not included in selection\n",
    "    if combine_others:\n",
    "        i = 'other'\n",
    "        other_sections = list(set(df['SECTIONHEADER']).difference(set(sections)))\n",
    "        sections.append(i)\n",
    "        df_x = df[df['SECTIONHEADER'].isin(other_sections)]['TEXT'].values\n",
    "        df_y = df[df['SECTIONHEADER'].isin(other_sections)]['CPT_CD']\n",
    "        tt_dict['X_train_' + i], tt_dict['X_test_' + i], tt_dict['y_train_' + i], tt_dict['y_test_' + i], \\\n",
    "        tt_dict['index_train_' + i], tt_dict['index_test_' + i] = \\\n",
    "        train_test_split(df_x, df_y, range(len(df_y)), test_size = .3, random_state = 42, shuffle=True)\n",
    "        \n",
    "        \n",
    "split_stratify_df(filtered_df_cpt, sections, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-witch",
   "metadata": {},
   "source": [
    "# Select ICD sections to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "exciting-circular",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Evaluation and management', 'Surgery', 'Medicine', 'other', 'icd']\n"
     ]
    }
   ],
   "source": [
    "sections.append('icd')\n",
    "# sections.append('other')\n",
    "print(sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-adobe",
   "metadata": {},
   "source": [
    "# Split the Data - ICD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "breathing-lithuania",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_dict['X_train_icd'], tt_dict['X_test_icd'] , tt_dict['y_train_icd'], tt_dict['y_test_icd'] = \\\n",
    "train_test_split(filtered_df_icd['TEXT'].values, filtered_df_icd['ICD9_CODE'], test_size = .3, random_state = 42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-removal",
   "metadata": {},
   "source": [
    "# Balance the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "quantitative-catalog",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation and management\n",
      "New Balanced Record Count per feature: 2580\n",
      "Surgery\n",
      "New Balanced Record Count per feature: 893\n",
      "Medicine\n",
      "New Balanced Record Count per feature: 7842\n",
      "other\n",
      "New Balanced Record Count per feature: 308\n",
      "icd\n",
      "New Balanced Record Count per feature: 785\n"
     ]
    }
   ],
   "source": [
    "def oversample_df(X_train, y_train, percentile):\n",
    "            \n",
    "    # Recombine the training dataset\n",
    "    x = pd.Series(X_train).reset_index(drop=True)\n",
    "    y = pd.Series(y_train).reset_index(drop=True)\n",
    "    training_df = pd.concat([x,y], axis=1, ignore_index=True)\n",
    "\n",
    "    # Check counts\n",
    "    df_cts = training_df.iloc[:,1].value_counts()\n",
    "    record_ct = round(np.percentile(df_cts, percentile))\n",
    "    print('New Balanced Record Count per feature: {}'.format(record_ct))\n",
    "    \n",
    "    # Create a list of CPT values\n",
    "    df = list(df_cts.index.values)\n",
    "\n",
    "    # Resample\n",
    "    minority_df = []\n",
    "    for i in df:\n",
    "        test_resampled = resample(training_df[training_df.iloc[:,1] == i], replace=True, n_samples=record_ct, random_state=123)\n",
    "        minority_df.append(test_resampled)\n",
    "    \n",
    "    # Create final dataframe\n",
    "    new_df = pd.concat(minority_df)\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "def balance(tt_dict, sections):\n",
    "    for section in sections:\n",
    "        print(section)\n",
    "        \n",
    "        # Running balance function\n",
    "        training_balanced = oversample_df(tt_dict['X_train_' + section], tt_dict['y_train_' + section] , 95)\n",
    "        \n",
    "        # Reassign balanced data\n",
    "        tt_dict['X_train_' + section] = np.array(training_balanced.iloc[:,0].values)\n",
    "        tt_dict['y_train_' + section] = np.array(training_balanced.iloc[:,1].values)\n",
    "\n",
    "# Run the functions\n",
    "balance(tt_dict, sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-comment",
   "metadata": {},
   "source": [
    "# Tokenize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "determined-waters",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stop words\n",
    "my_stop_words = list(set(stopwords.words('english'))) \\\n",
    "                + ['admission', 'date', 'sex'] \\\n",
    "                + ['needed', 'every', 'seen', 'weeks', 'please', 'ml', 'unit', 'small', 'year', 'old', 'cm', 'non', 'mm', 'however']\n",
    "                # Got the above from my top 100 most predictive words that I wanted to remove\n",
    "\n",
    "# Set Dictionary for vectorized words\n",
    "vectorized_words = {}\n",
    "\n",
    "# Import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=my_stop_words, max_df=.7, min_df = 2, sublinear_tf = True, ngram_range = (1, 2))\n",
    "    \n",
    "def vectorize_df(train_test_dict, tfidf_vectorizer, sections):\n",
    "\n",
    "    for section in sections:\n",
    "        \n",
    "        # Transform the training data\n",
    "        tfidf_train = tfidf_vectorizer.fit_transform(train_test_dict['X_train_' + section])\n",
    "\n",
    "        # Transform the test data\n",
    "        tfidf_test = tfidf_vectorizer.transform(train_test_dict['X_test_' + section])\n",
    "\n",
    "        # Add results to dictionary\n",
    "\n",
    "        vectorized_words['tfidf_train_' + section] = tfidf_train\n",
    "        vectorized_words['tfidf_test_' + section] = tfidf_test\n",
    "        vectorized_words['tfidf_vectorizer' + section] = tfidf_vectorizer \n",
    "\n",
    "vectorize_df(tt_dict, tfidf_vectorizer, ['Surgery'])   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-grenada",
   "metadata": {},
   "source": [
    "# Run Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cultural-india",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_nb = {}\n",
    "\n",
    "def run_clf(vectorized_words, train_test_dict, sections):\n",
    "\n",
    "    # Fit and check accuracy\n",
    "    for section in sections:\n",
    "        \n",
    "        # Use Naive Bayes model\n",
    "        nb_classifier = MultinomialNB()\n",
    "        \n",
    "        # Fit model\n",
    "        nb_classifier.fit(vectorized_words['tfidf_train_' + section], train_test_dict['y_train_' + section])\n",
    "        \n",
    "        # Save in dictionary\n",
    "        models_nb[section] = nb_classifier\n",
    "    \n",
    "run_clf(vectorized_words, tt_dict, ['other'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-surgery",
   "metadata": {},
   "source": [
    "# Run Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "early-three",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "models_tree = {}\n",
    "\n",
    "def run_clf(vectorized_words, train_test_dict, sections):\n",
    "\n",
    "    # Fit and check accuracy\n",
    "    for section in sections:\n",
    "        \n",
    "        # Use Naive Bayes model\n",
    "        clf = DecisionTreeClassifier(random_state=123)\n",
    "        \n",
    "        # Fit model\n",
    "        clf.fit(vectorized_words['tfidf_train_' + section], train_test_dict['y_train_' + section])\n",
    "        \n",
    "        # Save in dictionary\n",
    "        models_tree[section] = clf\n",
    "    \n",
    "run_clf(vectorized_words, tt_dict, ['other'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-portugal",
   "metadata": {},
   "source": [
    "# Run Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "sustainable-shopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "models_rf = {}\n",
    "\n",
    "def run_clf(vectorized_words, train_test_dict, sections):\n",
    "\n",
    "    # Fit and check accuracy\n",
    "    for section in sections:\n",
    "        \n",
    "        # Use Naive Bayes model\n",
    "        clf = RandomForestClassifier(random_state=123)\n",
    "        \n",
    "        # Fit model\n",
    "        clf.fit(vectorized_words['tfidf_train_' + section], train_test_dict['y_train_' + section])\n",
    "        \n",
    "        # Save in dictionary\n",
    "        models_rf[section] = clf\n",
    "    \n",
    "run_clf(vectorized_words, tt_dict, ['other'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-islam",
   "metadata": {},
   "source": [
    "# Run Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "traditional-distribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "models_xg = {}\n",
    "\n",
    "def run_clf(vectorized_words, train_test_dict, sections):\n",
    "\n",
    "    # Fit and check accuracy\n",
    "    for section in sections:\n",
    "        \n",
    "        # Use Naive Bayes model\n",
    "        clf = GradientBoostingClassifier(random_state=123)\n",
    "        \n",
    "        # Fit model\n",
    "        clf.fit(vectorized_words['tfidf_train_' + section], train_test_dict['y_train_' + section])\n",
    "        \n",
    "        # Save in dictionary\n",
    "        models_xg[section] = clf\n",
    "    \n",
    "run_clf(vectorized_words, tt_dict, ['other'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-compromise",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "stainless-opinion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "models_knn = {}\n",
    "\n",
    "def run_clf(vectorized_words, train_test_dict, sections):\n",
    "\n",
    "    # Fit and check accuracy\n",
    "    for section in sections:\n",
    "        \n",
    "        # Use Naive Bayes model\n",
    "        clf = KNeighborsClassifier()\n",
    "        \n",
    "        # Fit model\n",
    "        clf.fit(vectorized_words['tfidf_train_' + section], train_test_dict['y_train_' + section])\n",
    "        \n",
    "        # Save in dictionary\n",
    "        models_knn[section] = clf\n",
    "    \n",
    "run_clf(vectorized_words, tt_dict, ['other'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-census",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "beginning-section",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "models_lr = {}\n",
    "\n",
    "def run_clf(vectorized_words, train_test_dict, sections):\n",
    "\n",
    "    # Fit and check accuracy\n",
    "    for section in sections:\n",
    "        \n",
    "        # Use Naive Bayes model\n",
    "        clf = LogisticRegression(random_state=123, C=1, max_iter=25, solver='sag', n_jobs=-1)\n",
    "        \n",
    "        # Fit model\n",
    "        clf.fit(vectorized_words['tfidf_train_' + section], train_test_dict['y_train_' + section])\n",
    "        \n",
    "        # Save in dictionary\n",
    "        models_lr[section] = clf\n",
    "    \n",
    "run_clf(vectorized_words, tt_dict, sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-detective",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "forty-treaty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Evaluation and management': LogisticRegression(C=1, max_iter=25, n_jobs=-1, random_state=123, solver='sag'), 'Surgery': LogisticRegression(C=1, max_iter=25, n_jobs=-1, random_state=123, solver='sag'), 'Medicine': LogisticRegression(C=1, max_iter=25, n_jobs=-1, random_state=123, solver='sag'), 'other': LogisticRegression(C=1, max_iter=25, n_jobs=-1, random_state=123, solver='sag'), 'icd': LogisticRegression(C=1, max_iter=25, n_jobs=-1, random_state=123, solver='sag')}\n",
      "Evaluation and management\n",
      "0.21058338755150727\n",
      "Surgery\n",
      "0.47491166077738517\n",
      "Medicine\n",
      "0.8240511851097863\n",
      "other\n",
      "0.7959183673469388\n",
      "icd\n",
      "0.6199056199056199\n"
     ]
    }
   ],
   "source": [
    "# models_ls = [models_nb, models_rf, models_xg, models_knn, models_lr, models_tree]\n",
    "models_ls = [models_lr]\n",
    "\n",
    "# Check accuracy\n",
    "def predictions(tt_dict, models, section=[]):\n",
    "    for key, model in models.items():\n",
    "        if len(section) == 0 or key == section:\n",
    "            pred = model.predict(vectorized_words['tfidf_test_' + key])\n",
    "            print(key)\n",
    "            print(metrics.accuracy_score(tt_dict['y_test_' + key], pred))\n",
    "\n",
    "for model in models_ls:\n",
    "    print(str(model))\n",
    "    predictions(tt_dict, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-kenya",
   "metadata": {},
   "source": [
    "# Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "useful-strand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'tfidf_test_other'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-116-ec1d24171b5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'other'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels_ls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msection\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectorized_words\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tfidf_test_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msection\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtt_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y_test_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msection\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'tfidf_test_other'"
     ]
    }
   ],
   "source": [
    "# Create classification report taken from here: https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568\n",
    "print('Test')\n",
    "section = 'other'\n",
    "pred = models_ls[0][section].predict(vectorized_words['tfidf_test_' + section])\n",
    "print(classification_report(tt_dict['y_test_' + section], pred))\n",
    "\n",
    "# print('Training')\n",
    "# pred_x = nb_classifier.predict(vectorized_words['tfidf_train'])\n",
    "# print(classification_report(tt_dict['y_train_' + section], pred_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-lawyer",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning - Grid Search - LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cultural-metallic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n",
      "Best parameters set:\n",
      "[('tfidf', TfidfVectorizer(stop_words=['as', 'this', 'during', 'up', 'than', 'what', 'had',\n",
      "                            'wouldn', 'shan', 'm', 'ours', 'y', 'how', 'you',\n",
      "                            'of', 'further', 'while', 'if', 'can', 'off',\n",
      "                            'some', 'whom', 'shouldn', 'any', 'that', 'your',\n",
      "                            't', 'does', 'after', 'below', ...])), ('clf', LogisticRegression(C=1, max_iter=25, random_state=123))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amartins\\onedrive - intermountain healthcare\\python_pycharm_virt_env\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Define stop words\n",
    "my_stop_words = list(set(stopwords.words('english'))) \\\n",
    "                + ['admission', 'date', 'sex'] \\\n",
    "                + ['needed', 'every', 'seen', 'weeks', 'please', 'ml', 'unit', 'small', 'year', 'old', 'cm', 'non', 'mm', 'however']\n",
    "                # Got the above from my top 100 most predictive words that I wanted to remove\n",
    "\n",
    "# Taken from: https://stackoverflow.com/questions/44066264/how-to-choose-parameters-in-tfidfvectorizer-in-sklearn-during-unsupervised-clust/44080802\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=my_stop_words)),\n",
    "    ('clf', LogisticRegression(random_state=123)),\n",
    "])\n",
    "parameters = {\n",
    "#     'tfidf__max_df': (.15,.2,.25,.3) # .2 is the best param\n",
    "#     , 'tfidf__sublinear_tf' : (True, False) # True\n",
    "#     'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)], # (1,2) is best\n",
    "#     'clf__alpha': (0.001, .01) # .001 is best\n",
    "    \n",
    "#     'tfidf__max_df': (.2,.5,.7) # .7 is the best param\n",
    "#     , 'tfidf__ngram_range': [(1, 1), (1, 2)] # (1,2) is best\n",
    "#     , 'tfidf__min_df': (1,2,3) # 2 is the best\n",
    "#     , 'clf__alpha': (0.001, .01, .1,.5) # .001 is best\n",
    "    'clf__C': (.8,.9,1) # 1\n",
    "#     , 'clf__solver': ('liblinear', 'sag', 'saga') # sag\n",
    "    , 'clf__max_iter': (25,40,50) # 25\n",
    "   \n",
    "}\n",
    "\n",
    "grid_search_tune = GridSearchCV(pipeline, parameters, cv=2, n_jobs=-1, verbose=3, scoring='accuracy')\n",
    "grid_search_tune.fit(tt_dict['X_train_other'], tt_dict['y_train_other'])\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search_tune.best_estimator_.steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "african-award",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning - Grid Search - NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-tunnel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stop words\n",
    "my_stop_words = list(set(stopwords.words('english'))) \\\n",
    "                + ['admission', 'date', 'sex'] \\\n",
    "                + ['needed', 'every', 'seen', 'weeks', 'please', 'ml', 'unit', 'small', 'year', 'old', 'cm', 'non', 'mm', 'however']\n",
    "                # Got the above from my top 100 most predictive words that I wanted to remove\n",
    "\n",
    "# Taken from: https://stackoverflow.com/questions/44066264/how-to-choose-parameters-in-tfidfvectorizer-in-sklearn-during-unsupervised-clust/44080802\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=my_stop_words)),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "parameters = {\n",
    "#     'tfidf__max_df': (.15,.2,.25,.3) # .2 is the best param\n",
    "#     , 'tfidf__sublinear_tf' : (True, False) # True\n",
    "#     'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)], # (1,2) is best\n",
    "#     'clf__alpha': (0.001, .01) # .001 is best\n",
    "    \n",
    "    'tfidf__max_df': (.2,.5,.7) # .7 is the best param\n",
    "    , 'tfidf__ngram_range': [(1, 1), (1, 2)] # (1,2) is best\n",
    "    , 'tfidf__min_df': (1,2,3) # 2 is the best\n",
    "    , 'clf__alpha': (0.001, .01, .1,.5) # .001 is best\n",
    "   \n",
    "}\n",
    "\n",
    "grid_search_tune = GridSearchCV(pipeline, parameters, cv=2, n_jobs=-1, verbose=3, scoring='accuracy')\n",
    "grid_search_tune.fit(tt_dict['X_train_other'], tt_dict['y_train_other'])\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search_tune.best_estimator_.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "confident-dance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9090909090909092\n"
     ]
    }
   ],
   "source": [
    "best_result = grid_search_tune.best_score_\n",
    "print(best_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-mining",
   "metadata": {},
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "similar-senator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['36620'] 15.53%\n",
      "[0.06305929 0.14101228 0.10888526 0.14560006 0.09102712 0.02977054\n",
      " 0.1164756  0.08330722 0.15525441 0.06560823]\n"
     ]
    }
   ],
   "source": [
    "def predict_cpt(text):\n",
    "    input_text_clean = clean_data(pd.Series(text), False)\n",
    "    tfidf_input_test = tfidf_vectorizer.transform(input_text_clean)\n",
    "    models_ls[0]['Surgery'].predict(tfidf_input_test)\n",
    "    print(models_ls[0]['Surgery'].predict(tfidf_input_test), str(round(max(models_ls[0]['Surgery'].predict_proba(tfidf_input_test)[0]) * 100,2)) + '%')\n",
    "    print(models_ls[0]['Surgery'].predict_proba(tfidf_input_test)[0])\n",
    "          \n",
    "text_cpt = ''\n",
    "predict_cpt(text_cpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-swing",
   "metadata": {},
   "source": [
    "# Look at the Most Predictive Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-extension",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes\n",
    "# sum([np.exp(1)** x for x in nb_classifier.coef_[0]]) # The probability of all the words equals one\n",
    "# # Taken from here: * https://stackoverflow.com/questions/61586946/how-to-calculate-feature-log-prob-in-the-naive-bayes-multinomialnb\n",
    "\n",
    "# ------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_feature_rank(tfidf_vectorizer, y_no, nb_classifier):\n",
    "    \n",
    "    # Get the feature names\n",
    "    feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "    # Zip together the first CPT weights with feature names\n",
    "    feat_with_weights =  sorted(zip(nb_classifier.coef_[y_no], feature_names))\n",
    "    \n",
    "    # Print words most responsible for the prediction\n",
    "#     print('Top 100 \\n\\n\\n\\n')\n",
    "#     top_100_ls = []\n",
    "    for i in range(100):\n",
    "        x = feat_with_weights[-i-1]\n",
    "#         top_100_ls.append(x[1])\n",
    "#         print(nb_classifier.classes_[y_no], i, round((np.exp(1) ** x[0]),4), x[1])\n",
    "\n",
    "#     print('\\n\\n\\n\\n Bottom 100 \\n\\n\\n\\n')\n",
    "    for i in range(100):\n",
    "        x = feat_with_weights[i]\n",
    "#         print(nb_classifier.classes_[y_no], i, round((np.exp(1) ** x[0]),4), x[1])\n",
    "    \n",
    "#     min_weight = min([i[0] for i in feat_with_weights])\n",
    "    \n",
    "    x = [i[0] for i in feat_with_weights]\n",
    "    \n",
    "    median_pred = np.median(x)\n",
    "          \n",
    "    return [i[1] for i in feat_with_weights if i[0] <= median_pred] # Minimum weight words\n",
    "#     return top_100_ls\n",
    "\n",
    "# Find the least predictive words\n",
    "def least_pred_words(nb_classifier, tfidf_vectorizer):\n",
    "    low_wt_stop_ls = []\n",
    "\n",
    "    for i in range(len(nb_classifier.classes_)):\n",
    "        low_wt_stop_ls += get_feature_rank(tfidf_vectorizer, i, nb_classifier)\n",
    "\n",
    "    low_wt_stop_ls = list(set(low_wt_stop_ls))\n",
    "    return low_wt_stop_ls\n",
    "    \n",
    "low_wt_stop_ls = least_pred_words(nb_classifier, tfidf_vectorizer)\n",
    "\n",
    "# Find top 100 words - doesn't seem to improve the model\n",
    "def highest_pred_words(nb_classifier, tfidf_vectorizer):\n",
    "    top_100_ls = []\n",
    "    for i in range(len(nb_classifier.classes_)):\n",
    "        top_100_ls += get_feature_rank(tfidf_vectorizer, i, nb_classifier)\n",
    "\n",
    "    top_100_ls = list(set(top_100_ls))\n",
    "    return top_100_ls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

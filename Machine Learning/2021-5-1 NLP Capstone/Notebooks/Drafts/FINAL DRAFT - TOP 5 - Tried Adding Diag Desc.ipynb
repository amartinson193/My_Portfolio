{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "expired-sharing",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "answering-retro",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import glob\n",
    "import string\n",
    "from sklearn.utils import resample\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-alabama",
   "metadata": {},
   "source": [
    "\n",
    "# Import the MIMIC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "environmental-character",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amartins\\onedrive - intermountain healthcare\\python_pycharm_virt_env\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (4,5,7,11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "c:\\users\\amartins\\onedrive - intermountain healthcare\\python_pycharm_virt_env\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (4,5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "dataset_dictionary = {}\n",
    "\n",
    "for file_path in glob.glob('..\\\\Data\\\\MIMIC Files\\*'):\n",
    "    file_name = file_path.split('\\\\')[3].split('.')[0]\n",
    "    with gzip.open(file_path, mode='r') as file:\n",
    "        dataset_dictionary[file_name] = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-literature",
   "metadata": {},
   "source": [
    "# Assign Datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "delayed-moscow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['CPTEVENTS', 'DIAGNOSES_ICD', 'D_CPT', 'D_ICD_DIAGNOSES', 'D_ICD_PROCEDURES', 'NOTEEVENTS', 'PATIENTS', 'PROCEDURES_ICD'])\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 573146 entries, 0 to 573145\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   ROW_ID            573146 non-null  int64  \n",
      " 1   SUBJECT_ID        573146 non-null  int64  \n",
      " 2   HADM_ID           573146 non-null  int64  \n",
      " 3   COSTCENTER        573146 non-null  object \n",
      " 4   CHARTDATE         101545 non-null  object \n",
      " 5   CPT_CD            573146 non-null  object \n",
      " 6   CPT_NUMBER        573128 non-null  float64\n",
      " 7   CPT_SUFFIX        22 non-null      object \n",
      " 8   TICKET_ID_SEQ     471601 non-null  float64\n",
      " 9   SECTIONHEADER     573125 non-null  object \n",
      " 10  SUBSECTIONHEADER  573125 non-null  object \n",
      " 11  DESCRIPTION       101545 non-null  object \n",
      "dtypes: float64(2), int64(3), object(7)\n",
      "memory usage: 52.5+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 651047 entries, 0 to 651046\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   ROW_ID      651047 non-null  int64  \n",
      " 1   SUBJECT_ID  651047 non-null  int64  \n",
      " 2   HADM_ID     651047 non-null  int64  \n",
      " 3   SEQ_NUM     651000 non-null  float64\n",
      " 4   ICD9_CODE   651000 non-null  object \n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 24.8+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 134 entries, 0 to 133\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   ROW_ID               134 non-null    int64 \n",
      " 1   CATEGORY             134 non-null    int64 \n",
      " 2   SECTIONRANGE         134 non-null    object\n",
      " 3   SECTIONHEADER        134 non-null    object\n",
      " 4   SUBSECTIONRANGE      134 non-null    object\n",
      " 5   SUBSECTIONHEADER     134 non-null    object\n",
      " 6   CODESUFFIX           11 non-null     object\n",
      " 7   MINCODEINSUBSECTION  134 non-null    int64 \n",
      " 8   MAXCODEINSUBSECTION  134 non-null    int64 \n",
      "dtypes: int64(4), object(5)\n",
      "memory usage: 9.5+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14567 entries, 0 to 14566\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   ROW_ID       14567 non-null  int64 \n",
      " 1   ICD9_CODE    14567 non-null  object\n",
      " 2   SHORT_TITLE  14567 non-null  object\n",
      " 3   LONG_TITLE   14567 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 455.3+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3882 entries, 0 to 3881\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   ROW_ID       3882 non-null   int64 \n",
      " 1   ICD9_CODE    3882 non-null   int64 \n",
      " 2   SHORT_TITLE  3882 non-null   object\n",
      " 3   LONG_TITLE   3882 non-null   object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 121.4+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2083180 entries, 0 to 2083179\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Dtype  \n",
      "---  ------       -----  \n",
      " 0   ROW_ID       int64  \n",
      " 1   SUBJECT_ID   int64  \n",
      " 2   HADM_ID      float64\n",
      " 3   CHARTDATE    object \n",
      " 4   CHARTTIME    object \n",
      " 5   STORETIME    object \n",
      " 6   CATEGORY     object \n",
      " 7   DESCRIPTION  object \n",
      " 8   CGID         float64\n",
      " 9   ISERROR      float64\n",
      " 10  TEXT         object \n",
      "dtypes: float64(3), int64(2), object(6)\n",
      "memory usage: 174.8+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 46520 entries, 0 to 46519\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   ROW_ID       46520 non-null  int64 \n",
      " 1   SUBJECT_ID   46520 non-null  int64 \n",
      " 2   GENDER       46520 non-null  object\n",
      " 3   DOB          46520 non-null  object\n",
      " 4   DOD          15759 non-null  object\n",
      " 5   DOD_HOSP     9974 non-null   object\n",
      " 6   DOD_SSN      13378 non-null  object\n",
      " 7   EXPIRE_FLAG  46520 non-null  int64 \n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 2.8+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 240095 entries, 0 to 240094\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count   Dtype\n",
      "---  ------      --------------   -----\n",
      " 0   ROW_ID      240095 non-null  int64\n",
      " 1   SUBJECT_ID  240095 non-null  int64\n",
      " 2   HADM_ID     240095 non-null  int64\n",
      " 3   SEQ_NUM     240095 non-null  int64\n",
      " 4   ICD9_CODE   240095 non-null  int64\n",
      "dtypes: int64(5)\n",
      "memory usage: 9.2 MB\n",
      "None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'to_datetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-1384668da6e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# CPTEVENTS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mdataset_dictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CPTEVENTS'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SECTIONHEADER'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'CPT_CD'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_dictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CPTEVENTS'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SECTIONHEADER'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'CPT_CD'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mdataset_dictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CPTEVENTS'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CHARTDATE'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_dictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CPTEVENTS'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CHARTDATE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\amartins\\onedrive - intermountain healthcare\\python_pycharm_virt_env\\.venv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5460\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5461\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5462\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5464\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'to_datetime'"
     ]
    }
   ],
   "source": [
    "# Check all the datasets exist in the dictionary \n",
    "print(dataset_dictionary.keys())\n",
    "\n",
    "# Check the datatypes and information for each table \n",
    "for i in dataset_dictionary.keys():\n",
    "    print(dataset_dictionary[i].info())\n",
    "\n",
    "# Correct any datatype issues #####\n",
    "\n",
    "# CPTEVENTS\n",
    "dataset_dictionary['CPTEVENTS'].loc[:,['SECTIONHEADER','CPT_CD']] = dataset_dictionary['CPTEVENTS'].loc[:,['SECTIONHEADER','CPT_CD']].astype(str)\n",
    "dataset_dictionary['CPTEVENTS']['CHARTDATE'] = dataset_dictionary['CPTEVENTS']['CHARTDATE'].to_datetime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "north-comfort",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14567\n",
      "14567\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>ICD9_CODE</th>\n",
       "      <th>SHORT_TITLE</th>\n",
       "      <th>LONG_TITLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174</td>\n",
       "      <td>01166</td>\n",
       "      <td>TB pneumonia-oth test</td>\n",
       "      <td>Tuberculous pneumonia [any form], tubercle bac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>175</td>\n",
       "      <td>01170</td>\n",
       "      <td>TB pneumothorax-unspec</td>\n",
       "      <td>Tuberculous pneumothorax, unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>176</td>\n",
       "      <td>01171</td>\n",
       "      <td>TB pneumothorax-no exam</td>\n",
       "      <td>Tuberculous pneumothorax, bacteriological or h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>177</td>\n",
       "      <td>01172</td>\n",
       "      <td>TB pneumothorx-exam unkn</td>\n",
       "      <td>Tuberculous pneumothorax, bacteriological or h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>178</td>\n",
       "      <td>01173</td>\n",
       "      <td>TB pneumothorax-micro dx</td>\n",
       "      <td>Tuberculous pneumothorax, tubercle bacilli fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14562</th>\n",
       "      <td>14432</td>\n",
       "      <td>V7399</td>\n",
       "      <td>Scrn unspcf viral dis</td>\n",
       "      <td>Special screening examination for unspecified ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14563</th>\n",
       "      <td>14433</td>\n",
       "      <td>V740</td>\n",
       "      <td>Screening for cholera</td>\n",
       "      <td>Screening examination for cholera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14564</th>\n",
       "      <td>14434</td>\n",
       "      <td>V741</td>\n",
       "      <td>Screening-pulmonary TB</td>\n",
       "      <td>Screening examination for pulmonary tuberculosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14565</th>\n",
       "      <td>14435</td>\n",
       "      <td>V742</td>\n",
       "      <td>Screening for leprosy</td>\n",
       "      <td>Screening examination for leprosy (Hansen's di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14566</th>\n",
       "      <td>14436</td>\n",
       "      <td>V743</td>\n",
       "      <td>Screening for diphtheria</td>\n",
       "      <td>Screening examination for diphtheria</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14567 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ROW_ID ICD9_CODE               SHORT_TITLE  \\\n",
       "0         174     01166     TB pneumonia-oth test   \n",
       "1         175     01170    TB pneumothorax-unspec   \n",
       "2         176     01171   TB pneumothorax-no exam   \n",
       "3         177     01172  TB pneumothorx-exam unkn   \n",
       "4         178     01173  TB pneumothorax-micro dx   \n",
       "...       ...       ...                       ...   \n",
       "14562   14432     V7399     Scrn unspcf viral dis   \n",
       "14563   14433      V740     Screening for cholera   \n",
       "14564   14434      V741    Screening-pulmonary TB   \n",
       "14565   14435      V742     Screening for leprosy   \n",
       "14566   14436      V743  Screening for diphtheria   \n",
       "\n",
       "                                              LONG_TITLE  \n",
       "0      Tuberculous pneumonia [any form], tubercle bac...  \n",
       "1                  Tuberculous pneumothorax, unspecified  \n",
       "2      Tuberculous pneumothorax, bacteriological or h...  \n",
       "3      Tuberculous pneumothorax, bacteriological or h...  \n",
       "4      Tuberculous pneumothorax, tubercle bacilli fou...  \n",
       "...                                                  ...  \n",
       "14562  Special screening examination for unspecified ...  \n",
       "14563                  Screening examination for cholera  \n",
       "14564   Screening examination for pulmonary tuberculosis  \n",
       "14565  Screening examination for leprosy (Hansen's di...  \n",
       "14566               Screening examination for diphtheria  \n",
       "\n",
       "[14567 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------\n",
    "    # -- QA\n",
    "# ------------------\n",
    "\n",
    "# Check that the ICD9 code column is distinct\n",
    "print(len(set(dataset_dictionary['D_ICD_DIAGNOSES']['ICD9_CODE'])))\n",
    "print(len(dataset_dictionary['D_ICD_DIAGNOSES']))\n",
    "\n",
    "dataset_dictionary['D_ICD_DIAGNOSES']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-desert",
   "metadata": {},
   "source": [
    "# Join the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "grateful-tracker",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-146-8906be543787>:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  note_cpt_add['TEXT'] = note_cpt_add['TEXT'] + ' ' + note_cpt_add['LONG_TITLE']\n"
     ]
    }
   ],
   "source": [
    "def join_tables(dataset_dictionary, category=['Discharge summary'], all_notes=False):\n",
    "\n",
    "    # Define tables\n",
    "    note_events_base = dataset_dictionary['NOTEEVENTS']\n",
    "    cpt_events_base = dataset_dictionary['CPTEVENTS']\n",
    "    icd_events_base = dataset_dictionary['DIAGNOSES_ICD']\n",
    "    icd_detail_base = dataset_dictionary['D_ICD_DIAGNOSES'].loc[:,['ICD9_CODE', 'LONG_TITLE']]\n",
    "\n",
    "    # Combine text for each subject and encounter\n",
    "    if all_notes == False:\n",
    "        note_events_base = note_events_base[note_events_base.loc[:,'CATEGORY'].isin(category)]\n",
    "    \n",
    "    # Filter out the addendums and restrict notes only to reports\n",
    "    note_events_base = note_events_base[note_events_base['DESCRIPTION'] == 'Report']\n",
    "    \n",
    "    # Aggregate text by Subject and HADM ID's\n",
    "    note_events = note_events_base.groupby(['SUBJECT_ID', 'HADM_ID'], as_index=False)['TEXT'].agg(sum)\n",
    "    \n",
    "    # Create CPT table\n",
    "    cpt_events_base = cpt_events_base.loc[:, ['SUBJECT_ID','HADM_ID', 'CPT_CD', 'SECTIONHEADER', 'DESCRIPTION']]\n",
    "    cpt_events = cpt_events_base.drop_duplicates()\n",
    "    \n",
    "    # Create ICD table\n",
    "    icd_events_base = icd_events_base[icd_events_base['SEQ_NUM'] == 1]\n",
    "    icd_events_base = icd_events_base.loc[:, ['SUBJECT_ID','HADM_ID', 'ICD9_CODE']]\n",
    "    icd_events = icd_events_base.drop_duplicates()\n",
    "    \n",
    "    # Join the datasets\n",
    "    note_cpt = note_events.merge(cpt_events, on = ['SUBJECT_ID','HADM_ID'])\\\n",
    "                          .merge(icd_events, on = ['SUBJECT_ID', 'HADM_ID'])\\\n",
    "                          .merge(icd_detail_base, on = 'ICD9_CODE')\n",
    "    note_icd = note_events.merge(icd_events, on = ['SUBJECT_ID', 'HADM_ID'])\\\n",
    "                          .merge(icd_detail_base, on = 'ICD9_CODE')\n",
    "    \n",
    "    # CPT - Replace any nulls with blanks\n",
    "    x = note_cpt[note_cpt['DESCRIPTION'].isnull()].copy()\n",
    "    x.loc[:,'DESCRIPTION'] = ''\n",
    "    y = note_cpt[note_cpt['DESCRIPTION'].notnull()].copy()\n",
    "    note_cpt = pd.concat([x,y])\n",
    "    \n",
    "    # CPT - Combine description and text columns\n",
    "    note_cpt['TEXT'] = note_cpt['TEXT'] + note_cpt['DESCRIPTION']\n",
    "    note_cpt = note_cpt.drop('DESCRIPTION', axis=1)\n",
    "    \n",
    "    # CPT - Combine ICD description with text for specific sections\n",
    "    ls_to_add = ['Anesthesia','Pathology and laboratory', 'Radiology']\n",
    "    ls_to_keep = list(set(note_cpt['SECTIONHEADER']).difference(set(ls_to_add)))\n",
    "    \n",
    "    note_cpt_add = note_cpt[note_cpt.SECTIONHEADER.isin(ls_to_add)]\n",
    "    note_cpt_keep = note_cpt[note_cpt.SECTIONHEADER.isin(ls_to_keep)]\n",
    "    note_cpt_add['TEXT'] = note_cpt_add['TEXT'] + ' ' + note_cpt_add['LONG_TITLE']\n",
    "    note_cpt = pd.concat([note_cpt_add, note_cpt_keep])\n",
    "        \n",
    "    return note_cpt, note_icd\n",
    "\n",
    "# Run the function\n",
    "note_cpt, note_icd = join_tables(dataset_dictionary)\n",
    "\n",
    "# Drop notes with the nan sectionheader\n",
    "drop_ls = note_cpt[note_cpt['SECTIONHEADER'] == 'nan']\n",
    "note_cpt = note_cpt.drop(drop_ls.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "supported-baker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICD - Update column names\n",
    "note_icd.columns = ['SUBJECT_ID', 'HADM_ID', 'CLINICAL_TEXT', 'ICD9_CODE', 'TEXT']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-dealing",
   "metadata": {},
   "source": [
    "# Filter the data - CPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "pursuant-thumbnail",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(combined_df, threshold):\n",
    "\n",
    "    # Print value counts original\n",
    "    print('Value Counts for the original data:\\n\\n', combined_df['CPT_CD'].value_counts().head(25))\n",
    "\n",
    "    # Filter based on count limit\n",
    "    df = combined_df['CPT_CD'].value_counts()\n",
    "    filtered_ls = list((df[df >= threshold]).index.values)\n",
    "    filtered_df = combined_df[combined_df['CPT_CD'].isin(filtered_ls)]\n",
    "    \n",
    "    # Print value counts filtered\n",
    "    print('Value Counts for the filtered data:\\n\\n', combined_df['CPT_CD'].value_counts().head(25))\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "# Find Counts of CPT Codes per Patient Encounter and filter df\n",
    "def cpt_count_filter(df, og_df, cpt_section_hadm_limit, cpt_hadm_limit):\n",
    "    \n",
    "    # Filter based on limit per SECTIONHEADER & merge\n",
    "    df1 = og_df.groupby(['HADM_ID', 'SECTIONHEADER'])['CPT_CD'].count()\n",
    "    filtered_encntrs = df1[df1 <= cpt_section_hadm_limit]\n",
    "    final_df = df.merge(filtered_encntrs, on=['HADM_ID', 'SECTIONHEADER'])\n",
    "    final_df.drop('CPT_CD_y', axis=1, inplace=True)\n",
    "    \n",
    "    # Filter dataset again based on total number of CPT codes per HADM\n",
    "    df2 = og_df.groupby(['HADM_ID'])['CPT_CD'].count()\n",
    "    filtered_encntrs = df2[df2 <= cpt_hadm_limit]\n",
    "    final_df = final_df.merge(filtered_encntrs, on=['HADM_ID'])\n",
    "    final_df.drop('CPT_CD', axis=1, inplace=True)\n",
    "    \n",
    "    # Rename columns\n",
    "    final_df.columns = ['SUBJECT_ID', 'HADM_ID', 'TEXT', 'CPT_CD', 'SECTIONHEADER', 'ICD9_CODE', 'LONG_TITLE']\n",
    "    \n",
    "    print('Value Counts for the filtered data:\\n\\n', final_df['CPT_CD'].value_counts().head(50))\n",
    "\n",
    "    return final_df\n",
    "    \n",
    "# Filter DataFrame to a set amount of CPT codes in each section header #####\n",
    "def cpt_per_section_filter(df, section_limit, sections=['Emerging technology'], all_sections=False):\n",
    "    \n",
    "    # Create list for dataframes\n",
    "    df_ls = []\n",
    "\n",
    "    # Group by and count the number of CPT codes\n",
    "    cts_by_cpt = df.groupby(['SECTIONHEADER', 'CPT_CD'])['CPT_CD'].count()\n",
    "    cts_by_cpt.index.names = ['SECTIONHEADER', 'CPT_CDS']\n",
    "    cts_by_cpt = cts_by_cpt.reset_index()\n",
    "    cts_by_cpt.columns = ['SECTIONHEADER', 'CPT_CD', 'COUNT']\n",
    "\n",
    "    # Sort values by section and CPT code count\n",
    "    cts_by_cpt_s = cts_by_cpt.sort_values(by=['SECTIONHEADER','COUNT'], ascending=False)\n",
    "\n",
    "    # Filter based on the limit of CPT codes wanted for each category\n",
    "    if all_sections == True:\n",
    "        sections = list(set(df['SECTIONHEADER']))\n",
    "        \n",
    "    for i in sections:\n",
    "        top_cts = cts_by_cpt_s[cts_by_cpt_s['SECTIONHEADER'] == i].iloc[:section_limit,:]\n",
    "\n",
    "        # Append to list\n",
    "        df_ls.append(top_cts)\n",
    "\n",
    "    # Combine DataFrames\n",
    "    df_combo = pd.concat(df_ls)\n",
    "\n",
    "    # Join back to source data\n",
    "    final_df = df.merge(df_combo, on=['SECTIONHEADER','CPT_CD'])\n",
    "    \n",
    "    print('\\nThe length of the initial dataset was {} and the new dataset is {}\\n\\n'.format(len(df), len(final_df)))\n",
    "\n",
    "    return final_df\n",
    "\n",
    "def show_section_counts(df):\n",
    "    # Print count of CPT codes by section\n",
    "    cts_by_cpt = df.groupby(['SECTIONHEADER', 'CPT_CD'])['CPT_CD'].count()\n",
    "    cts_by_section = cts_by_cpt.groupby('SECTIONHEADER').count()\n",
    "    print('\\nHere are the counts by section:\\n\\n', cts_by_section)\n",
    "\n",
    "def show_cpt_counts_by_section(df):\n",
    "    cts_by_cpt = df.groupby(['SECTIONHEADER', 'CPT_CD'])['CPT_CD'].count()\n",
    "    print('\\nHere are the counts by CPT by section\\n\\n:')\n",
    "#     print(pd.DataFrame(cts_by_cpt.rename('Count')).reset_index())\n",
    "    for i, x in pd.DataFrame(cts_by_cpt.rename('Count')).reset_index().iterrows():\n",
    "        print(x['SECTIONHEADER'], x['CPT_CD'], x['Count'])\n",
    "        \n",
    "def filter_cpt_ct(df, section, ct):\n",
    "    df = df[df['SECTIONHEADER'] == section]\n",
    "    top_codes = list(df['CPT_CD'].value_counts().head(ct).index)\n",
    "    df = df[df.CPT_CD.isin(top_codes)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "encouraging-music",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Counts for the filtered data:\n",
      "\n",
      " 94003    12672\n",
      "94002     8100\n",
      "99291     4716\n",
      "99232     2361\n",
      "99233     1901\n",
      "36556     1765\n",
      "99254     1151\n",
      "99231     1067\n",
      "99223     1021\n",
      "90935     1014\n",
      "99222      961\n",
      "99253      852\n",
      "99255      689\n",
      "36620      650\n",
      "99238      476\n",
      "31624      457\n",
      "76942      437\n",
      "33405      435\n",
      "76937      350\n",
      "31645      328\n",
      "99252      327\n",
      "99292      310\n",
      "99239      308\n",
      "31622      302\n",
      "99221      264\n",
      "90801      236\n",
      "62270      223\n",
      "31500      192\n",
      "01996      178\n",
      "99024      168\n",
      "90945      153\n",
      "90937      149\n",
      "36489      142\n",
      "32002      139\n",
      "49080      127\n",
      "61312      124\n",
      "99251      108\n",
      "43246      108\n",
      "33427      107\n",
      "93503      104\n",
      "31600      104\n",
      "33430       92\n",
      "33533       91\n",
      "92960       90\n",
      "47135       89\n",
      "33860       86\n",
      "54150       84\n",
      "32422       81\n",
      "27245       80\n",
      "32000       74\n",
      "Name: CPT_CD, dtype: int64\n",
      "Available sections:\n",
      "\n",
      " {'Medicine', 'Pathology and laboratory', 'Radiology', 'Surgery', 'Emerging technology', 'Evaluation and management', 'Anesthesia'}\n",
      "\n",
      "The length of the initial dataset was 52047 and the new dataset is 38179\n",
      "\n",
      "\n",
      "Value Counts for the original data:\n",
      "\n",
      " 94003    12672\n",
      "94002     8100\n",
      "99291     4716\n",
      "99232     2361\n",
      "99233     1901\n",
      "36556     1765\n",
      "99254     1151\n",
      "99231     1067\n",
      "90935     1014\n",
      "36620      650\n",
      "31624      457\n",
      "76942      437\n",
      "33405      435\n",
      "76937      350\n",
      "31645      328\n",
      "90801      236\n",
      "01996      178\n",
      "99024      168\n",
      "76604       55\n",
      "75940       32\n",
      "99141       22\n",
      "85060       22\n",
      "75989       19\n",
      "99144       19\n",
      "0256T        8\n",
      "Name: CPT_CD, dtype: int64\n",
      "Value Counts for the filtered data:\n",
      "\n",
      " 94003    12672\n",
      "94002     8100\n",
      "99291     4716\n",
      "99232     2361\n",
      "99233     1901\n",
      "36556     1765\n",
      "99254     1151\n",
      "99231     1067\n",
      "90935     1014\n",
      "36620      650\n",
      "31624      457\n",
      "76942      437\n",
      "33405      435\n",
      "76937      350\n",
      "31645      328\n",
      "90801      236\n",
      "01996      178\n",
      "99024      168\n",
      "76604       55\n",
      "75940       32\n",
      "99141       22\n",
      "85060       22\n",
      "75989       19\n",
      "99144       19\n",
      "0256T        8\n",
      "Name: CPT_CD, dtype: int64\n",
      "\n",
      "Here are the counts by section:\n",
      "\n",
      " SECTIONHEADER\n",
      "Anesthesia                   3\n",
      "Evaluation and management    5\n",
      "Medicine                     5\n",
      "Pathology and laboratory     1\n",
      "Radiology                    5\n",
      "Surgery                      5\n",
      "Name: CPT_CD, dtype: int64\n",
      "\n",
      "Here are the counts by CPT by section\n",
      "\n",
      ":\n",
      "Anesthesia 01996 178\n",
      "Anesthesia 99141 22\n",
      "Anesthesia 99144 19\n",
      "Evaluation and management 99231 1067\n",
      "Evaluation and management 99232 2361\n",
      "Evaluation and management 99233 1901\n",
      "Evaluation and management 99254 1151\n",
      "Evaluation and management 99291 4716\n",
      "Medicine 90801 236\n",
      "Medicine 90935 1014\n",
      "Medicine 94002 8100\n",
      "Medicine 94003 12672\n",
      "Medicine 99024 168\n",
      "Pathology and laboratory 85060 22\n",
      "Radiology 75940 32\n",
      "Radiology 75989 19\n",
      "Radiology 76604 55\n",
      "Radiology 76937 350\n",
      "Radiology 76942 437\n",
      "Surgery 31624 457\n",
      "Surgery 31645 328\n",
      "Surgery 33405 435\n",
      "Surgery 36556 1765\n",
      "Surgery 36620 650\n"
     ]
    }
   ],
   "source": [
    "# Filter the number of CPT occurrences by section and CPT\n",
    "filtered_df1 = cpt_count_filter(note_cpt, note_cpt, 2, 10)\n",
    "\n",
    "# Show available sections\n",
    "print('Available sections:\\n\\n', set(filtered_df1['SECTIONHEADER']))\n",
    "\n",
    "# Filter to a set amount of CPT codes for each section header - only here to make the code run faster when testing\n",
    "filtered_df2 = cpt_per_section_filter(filtered_df1, 5, all_sections=True)\n",
    "\n",
    "# Filter to those CPT codes that have at least 100 notes or more\n",
    "filtered_df_cpt = filter_df(filtered_df2, 10)\n",
    "\n",
    "# Filter total number of CPT codes in the dataset by section\n",
    "# filtered_df_cpt = filter_cpt_ct(filtered_df_cpt, 'Evaluation and management', 3)\n",
    "\n",
    "# Show some dataset stats\n",
    "show_section_counts(filtered_df_cpt)\n",
    "show_cpt_counts_by_section(filtered_df_cpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "pursuant-batch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SECTIONHEADER              CPT_CD\n",
       "Anesthesia                 01996       178\n",
       "                           99141        22\n",
       "                           99144        19\n",
       "Evaluation and management  99231      1067\n",
       "                           99232      2361\n",
       "                           99233      1901\n",
       "                           99254      1151\n",
       "                           99291      4716\n",
       "Medicine                   90801       236\n",
       "                           90935      1014\n",
       "                           94002      8100\n",
       "                           94003     12672\n",
       "                           99024       168\n",
       "Pathology and laboratory   85060        22\n",
       "Radiology                  75940        32\n",
       "                           75989        19\n",
       "                           76604        55\n",
       "                           76937       350\n",
       "                           76942       437\n",
       "Surgery                    31624       457\n",
       "                           31645       328\n",
       "                           33405       435\n",
       "                           36556      1765\n",
       "                           36620       650\n",
       "dtype: int64"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df_cpt[['SECTIONHEADER','CPT_CD']].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-memorial",
   "metadata": {},
   "source": [
    "# Filter the Data - ICD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "spoken-alberta",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df_icd(df, threshold):\n",
    "\n",
    "    x = df['ICD9_CODE'].value_counts() > threshold\n",
    "    y = list(x[x == 1].index)\n",
    "\n",
    "    z = df[df['ICD9_CODE'].isin(y)]\n",
    "\n",
    "    return z\n",
    "\n",
    "def filter_icd_ct(df,ct):\n",
    "    top_codes = list(df['ICD9_CODE'].value_counts().head(ct).index)\n",
    "    df = df[df.ICD9_CODE.isin(top_codes)]\n",
    "    return df\n",
    "\n",
    "filtered_df_icd = filter_df_icd(note_icd, 100)\n",
    "filtered_df_icd = filter_icd_ct(filtered_df_icd, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "thousand-blowing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>CLINICAL_TEXT</th>\n",
       "      <th>ICD9_CODE</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>145834.0</td>\n",
       "      <td>Admission Date:  [**2101-10-20**]     Discharg...</td>\n",
       "      <td>0389</td>\n",
       "      <td>Unspecified septicemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>176176.0</td>\n",
       "      <td>Admission Date:  [**2116-12-23**]     Discharg...</td>\n",
       "      <td>0389</td>\n",
       "      <td>Unspecified septicemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85</td>\n",
       "      <td>112077.0</td>\n",
       "      <td>Admission Date:  [**2167-7-25**]              ...</td>\n",
       "      <td>0389</td>\n",
       "      <td>Unspecified septicemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111</td>\n",
       "      <td>155897.0</td>\n",
       "      <td>Admission Date:  [**2144-7-1**]              D...</td>\n",
       "      <td>0389</td>\n",
       "      <td>Unspecified septicemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>112</td>\n",
       "      <td>173177.0</td>\n",
       "      <td>Admission Date:  [**2196-9-27**]              ...</td>\n",
       "      <td>0389</td>\n",
       "      <td>Unspecified septicemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15082</th>\n",
       "      <td>32588</td>\n",
       "      <td>161808.0</td>\n",
       "      <td>Unit No:  [**Numeric Identifier 74734**]\\nAdmi...</td>\n",
       "      <td>V3001</td>\n",
       "      <td>Single liveborn, born in hospital, delivered b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15083</th>\n",
       "      <td>32596</td>\n",
       "      <td>112009.0</td>\n",
       "      <td>Admission Date: [**2184-11-1**]        Dischar...</td>\n",
       "      <td>V3001</td>\n",
       "      <td>Single liveborn, born in hospital, delivered b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15084</th>\n",
       "      <td>32603</td>\n",
       "      <td>182063.0</td>\n",
       "      <td>Unit No:  [**Numeric Identifier 75844**]\\nAdmi...</td>\n",
       "      <td>V3001</td>\n",
       "      <td>Single liveborn, born in hospital, delivered b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15085</th>\n",
       "      <td>32641</td>\n",
       "      <td>168336.0</td>\n",
       "      <td>Admission Date: [**2152-10-19**]        Discha...</td>\n",
       "      <td>V3001</td>\n",
       "      <td>Single liveborn, born in hospital, delivered b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15086</th>\n",
       "      <td>32803</td>\n",
       "      <td>105824.0</td>\n",
       "      <td>Admission Date: [**2118-2-6**]        Discharg...</td>\n",
       "      <td>V3001</td>\n",
       "      <td>Single liveborn, born in hospital, delivered b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9684 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SUBJECT_ID   HADM_ID  \\\n",
       "0               3  145834.0   \n",
       "1              33  176176.0   \n",
       "2              85  112077.0   \n",
       "3             111  155897.0   \n",
       "4             112  173177.0   \n",
       "...           ...       ...   \n",
       "15082       32588  161808.0   \n",
       "15083       32596  112009.0   \n",
       "15084       32603  182063.0   \n",
       "15085       32641  168336.0   \n",
       "15086       32803  105824.0   \n",
       "\n",
       "                                           CLINICAL_TEXT ICD9_CODE  \\\n",
       "0      Admission Date:  [**2101-10-20**]     Discharg...      0389   \n",
       "1      Admission Date:  [**2116-12-23**]     Discharg...      0389   \n",
       "2      Admission Date:  [**2167-7-25**]              ...      0389   \n",
       "3      Admission Date:  [**2144-7-1**]              D...      0389   \n",
       "4      Admission Date:  [**2196-9-27**]              ...      0389   \n",
       "...                                                  ...       ...   \n",
       "15082  Unit No:  [**Numeric Identifier 74734**]\\nAdmi...     V3001   \n",
       "15083  Admission Date: [**2184-11-1**]        Dischar...     V3001   \n",
       "15084  Unit No:  [**Numeric Identifier 75844**]\\nAdmi...     V3001   \n",
       "15085  Admission Date: [**2152-10-19**]        Discha...     V3001   \n",
       "15086  Admission Date: [**2118-2-6**]        Discharg...     V3001   \n",
       "\n",
       "                                                    TEXT  \n",
       "0                                 Unspecified septicemia  \n",
       "1                                 Unspecified septicemia  \n",
       "2                                 Unspecified septicemia  \n",
       "3                                 Unspecified septicemia  \n",
       "4                                 Unspecified septicemia  \n",
       "...                                                  ...  \n",
       "15082  Single liveborn, born in hospital, delivered b...  \n",
       "15083  Single liveborn, born in hospital, delivered b...  \n",
       "15084  Single liveborn, born in hospital, delivered b...  \n",
       "15085  Single liveborn, born in hospital, delivered b...  \n",
       "15086  Single liveborn, born in hospital, delivered b...  \n",
       "\n",
       "[9684 rows x 5 columns]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df_icd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-september",
   "metadata": {},
   "source": [
    "# Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "unable-minimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(text_series, remove_sections):\n",
    "  \n",
    "    # lowercase all letters\n",
    "    text_series = text_series.str.lower() \n",
    "\n",
    "    # Remove topics\n",
    "    if remove_sections:\n",
    "        data = text_series.str.split(r'(\\n\\n)')\n",
    "        for row_num, value in enumerate(data):\n",
    "            text_chunks = [x.split(':', maxsplit=1) for x in value]\n",
    "            ls = []\n",
    "            for i, x in enumerate(text_chunks):\n",
    "                try:\n",
    "                    if x[0] != 'social history' or x[0] != 'family history' or 'medication' not in x[0]:\n",
    "                        ls.append(x[1])\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "            text_series.iloc[row_num] = ' '.join(ls)\n",
    "\n",
    "        \n",
    "    # Remove dates and locations\n",
    "    text_series = text_series.str.replace('\\[\\*\\*(.*?)\\*\\*\\]', ' ', regex=True)\n",
    "    \n",
    "    # Replace \\n \n",
    "    text_series = text_series.str.replace('\\\\n',' ', regex=True)  \n",
    "    \n",
    "    # Replace punctuation\n",
    "    text_series = text_series.str.replace('[' + string.punctuation + ']', ' ', regex=True)\n",
    "    \n",
    "    # Remove all digits\n",
    "    text_series = text_series.str.replace('\\d',' ', regex=True)\n",
    "    \n",
    "    # Replace plurals, endings with ing, endings with ed, endings with ly\n",
    "#     text_series = text_series.str.replace('s(?=\\s)', ' ', regex=True)\n",
    "#     text_series = text_series.str.replace('ing(?=\\s)', ' ', regex=True)\n",
    "#     text_series = text_series.str.replace('ed(?=\\s)', ' ', regex=True)\n",
    "#     text_series = text_series.str.replace('ly(?=\\s)', ' ', regex=True)\n",
    "    \n",
    "    return text_series\n",
    "\n",
    "# Update Text Column -----\n",
    "# filtered_df_cpt['TEXT'] = clean_data(filtered_df_cpt['TEXT'], True)\n",
    "filtered_df_icd['TEXT'] = clean_data(filtered_df_icd['TEXT'], False)\n",
    "filtered_df_icd['CLINICAL_TEXT'] = clean_data(filtered_df_icd['CLINICAL_TEXT'], True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-mixer",
   "metadata": {},
   "source": [
    "# Label Encode the Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cooked-cloud",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "filtered_df['CPT_CD'] = le.fit_transform(filtered_df['CPT_CD'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coupled-nerve",
   "metadata": {},
   "source": [
    "# Select CPT sections to Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "documented-coordinate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Medicine', 'Pathology and laboratory', 'Radiology', 'Surgery', 'Evaluation and management', 'Anesthesia']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "sections = list(set(filtered_df_cpt['SECTIONHEADER']))\n",
    "print(sections)\n",
    "sections = []\n",
    "print(sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-devil",
   "metadata": {},
   "source": [
    "# Split the Data - CPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "double-islam",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_dict = {} \n",
    "\n",
    "def split_stratify_df(df, sections, combine_others=False, all_=False):\n",
    "    \n",
    "    # Train test split for each section selected\n",
    "    if all_:\n",
    "        sections.clear()\n",
    "    else:\n",
    "        for i in sections:\n",
    "            \n",
    "            # Test and training\n",
    "            df_x = df[df['SECTIONHEADER'] == i]['TEXT'].values\n",
    "            df_y = df[df['SECTIONHEADER'] == i]['CPT_CD']\n",
    "            tt_dict['X_train_' + i], tt_dict['X_test_' + i], tt_dict['y_train_' + i], tt_dict['y_test_' + i], \\\n",
    "            tt_dict['index_train_' + i], tt_dict['index_test_' + i] = \\\n",
    "            train_test_split(df_x, df_y, range(len(df_y)), test_size = .3, random_state = 42, shuffle=True)\n",
    "            \n",
    "            # Validation\n",
    "            tt_dict['X_test_' + i], tt_dict['X_val_' + i], tt_dict['y_test_' + i], tt_dict['y_val_' + i], \\\n",
    "            tt_dict['index_test_' + i], tt_dict['index_val_' + i] = \\\n",
    "            train_test_split(tt_dict['X_test_' + i], tt_dict['y_test_' + i], range(len(tt_dict['y_test_' + i])), \\\n",
    "                             test_size = .05, random_state = 42, shuffle=True)\n",
    "            \n",
    "    # Group other sections not included in selection\n",
    "    if combine_others:\n",
    "        i = 'other'\n",
    "        other_sections = list(set(df['SECTIONHEADER']).difference(set(sections)))\n",
    "        sections.append(i)\n",
    "        df_x = df[df['SECTIONHEADER'].isin(other_sections)]['TEXT'].values\n",
    "        df_y = df[df['SECTIONHEADER'].isin(other_sections)]['CPT_CD']\n",
    "        \n",
    "        # Test and training\n",
    "        tt_dict['X_train_' + i], tt_dict['X_test_' + i], tt_dict['y_train_' + i], tt_dict['y_test_' + i], \\\n",
    "        tt_dict['index_train_' + i], tt_dict['index_test_' + i] = \\\n",
    "        train_test_split(df_x, df_y, range(len(df_y)), test_size = .3, random_state = 42, shuffle=True)\n",
    "        \n",
    "        # Validation\n",
    "        tt_dict['X_test_' + i], tt_dict['X_val_' + i], tt_dict['y_test_' + i], tt_dict['y_val_' + i], \\\n",
    "        tt_dict['index_test_' + i], tt_dict['index_val_' + i] = \\\n",
    "        train_test_split(tt_dict['X_test_' + i], tt_dict['y_test_' + i], range(len(tt_dict['y_test_' + i])), \\\n",
    "                         test_size = .05, random_state = 42, shuffle=True)\n",
    "        \n",
    "split_stratify_df(filtered_df_cpt, sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-witch",
   "metadata": {},
   "source": [
    "# Select ICD sections to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "exciting-circular",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['icd']\n"
     ]
    }
   ],
   "source": [
    "sections.append('icd')\n",
    "print(sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "lasting-blowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df_icd['TEXT'] = (filtered_df_icd['TEXT'] + ' ' + filtered_df_icd['CLINICAL_TEXT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "leading-wiring",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unspecified septicemia         discharge date              sex   m   medicine   admitted from rehabilitation for hypotension  systolic blood pressure to the   s  and decreased urine output    the patient is a    year old male who had been hospitalized at the   from   through   of   after undergoing a left femoral at bypass graft and was subsequently discharged to a rehabilitation facility        coronary artery disease with diffuse   vessel disease  right dominant  status post proximal left circumflex stent in   with occlusion of the distal left circumflex  status post right coronary artery stent on    no percutaneous coronary intervention to     diagonal left circumflex      small proximal left anterior descending artery  or     small distal left anterior descending artery        congestive heart failure  with an ejection fraction of     to            type   diabetes with neuropathy       hypertension       diverticulosis  found on colonoscopy in          alzheimer s dementia       history of gastrointestinal bleed  while the patient was taking eptifibatide        cardiac risk factors  with a baseline creatinine of     to            hypercholesterolemia       history of methicillin resistant staphylococcus aureus and pseudomonas growth in wound cultures       severe peripheral vascular disease  status post left femoral at bypass graft on         chronic nonhealing foot ulcers       recent right pedal cellulitis    the patient has no known drug allergies        vancomycin   g intravenously q   h  for a level of less than     started on          levofloxacin     mg p o  q d   started on          metronidazole     mg p o  q  h   started on          heparin      units subcutaneous b i d       simvastatin    mg p o  q d       lisinopril   mg p o  q d       furosemide    mg p o  q d       vitamin e     iu p o  q d       atenolol    mg p o  q d       pantoprazole    mg p o  q d       ascorbic acid     mg p o  b i d       nph    units b i d       regular insulin sliding scale       bisacodyl    mg p o  p r  as needed       docusate     mg p o  b i d       percocet       mg one tablet p o  q    h  as needed for pain       aspirin    mg p o  q d       metoprolol    mg p o  b i d    the patient is retired and had been living at home with his wife prior to his admission to the hospital on    he had been living at   for the day prior to admission   he is a social drinker and has a    pack year smoking history  although  he quit smoking    years ago     initial physical examination revealed temperature was      degrees fahrenheit  heart rate was     blood pressure was         following administration of   liters of normal saline   respiratory was     and his oxygen saturation was      on   liters nasal cannula   his heart had a regular rate and rhythm   there were normal first and second heart sounds   there was a     systolic ejection murmur  and there were no rubs or gallops  his lungs were clear to auscultation bilaterally   his abdomen was soft  nontender  and nondistended  and there were hypoactive bowel sounds   he had a palpable bypass graft pulse    dorsalis pedis and posterior tibialis pulses bilaterally  and his surgical incision was clean  dry  and intact   please note that the above examination was done by the vascular surgery team  which was the team that was initially planning to admit the patient to the hospital    on initial laboratory evaluation the patient had a white blood cell count of       hematocrit was       and platelets were           his pt was       ptt was       and inr was       his serum chemistries revealed sodium was      potassium was      chloride was     bicarbonate was     blood urea nitrogen was     creatinine was      and blood glucose was      his calcium was      magnesium was      and phosphate was       blood cultures drawn on admission were pending  but ultimately negative   a urine culture taken on admission was initially pending  but ultimately grew out yeast   a sputum culture taken on admission was also initially pending  but ultimately also grew out yeast    his admission chest x ray demonstrated stable prominence of the right main pulmonary artery  no focal areas of consolidation  overall stable appearance of the chest compared with a   study   no radiographic evidence of congestive heart failure or pneumonia     the patient was initially admitted to the vascular intensive care unit with hypotension  decreased urine output  and acute renal failure  most likely secondary to a presumed gram negative urosepsis  although there were never any positive culture data to confirm this diagnosis     the patient was started on gentamicin and piperacillin tazobactam in addition to the levofloxacin  metronidazole  and vancomycin he was already taking for right lower extremity cellulitis prior to admission for empiric coverage of a presumed gram negative urosepsis  and he was aggressively hydrated with intravenous fluids    as noted above  the patient was intubated and he was extubated on     he subsequently developed wheezing and mild hypoxia  most likely secondary to cardiac asthma and fluid overload in the setting of his aggressive fluid resuscitation   he was gently diuresed toward the end of his hospitalization  and by the time of his he was maintaining an oxygen saturation of greater than     on   liters nasal cannula  intermittent ipratropium nebulizers  and chest physical therapy for clearance of his respiratory secretions    the patient presented with acute renal failure and prerenal azotemia that rapidly resolved following fluid resuscitation   by the time of discharge  his serum creatinine was stable and at his preadmission baseline    the patient was found to be profoundly malnourished with a serum albumin of     on admission   once he was extubated and taking orals  he performed poorly on a modified barium swallowing study and was started on a thin liquid  ground solid diet with whole medication tablets  small bites and sips  upright posture with meals  and aspiration precautions   he was also given promod shakes with and between meals for nutritional supplementation of his heart healthy diabetic diet    the patient s operative incisions and foot ulcers continued to heal throughout this admission   he was started on an multivitamin  vitamin c  and zinc for improved wound healing    the patient was transfused one unit of packed red blood cells on   to maintain a hematocrit of greater than    given his history of severe coronary artery disease   his hematocrit subsequently remained stable    condition on discharge was stable        rehabilitation facility        cardiorespiratory arrest       non q wave myocardial infarction       acute renal failure       coronary artery disease with diffuse   vessel disease  right dominant  status post proximal left circumflex stent in   with occlusion of distal left circumflex  status post right coronary artery stent on    no percutaneous coronary intervention to      distal left circumflex      small proximal left anterior descending artery      small distal left anterior descending artery        congestive heart failure  with an ejection fraction of     to            type   diabetes with neuropathy       hypertension       diverticulosis  found on colonoscopy in          alzheimer s dementia       history of gastrointestinal bleed  while the patient was taking eptifibatide        cardiac risk factors  with a baseline creatinine of     to            history of methicillin resistant staphylococcus aureus and pseudomonas growth in wound cultures       severe peripheral vascular disease  status post left femoral at bypass graft on         chronic nonhealing foot ulcers        amiodarone     mg p o  b i d   through     then     mg p o  q d   times one week   then     mg p o  q d       metoprolol    mg p o  b i d       captopril      mg p o  t i d       aspirin     mg p o  q d       pantoprazole    mg p o  q d       heparin      units subcutaneously b i d       multivitamin one tablet p o  q d       zinc sulfate     mg p o  q d       vitamin c     mg p o  q d       ipratropium nebulizers q    h  as needed  for wheezing        acetaminophen     mg to     mg p o  q    h  as needed  for pain        miconazole    powder to groin b i d       santyl lotion to heels b i d       regular insulin sliding scale    do not resuscitate do not intubate    if applicable  an addendum to this discharge summary will be dictated to include follow up appointments as well as any changes to the medication list noted above               t            job      '"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df_icd['TEXT'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-adobe",
   "metadata": {},
   "source": [
    "# Split the Data - ICD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "breathing-lithuania",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and test\n",
    "tt_dict['X_train_icd'], tt_dict['X_test_icd'] , tt_dict['y_train_icd'], tt_dict['y_test_icd'] = \\\n",
    "train_test_split(filtered_df_icd['TEXT'].values, filtered_df_icd['ICD9_CODE'], test_size = .3, random_state = 42, shuffle=True)\n",
    "\n",
    "# Test and Validation\n",
    "tt_dict['X_test_icd'], tt_dict['X_val_icd'] , tt_dict['y_test_icd'], tt_dict['y_val_icd'] = \\\n",
    "train_test_split(tt_dict['X_test_icd'], tt_dict['y_test_icd'], test_size = .05, random_state = 42, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-removal",
   "metadata": {},
   "source": [
    "# Balance the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "quantitative-catalog",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "icd\n",
      "New Balanced Record Count per feature: 2372\n"
     ]
    }
   ],
   "source": [
    "def oversample_df(X_train, y_train, percentile):\n",
    "            \n",
    "    # Recombine the training dataset\n",
    "    x = pd.Series(X_train).reset_index(drop=True)\n",
    "    y = pd.Series(y_train).reset_index(drop=True)\n",
    "    training_df = pd.concat([x,y], axis=1, ignore_index=True)\n",
    "\n",
    "    # Check counts\n",
    "    df_cts = training_df.iloc[:,1].value_counts()\n",
    "    record_ct = round(np.percentile(df_cts, percentile))\n",
    "    print('New Balanced Record Count per feature: {}'.format(record_ct))\n",
    "    \n",
    "    # Create a list of CPT values\n",
    "    df = list(df_cts.index.values)\n",
    "\n",
    "    # Resample\n",
    "    minority_df = []\n",
    "    for i in df:\n",
    "        test_resampled = resample(training_df[training_df.iloc[:,1] == i], replace=True, n_samples=record_ct, random_state=123)\n",
    "        minority_df.append(test_resampled)\n",
    "    \n",
    "    # Create final dataframe\n",
    "    new_df = pd.concat(minority_df)\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "def balance(tt_dict, sections):\n",
    "    for section in sections:\n",
    "        print(section)\n",
    "        \n",
    "        # Running balance function\n",
    "        training_balanced = oversample_df(tt_dict['X_train_' + section], tt_dict['y_train_' + section] , 99)\n",
    "        \n",
    "        # Reassign balanced data\n",
    "        tt_dict['X_train_' + section] = np.array(training_balanced.iloc[:,0].values)\n",
    "        tt_dict['y_train_' + section] = np.array(training_balanced.iloc[:,1].values)\n",
    "\n",
    "# Run the functions\n",
    "balance(tt_dict, sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-comment",
   "metadata": {},
   "source": [
    "# Tokenize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "determined-waters",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stop words\n",
    "my_stop_words = list(set(stopwords.words('english'))) \\\n",
    "                + ['admission', 'date', 'sex'] \\\n",
    "                + ['needed', 'every', 'seen', 'weeks', 'please', 'ml', 'unit', 'small', 'year', 'old', 'cm', 'non', 'mm', 'however']\n",
    "                # Got the above from my top 100 most predictive words that I wanted to remove\n",
    "\n",
    "# Set Dictionary for vectorized words\n",
    "vectorized_words = {}\n",
    "    \n",
    "def vectorize_df(train_test_dict, sections):\n",
    "\n",
    "    for section in sections:\n",
    "        \n",
    "        # Import TfidfVectorizer\n",
    "        vectorized_words['tfidf_vectorizer_' + section] = TfidfVectorizer(stop_words=my_stop_words, max_df=.7, min_df = 2, sublinear_tf = True, ngram_range = (1, 2))\n",
    "\n",
    "        # Transform the training data\n",
    "        tfidf_train = vectorized_words['tfidf_vectorizer_' + section].fit_transform(train_test_dict['X_train_' + section])\n",
    "\n",
    "        # Transform the test data\n",
    "        tfidf_test = vectorized_words['tfidf_vectorizer_' + section].transform(train_test_dict['X_test_' + section])\n",
    "\n",
    "        # Add results to dictionary\n",
    "\n",
    "        vectorized_words['tfidf_train_' + section] = tfidf_train\n",
    "        vectorized_words['tfidf_test_' + section] = tfidf_test\n",
    "\n",
    "vectorize_df(tt_dict, sections)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-census",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "beginning-section",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "models_lr = {}\n",
    "\n",
    "def run_clf(train_test_dict, sections):\n",
    "\n",
    "    # Fit and check accuracy\n",
    "    for section in sections:\n",
    "        \n",
    "        # Use Naive Bayes model\n",
    "        clf = LogisticRegression(random_state=123, C=1, max_iter=25, solver='sag', n_jobs=-1)\n",
    "        \n",
    "        # Fit model\n",
    "        clf.fit(vectorized_words['tfidf_train_' + section], train_test_dict['y_train_' + section])\n",
    "        \n",
    "        # Save in dictionary\n",
    "        models_lr[section] = clf\n",
    "    \n",
    "run_clf(tt_dict, sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-detective",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "forty-treaty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "icd\n",
      "0.9605072463768116\n"
     ]
    }
   ],
   "source": [
    "# models_ls = [models_nb, models_rf, models_xg, models_knn, models_lr, models_tree]\n",
    "models_ls = [models_lr]\n",
    "\n",
    "# Check accuracy\n",
    "def predictions(tt_dict, models, section=[]):\n",
    "    for key, model in models.items():\n",
    "        if len(section) == 0 or key == section:\n",
    "            pred = model.predict(vectorized_words['tfidf_test_' + key])\n",
    "            print(key)\n",
    "            print(metrics.accuracy_score(tt_dict['y_test_' + key], pred))\n",
    "\n",
    "predictions(tt_dict, models_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-kenya",
   "metadata": {},
   "source": [
    "# Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "useful-strand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0389       0.97      0.99      0.98       573\n",
      "       41071       0.91      0.94      0.92       480\n",
      "       41401       0.98      0.93      0.96      1012\n",
      "        4241       0.92      0.98      0.95       320\n",
      "       V3001       1.00      1.00      1.00       375\n",
      "\n",
      "    accuracy                           0.96      2760\n",
      "   macro avg       0.96      0.97      0.96      2760\n",
      "weighted avg       0.96      0.96      0.96      2760\n",
      "\n",
      "Training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0389       1.00      1.00      1.00      2372\n",
      "       41071       1.00      1.00      1.00      2372\n",
      "       41401       1.00      0.99      1.00      2372\n",
      "        4241       1.00      1.00      1.00      2372\n",
      "       V3001       1.00      1.00      1.00      2372\n",
      "\n",
      "    accuracy                           1.00     11860\n",
      "   macro avg       1.00      1.00      1.00     11860\n",
      "weighted avg       1.00      1.00      1.00     11860\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create classification report taken from here: https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568\n",
    "print('Test')\n",
    "section = 'icd'\n",
    "pred = models_lr[section].predict(vectorized_words['tfidf_test_' + section])\n",
    "print(classification_report(tt_dict['y_test_' + section], pred))\n",
    "\n",
    "print('Training')\n",
    "pred_x = models_lr[section].predict(vectorized_words['tfidf_train_' + section])\n",
    "print(classification_report(tt_dict['y_train_' + section], pred_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-mining",
   "metadata": {},
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "similar-senator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                     discharge date               ...\n",
      "dtype: object\n",
      "['41071'] 74.95%\n"
     ]
    }
   ],
   "source": [
    "def predict_cpt(text, section):\n",
    "    input_text_clean = clean_data(pd.Series(text), False)\n",
    "    print(input_text_clean)\n",
    "    tfidf_input_test = vectorized_words['tfidf_vectorizer_' + section].transform(input_text_clean)\n",
    "    clf = models_lr[section]\n",
    "    \n",
    "    clf.predict(tfidf_input_test)\n",
    "    print(clf.predict(tfidf_input_test), str(round(max(clf.predict_proba(tfidf_input_test)[0]) * 100,2)) + '%')\n",
    "#     print(clf.predict_proba(tfidf_input_test)[0])\n",
    "\n",
    "# Set Variables\n",
    "txt_record_no = 0\n",
    "section = 'icd'\n",
    "# section_text = 'Anesthesia'\n",
    "\n",
    "# Run Function\n",
    "predict_cpt(x, section)\n",
    "\n",
    "# print(np.array(tt_dict['y_val_' + section_text])[txt_record_no])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "north-carry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'                 discharge date                      sex    m  medicine  penicillins   iodine  iodine containing   chief complaint  nstemi  cardiac catheterization  diagnostic  tooth extraction        mr    is a    y o male with a h o rheumatic heart disase  severe as  htn  and hyperlipidemia who presented initially to an osh ed with severe sob and was then transferred to the   ed when there was a concern for possible stemi  of note  the pt recently had left carotid stenting on    post procedure  he was instructed to keep his bp          taking sudafed at home if his bp decreased  about     days after his procedure  he noted increasing sob and doe  he denied any cp  he presented to   ed with the above complaints  he was started on a nitro gtt and given combivent nebs  lasix    iv x    solumedrol     mg iv x    ativan   mg iv x    morphine   mg iv x    asa     mg po  and lopressor   mg iv x    because of his respiratory distress  he was placed on bipap       a non contrast ct scan was performed to r o aortic dissection  it revealed moderate b l pleural effusions  she was then transferred to the   ed for further evaluation   bp        hr    rr         on bipap  question of ste on ekg  cpk      troponin       bnp       and wbc     at the   ed  he was started on a heparin gtt  vitals on presentation were t      hr    bp        rr         lnc   severe as rheumatic heart disease htn hyperlipidemia cri  unknown baseline stroke tia x   clean cath at   in    married  lives at home with his wife  quit tobacco in    denies alcohol or ivdu  non contributory  general appearance  well nourished  no acute distress  perrl  normocephalic   pmi normal    s   normal    s   normal    murmur  systolic   sem  best heart rusb  radiating to the carotids   right radial pulse  present    left radial pulse  present    right dp pulse  present    left dp pulse  present    expansion  symmetric    breath sounds  crackles       up lung fields  no t  wheezes      soft  non tender  bowel sounds present  distended  no t  tender   right      left       not assessed  rash  on trunk  maculopapular  attentive  a o x    cns ii xii grossly intact  sensation intact  good rom and strength in all   extremities          pm   ck cpk              pm   ck mb     mb indx      ctropnt              pm   glucose      urea n     creat      sodium     potassium     chloride    total co     anion gap           am   wbc      rbc       hgb       hct       mcv    mch      mchc       rdw             am   ck cpk              am   ck mb     mb indx             am   ctropnt           three vessel coronary artery disease     moderate to severe aortic stenosis     marked elevation of biventricular filling pressures   suboptimal image quality  lv wall thicknesses are normal  regional lv systolic dysfunction consistent with coronary artery disease  diastolic dysfunction  there is aortic stenosis which is at least moderate and may be severe  valve not well seen and doppler interrogation only possible from suprasternal view   the mitral valve is not well seen but does not appear to be rheumatic  there is no mitral stenosis  moderate pulmonary artery systolic hypertension      bilateral atelectasis and retrocardiac opacities  for which repeat pa and lateral were recommended if there is concern for aspiration or pneumonia     pulmonary edema      small left pleural effusion     no pneumonia  no chf   patent bilateral greater saphenous veins with very large diameters on the right and small diameters on the left   no official read     y o male with a h o rheumatic heart disase  severe as  htn  and hyperlipidemia who presented with worsening sob  determined to have a nstemi and left sided heart failure      three vessel coronary artery disease     moderate to severe aortic stenosis     marked elevation of biventricular filling pressures   based on these findings  recommendation was made to undergo cabg with avr once recovered from recent carotid stents  pt agreed and underwent screening by ct   as well as multiple pre op studies and dental work  removal of two teeth   cardiac enzymes continued to trend down and pt was discharged home to continue course of plavix  to be stopped   days prior to surgery   plavix    mg po daily asa     mg po daily atenolol chlorthalidone        mg po daily lisinopril    mg po daily allopurinol unknown dose zocor    mg po daily     aspirin     mg tablet sig  one     tablet po daily  daily      atorvastatin    mg tablet sig  one     tablet po daily  daily   disp     tablet s   refills        clopidogrel    mg tablet sig  one     tablet po daily  daily      furosemide    mg tablet sig      tablet po daily  daily   disp     tablet s   refills        allopurinol     mg tablet sig  two     tablet po once a day   one     tablet sustained release    hr po once a day  disp     tablet sustained release    hr s   refills        outpatient lab work serum creatinine  urine analysis and urine culture to be done on   at   medical building   the results need to be sent to your cardiac surgeon     amoxicillin     mg tablet sig  one     tablet po twice a day for   days  disp     tablet s   refills        lisinopril     mg tablet sig  one     tablet po once a day    disp     tablet s   refills      home  primary  non st elevation myocardial infarction  systolic congestive heart failure  ef        hypertension urinary tract infection hyperlipidemia coronary artery disease acute renal failure aortic stenosis  bun    creat     hct      wbc     bp        hr    otherwise stable  ambulating  and pain free   six hours after receiving amoxacillin  no wheezing  rashes  fever or other symptoms   you had a heart attack and some fluid accumulated in your lungs because your heart was not working well  you had a cardiac catheterization which showed severe aortic stenosis  a stiff arotic valve in your heart  and blockages in   of your arteries that feed blood to your heart  you will need surgery to bypass these arteries and fix your aortic valve  a tooth was pulled in preperation for the surgery  you had evidence of bacteria in your urine that needs treatment   you should complete a   day course of amoxacillin for this   you will need to get repeat urine studies  as well as repeat blood work done on     the results should be sent to your cardiac surgeon   otherwise  your pre operative work up is complete  you should stop taking plavix on    as well as get repeat labs  in preparation for your surgery on    new medicines     atorvastatin is taking the place of pravastatin    furosemide and toprol is taking the place of atenolol chlorthalidone     you have been restarted on plavix and should continue to take this until       your dose of lisinopril is lower      mg from    mg     please call dr    if you have any chest pain or pressure  trouble breathing  nausea  sweating or any other unusual symptoms   primary care       md phone    date time    at  pm   stop taking plavix on   and have repeat labs done at the   medical building    call cardiac surgey office at   if you have any questions   '"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = 7000\n",
    "# filtered_df_icd = filtered_df_icd.reset_index()\n",
    "print(filtered_df_icd['ICD9_CODE'][row])\n",
    "x = filtered_df_icd['CLINICAL_TEXT'][row]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "automated-savannah",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>CLINICAL_TEXT</th>\n",
       "      <th>ICD9_CODE</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>145834.0</td>\n",
       "      <td>discharge date              sex   m   ...</td>\n",
       "      <td>0389</td>\n",
       "      <td>unspecified septicemia         discharge date ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>176176.0</td>\n",
       "      <td>discharge date        patient is an   ...</td>\n",
       "      <td>0389</td>\n",
       "      <td>unspecified septicemia         discharge date ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85</td>\n",
       "      <td>112077.0</td>\n",
       "      <td>discharge date               ...</td>\n",
       "      <td>0389</td>\n",
       "      <td>unspecified septicemia                  discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111</td>\n",
       "      <td>155897.0</td>\n",
       "      <td>discharge date               ...</td>\n",
       "      <td>0389</td>\n",
       "      <td>unspecified septicemia                  discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>112</td>\n",
       "      <td>173177.0</td>\n",
       "      <td>discharge date       medicine...</td>\n",
       "      <td>0389</td>\n",
       "      <td>unspecified septicemia                  discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15082</th>\n",
       "      <td>32588</td>\n",
       "      <td>161808.0</td>\n",
       "      <td>admission date    discharge date    date o...</td>\n",
       "      <td>V3001</td>\n",
       "      <td>single liveborn  born in hospital  delivered b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15083</th>\n",
       "      <td>32596</td>\n",
       "      <td>112009.0</td>\n",
       "      <td>discharge date               sex   f...</td>\n",
       "      <td>V3001</td>\n",
       "      <td>single liveborn  born in hospital  delivered b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15084</th>\n",
       "      <td>32603</td>\n",
       "      <td>182063.0</td>\n",
       "      <td>admission date    discharge date    date o...</td>\n",
       "      <td>V3001</td>\n",
       "      <td>single liveborn  born in hospital  delivered b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15085</th>\n",
       "      <td>32641</td>\n",
       "      <td>168336.0</td>\n",
       "      <td>discharge date               sex   f...</td>\n",
       "      <td>V3001</td>\n",
       "      <td>single liveborn  born in hospital  delivered b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15086</th>\n",
       "      <td>32803</td>\n",
       "      <td>105824.0</td>\n",
       "      <td>discharge date               sex   f...</td>\n",
       "      <td>V3001</td>\n",
       "      <td>single liveborn  born in hospital  delivered b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9684 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SUBJECT_ID   HADM_ID  \\\n",
       "0               3  145834.0   \n",
       "1              33  176176.0   \n",
       "2              85  112077.0   \n",
       "3             111  155897.0   \n",
       "4             112  173177.0   \n",
       "...           ...       ...   \n",
       "15082       32588  161808.0   \n",
       "15083       32596  112009.0   \n",
       "15084       32603  182063.0   \n",
       "15085       32641  168336.0   \n",
       "15086       32803  105824.0   \n",
       "\n",
       "                                           CLINICAL_TEXT ICD9_CODE  \\\n",
       "0              discharge date              sex   m   ...      0389   \n",
       "1              discharge date        patient is an   ...      0389   \n",
       "2                       discharge date               ...      0389   \n",
       "3                       discharge date               ...      0389   \n",
       "4                       discharge date       medicine...      0389   \n",
       "...                                                  ...       ...   \n",
       "15082      admission date    discharge date    date o...     V3001   \n",
       "15083            discharge date               sex   f...     V3001   \n",
       "15084      admission date    discharge date    date o...     V3001   \n",
       "15085            discharge date               sex   f...     V3001   \n",
       "15086            discharge date               sex   f...     V3001   \n",
       "\n",
       "                                                    TEXT  \n",
       "0      unspecified septicemia         discharge date ...  \n",
       "1      unspecified septicemia         discharge date ...  \n",
       "2      unspecified septicemia                  discha...  \n",
       "3      unspecified septicemia                  discha...  \n",
       "4      unspecified septicemia                  discha...  \n",
       "...                                                  ...  \n",
       "15082  single liveborn  born in hospital  delivered b...  \n",
       "15083  single liveborn  born in hospital  delivered b...  \n",
       "15084  single liveborn  born in hospital  delivered b...  \n",
       "15085  single liveborn  born in hospital  delivered b...  \n",
       "15086  single liveborn  born in hospital  delivered b...  \n",
       "\n",
       "[9684 rows x 5 columns]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df_icd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-swing",
   "metadata": {},
   "source": [
    "# Look at the Most/Least Predictive Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "spoken-adobe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 & Section: Evaluation and management\n",
      "Class 1 & Section: Evaluation and management\n",
      "Class 2 & Section: Evaluation and management\n",
      "Class 3 & Section: Evaluation and management\n",
      "Class 4 & Section: Evaluation and management\n",
      "Class 0 & Section: Surgery\n",
      "Class 1 & Section: Surgery\n",
      "Class 2 & Section: Surgery\n",
      "Class 3 & Section: Surgery\n",
      "Class 4 & Section: Surgery\n",
      "Class 0 & Section: Medicine\n",
      "Class 1 & Section: Medicine\n",
      "Class 2 & Section: Medicine\n",
      "Class 3 & Section: Medicine\n",
      "Class 4 & Section: Medicine\n",
      "Class 0 & Section: Radiology\n",
      "Class 1 & Section: Radiology\n",
      "Class 2 & Section: Radiology\n",
      "Class 3 & Section: Radiology\n",
      "Class 4 & Section: Radiology\n",
      "Class 0 & Section: other\n",
      "Class 1 & Section: other\n",
      "Class 2 & Section: other\n",
      "Class 3 & Section: other\n",
      "Class 0 & Section: icd\n",
      "Class 1 & Section: icd\n",
      "Class 2 & Section: icd\n",
      "Class 3 & Section: icd\n",
      "Class 4 & Section: icd\n"
     ]
    }
   ],
   "source": [
    "def get_features(sections):\n",
    "\n",
    "    # Initialize dataframe list\n",
    "    df_ls = []\n",
    "    \n",
    "    for section in sections: \n",
    "    \n",
    "        # Loop through for each class\n",
    "        for index, class_ in enumerate(models_lr[section].classes_):\n",
    "            \n",
    "            print('Class ' + str(index) + ' & Section: ' + section)\n",
    "\n",
    "            # Get the feature names\n",
    "            feature_names = vectorized_words['tfidf_vectorizer_' + section].get_feature_names()\n",
    "\n",
    "            # Get the probabilities\n",
    "            # Source: # https://sebastiansauer.github.io/convert_logit2prob/ for converting odds to log odds\n",
    "            probs = [np.exp(x)/(1 + np.exp(x)) for x in models_lr[section].coef_[index]]\n",
    "\n",
    "            # Zip together the first CPT weights with feature names\n",
    "            feat_with_weights =  sorted(zip(probs, feature_names))\n",
    "            feat_with_weights_r = feat_with_weights[::-1]\n",
    "\n",
    "            # Bottom 100 dataframe\n",
    "            bottom_100 = pd.DataFrame(feat_with_weights[:100], columns = ['Prob','Features'])\n",
    "            bottom_100['Class'] = models_lr[section].classes_[index]\n",
    "            bottom_100['Direction'] = 'Bottom'\n",
    "            bottom_100['Section'] = section\n",
    "\n",
    "            # Top 100 dataframe\n",
    "            top_100 = pd.DataFrame(feat_with_weights_r[:100], columns = ['Prob','Features'])\n",
    "            top_100['Class'] = models_lr[section].classes_[index]\n",
    "            top_100['Direction'] = 'Top'\n",
    "            top_100['Section'] = section\n",
    "\n",
    "            # Add dataframes to list\n",
    "            df_ls.append(bottom_100)\n",
    "            df_ls.append(top_100)\n",
    "\n",
    "    return pd.concat(df_ls)\n",
    "\n",
    "features_df = get_features(sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "driven-composite",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the features\n",
    "features_df.to_csv('features_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-theology",
   "metadata": {},
   "source": [
    "# Save the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "dimensional-scientist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from here: https://machinelearningmastery.com/save-load-machine-learning-models-python-scikit-learn/\n",
    "# save the model to disk\n",
    "\n",
    "for key, model in models_lr.items():\n",
    "    filename = 'finalized_model_' + key + '.sav'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "#     # some time later...\n",
    "\n",
    "#     # load the model from disk\n",
    "#     loaded_model = pickle.load(open(filename, 'rb'))\n",
    "#     result = loaded_model.score(X_test, Y_test)\n",
    "#     print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominant-shield",
   "metadata": {},
   "source": [
    "# Save the Fitted Vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "broad-recycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, vectorizer in vectorized_words.items():\n",
    "    if 'vectorizer' in key:\n",
    "        filename = 'finalized_vectorizer_' + key + '.sav'\n",
    "        pickle.dump(vectorizer, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-wheel",
   "metadata": {},
   "source": [
    "# Save the Validation Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "romantic-headquarters",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in tt_dict.items():\n",
    "    if 'X_val_' in key or 'y_val_' in key:\n",
    "        pd.Series(value).to_csv(key + '.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

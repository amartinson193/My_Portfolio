{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "built-romance",
   "metadata": {},
   "source": [
    "# Changes from v13\n",
    "* Splitting out the data by CPT section and running one model for each one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-basis",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "## Questions\n",
    "* Run the data for each category with only no filter, one, and three CPT codes for each discharge summary\n",
    "    * ANSWER: It performs better with only 1 CPT per note and 3 had a decrease of 3% in accuracy\n",
    "* Does including all notes/CPT sections improve accuracy?\n",
    "    * ANSWER: No, it decreased the accuracy\n",
    "* Does including some sections improve accuracy when included with discharge summary?\n",
    "    * No, accuracy went from 80% to 71%- at least for the E/M category\n",
    "* Does accuracy improve when there are more notes per CPT code?\n",
    "    * Yes\n",
    "* What is the lowest threshold I can use without decreasing accuracy?\n",
    "    * It seems like I don't need a threshold\n",
    "* Does imbalance correction improve model accuracy?\n",
    "    * Yes, it makes a huge difference\n",
    "* Is undersampling or over-sampling a better method for imbalance correction?\n",
    "    * Oversampling since the lowest records only contain one note - could also try SMOTE and see if that gives better results or not\n",
    "* Use label encoder for the CPT codes\n",
    "    * Does the accuracy improve when using labelencoder?\n",
    "* Is limiting CPT codes to just one excluding CPT codes?\n",
    "    * No\n",
    "* Can I use the descriptions in the CPT table to help improve my analysis?\n",
    "    * Yes, only for 94002 and 94003\n",
    "* Do a greater variety of CPT scores improve CPT f-scores?\n",
    "    * No, they slightly change, but probably only b/c what goes in train and test changes\n",
    "* Does the accuracy improve when filtered to each CPT section individually?\n",
    "    * Yes\n",
    "\n",
    "\n",
    "\n",
    "# Next Steps\n",
    "\n",
    "* Adjust model so it can be run in smaller chunks\n",
    "* Check the accuracy for those CPT codes in v13 and see if accuracy decreased when looking at individual sections\n",
    "    * Add option to run the code without stratifying by section\n",
    "* Complete model to predict CPT and ICD codes with their probabilities\n",
    "* Serialize the model to be used in streamlit\n",
    "* Add loading statements with time it module times for how long each section takes to run\n",
    "* Add HCC code that suggests HCC's based on the output\n",
    "* Add descriptions for the ICD and CPT code predictions\n",
    "* Add top most predictive feature names for the model in the output\n",
    "* Use label encoder and then reverse transform the encoded values\n",
    "\n",
    "Extra:\n",
    "* Add K-Means clustering to add suggested codes based on CPT and ICD code output\n",
    "* Add the model to a class with functions as methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-sharing",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "answering-retro",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import glob\n",
    "import string\n",
    "from sklearn.utils import resample\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-alabama",
   "metadata": {},
   "source": [
    "\n",
    "# Import the MIMIC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "environmental-character",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amartins\\onedrive - intermountain healthcare\\python_pycharm_virt_env\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (4,5,7,11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "c:\\users\\amartins\\onedrive - intermountain healthcare\\python_pycharm_virt_env\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (4,5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "dataset_dictionary = {}\n",
    "\n",
    "for file_path in glob.glob('.\\\\Data\\\\MIMIC Files\\*'):\n",
    "    file_name = file_path.split('\\\\')[3].split('.')[0]\n",
    "    with gzip.open(file_path, mode='r') as file:\n",
    "        dataset_dictionary[file_name] = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-literature",
   "metadata": {},
   "source": [
    "# Assign Datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "delayed-moscow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['CPTEVENTS', 'DIAGNOSES_ICD', 'D_CPT', 'D_ICD_DIAGNOSES', 'D_ICD_PROCEDURES', 'NOTEEVENTS', 'PATIENTS', 'PROCEDURES_ICD'])\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 573146 entries, 0 to 573145\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   ROW_ID            573146 non-null  int64  \n",
      " 1   SUBJECT_ID        573146 non-null  int64  \n",
      " 2   HADM_ID           573146 non-null  int64  \n",
      " 3   COSTCENTER        573146 non-null  object \n",
      " 4   CHARTDATE         101545 non-null  object \n",
      " 5   CPT_CD            573146 non-null  object \n",
      " 6   CPT_NUMBER        573128 non-null  float64\n",
      " 7   CPT_SUFFIX        22 non-null      object \n",
      " 8   TICKET_ID_SEQ     471601 non-null  float64\n",
      " 9   SECTIONHEADER     573146 non-null  object \n",
      " 10  SUBSECTIONHEADER  573125 non-null  object \n",
      " 11  DESCRIPTION       101545 non-null  object \n",
      "dtypes: float64(2), int64(3), object(7)\n",
      "memory usage: 52.5+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 651047 entries, 0 to 651046\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   ROW_ID      651047 non-null  int64  \n",
      " 1   SUBJECT_ID  651047 non-null  int64  \n",
      " 2   HADM_ID     651047 non-null  int64  \n",
      " 3   SEQ_NUM     651000 non-null  float64\n",
      " 4   ICD9_CODE   651000 non-null  object \n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 24.8+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 134 entries, 0 to 133\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   ROW_ID               134 non-null    int64 \n",
      " 1   CATEGORY             134 non-null    int64 \n",
      " 2   SECTIONRANGE         134 non-null    object\n",
      " 3   SECTIONHEADER        134 non-null    object\n",
      " 4   SUBSECTIONRANGE      134 non-null    object\n",
      " 5   SUBSECTIONHEADER     134 non-null    object\n",
      " 6   CODESUFFIX           11 non-null     object\n",
      " 7   MINCODEINSUBSECTION  134 non-null    int64 \n",
      " 8   MAXCODEINSUBSECTION  134 non-null    int64 \n",
      "dtypes: int64(4), object(5)\n",
      "memory usage: 9.5+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14567 entries, 0 to 14566\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   ROW_ID       14567 non-null  int64 \n",
      " 1   ICD9_CODE    14567 non-null  object\n",
      " 2   SHORT_TITLE  14567 non-null  object\n",
      " 3   LONG_TITLE   14567 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 455.3+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3882 entries, 0 to 3881\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   ROW_ID       3882 non-null   int64 \n",
      " 1   ICD9_CODE    3882 non-null   int64 \n",
      " 2   SHORT_TITLE  3882 non-null   object\n",
      " 3   LONG_TITLE   3882 non-null   object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 121.4+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2083180 entries, 0 to 2083179\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Dtype  \n",
      "---  ------       -----  \n",
      " 0   ROW_ID       int64  \n",
      " 1   SUBJECT_ID   int64  \n",
      " 2   HADM_ID      float64\n",
      " 3   CHARTDATE    object \n",
      " 4   CHARTTIME    object \n",
      " 5   STORETIME    object \n",
      " 6   CATEGORY     object \n",
      " 7   DESCRIPTION  object \n",
      " 8   CGID         float64\n",
      " 9   ISERROR      float64\n",
      " 10  TEXT         object \n",
      "dtypes: float64(3), int64(2), object(6)\n",
      "memory usage: 174.8+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 46520 entries, 0 to 46519\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   ROW_ID       46520 non-null  int64 \n",
      " 1   SUBJECT_ID   46520 non-null  int64 \n",
      " 2   GENDER       46520 non-null  object\n",
      " 3   DOB          46520 non-null  object\n",
      " 4   DOD          15759 non-null  object\n",
      " 5   DOD_HOSP     9974 non-null   object\n",
      " 6   DOD_SSN      13378 non-null  object\n",
      " 7   EXPIRE_FLAG  46520 non-null  int64 \n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 2.8+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 240095 entries, 0 to 240094\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count   Dtype\n",
      "---  ------      --------------   -----\n",
      " 0   ROW_ID      240095 non-null  int64\n",
      " 1   SUBJECT_ID  240095 non-null  int64\n",
      " 2   HADM_ID     240095 non-null  int64\n",
      " 3   SEQ_NUM     240095 non-null  int64\n",
      " 4   ICD9_CODE   240095 non-null  int64\n",
      "dtypes: int64(5)\n",
      "memory usage: 9.2 MB\n",
      "None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'to_datetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-1384668da6e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# CPTEVENTS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mdataset_dictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CPTEVENTS'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SECTIONHEADER'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'CPT_CD'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_dictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CPTEVENTS'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SECTIONHEADER'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'CPT_CD'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mdataset_dictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CPTEVENTS'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CHARTDATE'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_dictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CPTEVENTS'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CHARTDATE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\amartins\\onedrive - intermountain healthcare\\python_pycharm_virt_env\\.venv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5460\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5461\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5462\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5464\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'to_datetime'"
     ]
    }
   ],
   "source": [
    "# Check all the datasets exist in the dictionary \n",
    "print(dataset_dictionary.keys())\n",
    "\n",
    "# Check the datatypes and information for each table \n",
    "for i in dataset_dictionary.keys():\n",
    "    print(dataset_dictionary[i].info())\n",
    "\n",
    "# Correct any datatype issues #####\n",
    "\n",
    "# CPTEVENTS\n",
    "dataset_dictionary['CPTEVENTS'].loc[:,['SECTIONHEADER','CPT_CD']] = dataset_dictionary['CPTEVENTS'].loc[:,['SECTIONHEADER','CPT_CD']].astype(str)\n",
    "dataset_dictionary['CPTEVENTS']['CHARTDATE'] = dataset_dictionary['CPTEVENTS']['CHARTDATE'].to_datetime()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historical-raise",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis - CPTEVENTS Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "pediatric-louis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total CPT counts per section\n",
      "\n",
      " SECTIONHEADER\n",
      "Anesthesia                      687\n",
      "Emerging technology              22\n",
      "Evaluation and management    404388\n",
      "Medicine                     114194\n",
      "Pathology and laboratory         53\n",
      "Radiology                      2974\n",
      "Surgery                       50807\n",
      "nan                              21\n",
      "Name: CPT_CD, dtype: int64\n",
      "\n",
      "Total Unique CPT counts per section\n",
      "\n",
      " SECTIONHEADER\n",
      "Anesthesia                      5\n",
      "Emerging technology             8\n",
      "Evaluation and management      58\n",
      "Medicine                       91\n",
      "Pathology and laboratory        4\n",
      "Radiology                      61\n",
      "Surgery                      1784\n",
      "nan                             7\n",
      "Name: CPT_CD, dtype: int64\n",
      "\n",
      " Section Header: Anesthesia \n",
      "\n",
      "count      5.000000\n",
      "mean     137.400000\n",
      "std      243.206291\n",
      "min        2.000000\n",
      "25%       21.000000\n",
      "50%       37.000000\n",
      "75%       56.000000\n",
      "max      571.000000\n",
      "Name: CPT_CD, dtype: float64\n",
      "\n",
      " Section Header: Emerging technology \n",
      "\n",
      "count    8.00000\n",
      "mean     2.75000\n",
      "std      2.54951\n",
      "min      1.00000\n",
      "25%      1.00000\n",
      "50%      1.50000\n",
      "75%      3.50000\n",
      "max      8.00000\n",
      "Name: CPT_CD, dtype: float64\n",
      "\n",
      " Section Header: Evaluation and management \n",
      "\n",
      "count        58.000000\n",
      "mean       6972.206897\n",
      "std       22252.229542\n",
      "min           1.000000\n",
      "25%           7.000000\n",
      "50%          32.500000\n",
      "75%         963.250000\n",
      "max      108434.000000\n",
      "Name: CPT_CD, dtype: float64\n",
      "\n",
      " Section Header: Medicine \n",
      "\n",
      "count       91.000000\n",
      "mean      1254.879121\n",
      "std       9325.079213\n",
      "min          1.000000\n",
      "25%          1.000000\n",
      "50%          5.000000\n",
      "75%         15.000000\n",
      "max      87984.000000\n",
      "Name: CPT_CD, dtype: float64\n",
      "\n",
      " Section Header: Pathology and laboratory \n",
      "\n",
      "count     4.000000\n",
      "mean     13.250000\n",
      "std      19.534158\n",
      "min       1.000000\n",
      "25%       1.000000\n",
      "50%       5.000000\n",
      "75%      17.250000\n",
      "max      42.000000\n",
      "Name: CPT_CD, dtype: float64\n",
      "\n",
      " Section Header: Radiology \n",
      "\n",
      "count      61.000000\n",
      "mean       48.754098\n",
      "std       179.448475\n",
      "min         1.000000\n",
      "25%         1.000000\n",
      "50%         5.000000\n",
      "75%        17.000000\n",
      "max      1050.000000\n",
      "Name: CPT_CD, dtype: float64\n",
      "\n",
      " Section Header: Surgery \n",
      "\n",
      "count    1784.000000\n",
      "mean       28.479260\n",
      "std       168.369641\n",
      "min         1.000000\n",
      "25%         1.000000\n",
      "50%         3.000000\n",
      "75%        11.000000\n",
      "max      4150.000000\n",
      "Name: CPT_CD, dtype: float64\n",
      "\n",
      " Section Header: nan \n",
      "\n",
      "count    7.000000\n",
      "mean     3.000000\n",
      "std      2.236068\n",
      "min      1.000000\n",
      "25%      1.500000\n",
      "50%      2.000000\n",
      "75%      4.000000\n",
      "max      7.000000\n",
      "Name: CPT_CD, dtype: float64\n",
      "\n",
      "Total Unique CPT counts per section\n",
      "\n",
      " SECTIONHEADER\n",
      "Anesthesia                      5\n",
      "Emerging technology             8\n",
      "Evaluation and management      58\n",
      "Medicine                       91\n",
      "Pathology and laboratory        4\n",
      "Radiology                      60\n",
      "Surgery                      1758\n",
      "nan                             7\n",
      "Name: CPT_CD, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# How many CPT codes are in the data for each CPT section? -----\n",
    "data_cpt = dataset_dictionary['CPTEVENTS']\n",
    "print('\\nTotal CPT counts per section\\n\\n', data_cpt.groupby('SECTIONHEADER')['CPT_CD'].count())\n",
    "\n",
    "# How many unique CPT codes are there per CPT section? -----\n",
    "data_nodups = data_cpt.loc[:,['CPT_CD', 'SECTIONHEADER']].drop_duplicates()\n",
    "print('\\nTotal Unique CPT counts per section\\n\\n', data_nodups.groupby('SECTIONHEADER')['CPT_CD'].count())\n",
    "\n",
    "# What is the distribution of counts for each CPT code per section? -----\n",
    "for i in np.unique(data_cpt['SECTIONHEADER']):\n",
    "    print('\\n Section Header:',i,'\\n')\n",
    "    print(data_cpt[data_cpt['SECTIONHEADER'] == i].groupby('CPT_CD')['CPT_CD'].count().describe())\n",
    "    \n",
    "# How many unique CPT codes are there per CPT section when filtered to the Discharge Summary Section in the Note Events Table? -----\n",
    "data_notes = dataset_dictionary['NOTEEVENTS']\n",
    "data_notes = data_notes[data_notes['CATEGORY'] == 'Discharge summary']\n",
    "data_merged = data_notes.merge(data_cpt, on = ['SUBJECT_ID','HADM_ID'])\n",
    "data_nodups = data_merged.loc[:,['CPT_CD', 'SECTIONHEADER']].drop_duplicates()\n",
    "print('\\nTotal Unique CPT counts per section\\n\\n', data_nodups.groupby('SECTIONHEADER')['CPT_CD'].count())\n",
    "\n",
    "# Are there multiple CPT codes per encounter? -----\n",
    "# Answer: Yes\n",
    "\n",
    "data_cpt.groupby('HADM_ID')['CPT_CD'].count()\n",
    "\n",
    "# What percentage of encounters only have one CPT code?\n",
    "# Answer: 8.3%\n",
    "data_grouped = data_cpt.groupby('HADM_ID')['CPT_CD'].count()\n",
    "(data_grouped == 1).sum()/ len(np.unique(data_cpt['HADM_ID']))\n",
    "\n",
    "# What does the distribution look like for number of CPT codes per encounter?\n",
    "data_grouped = data_cpt.groupby('HADM_ID')['CPT_CD'].count()\n",
    "plt.hist(data_grouped, bins=range(21))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-nursing",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis - NOTEEVENTS Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "willing-israel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Case Management ' 'Consult' 'Discharge summary' 'ECG' 'Echo' 'General'\n",
      " 'Nursing' 'Nursing/other' 'Nutrition' 'Pharmacy' 'Physician ' 'Radiology'\n",
      " 'Rehab Services' 'Respiratory ' 'Social Work']\n",
      "Chief Complaint:\n",
      "   24 Hour Events:\n",
      " Continued to be anuric.  Tolerated HD well.  Decision today by pt and\n",
      "   wife to convert to [**Name (NI) 617**].\n",
      "   History obtained from Patient\n",
      "   Allergies:\n",
      "   History obtained from PatientHeparin Agents\n",
      "   Thrombocytopeni\n",
      "   Last dose of Antibiotics:\n",
      "   Piperacillin - [**2138-3-20**] 08:00 PM\n",
      "   Piperacillin/Tazobactam (Zosyn) - [**2138-3-21**] 09:00 AM\n",
      "   Metronidazole - [**2138-3-21**] 10:12 AM\n",
      "   Infusions:\n",
      "   Other ICU medications:\n",
      "   Other medications:\n",
      "   Changes to medical and family history:\n",
      "   Review of systems is unchanged from admission except as noted below\n",
      "   Review of systems:\n",
      "   Flowsheet Data as of  [**2138-3-21**] 02:56 PM\n",
      "   Vital signs\n",
      "   Hemodynamic monitoring\n",
      "   Fluid balance\n",
      "                                                                  24 hours\n",
      "                                                               Since 12 AM\n",
      "   Tmax: 36.6\n",
      "C (97.9\n",
      "   Tcurrent: 36.1\n",
      "C (96.9\n",
      "   HR: 113 (103 - 115) bpm\n",
      "   BP: 106/58(71){91/45(58) - 106/67(76)} mmHg\n",
      "   RR: 23 (16 - 26) insp/min\n",
      "   SpO2: 100%\n",
      "   Heart rhythm: ST (Sinus Tachycardia)\n",
      "   Height: 72 Inch\n",
      "             Total In:\n",
      "                                                                    700 mL\n",
      "                                                                    569 mL\n",
      "   PO:\n",
      "                                                                    200 mL\n",
      "                                                                    220 mL\n",
      "   TF:\n",
      "   IVF:\n",
      "                                                                    500 mL\n",
      "                                                                    349 mL\n",
      "   Blood products:\n",
      "   Total out:\n",
      "                                                                     43 mL\n",
      "                                                                    163 mL\n",
      "   Urine:\n",
      "                                                                     43 mL\n",
      "                                                                     18 mL\n",
      "   NG:\n",
      "   Stool:\n",
      "   Drains:\n",
      "   Balance:\n",
      "                                                                    657 mL\n",
      "                                                                    406 mL\n",
      "   Respiratory support\n",
      "   O2 Delivery Device: None\n",
      "   SpO2: 100%\n",
      "   ABG: ///19/\n",
      "   Physical Examination\n",
      "   General Appearance: No acute distress\n",
      "   Head, Ears, Nose, Throat: Normocephalic\n",
      "   Cardiovascular: (S1: Normal), (S2: Normal), (Murmur: Systolic)\n",
      "   Peripheral Vascular: (Right radial pulse: Not assessed), (Left radial\n",
      "   pulse: Not assessed), (Right DP pulse: Not assessed), (Left DP pulse:\n",
      "   Not assessed)\n",
      "   Respiratory / Chest: (Expansion: Symmetric), (Breath Sounds: Clear : )\n",
      "   Abdominal: Soft, Non-tender, Bowel sounds present\n",
      "   Extremities: Right: 1+, Left: 1+\n",
      "   Musculoskeletal: Unable to stand\n",
      "   Skin:  Not assessed\n",
      "   Neurologic: Attentive, Follows simple commands, Responds to: Not\n",
      "   assessed, Movement: Not assessed, Tone: Not assessed\n",
      "   Labs / Radiology\n",
      "   233 K/uL\n",
      "   8.5 g/dL\n",
      "   173 mg/dL\n",
      "   4.4 mg/dL\n",
      "   19 mEq/L\n",
      "   4.3 mEq/L\n",
      "   87 mg/dL\n",
      "   111 mEq/L\n",
      "   143 mEq/L\n",
      "   27.8 %\n",
      "   5.1 K/uL\n",
      "        [image002.jpg]\n",
      "                             [**2138-3-17**]  07:46 PM\n",
      "                             [**2138-3-18**]  05:42 AM\n",
      "                             [**2138-3-18**]  01:56 PM\n",
      "                             [**2138-3-19**]  05:59 AM\n",
      "                             [**2138-3-19**]  04:41 PM\n",
      "                             [**2138-3-19**]  08:27 PM\n",
      "                             [**2138-3-20**]  04:52 AM\n",
      "                             [**2138-3-20**]  04:38 PM\n",
      "                             [**2138-3-21**]  04:37 AM\n",
      "   WBC\n",
      "   14.8\n",
      "   5.0\n",
      "   6.1\n",
      "   5.8\n",
      "   5.1\n",
      "   Hct\n",
      "   31.8\n",
      "   28.8\n",
      "   28.7\n",
      "   28.0\n",
      "   27.8\n",
      "   Plt\n",
      "   [**Telephone/Fax (3) 745**]85\n",
      "   233\n",
      "   Cr\n",
      "   4.5\n",
      "   4.3\n",
      "   4.5\n",
      "   4.5\n",
      "   4.8\n",
      "   4.9\n",
      "   5.2\n",
      "   4.2\n",
      "   4.4\n",
      "   TropT\n",
      "   0.42\n",
      "   0.35\n",
      "   0.33\n",
      "   Glucose\n",
      "   [**Telephone/Fax (3) 696**]64\n",
      "   163\n",
      "   152\n",
      "   208\n",
      "   173\n",
      "   Other labs: PT / PTT / INR:13.9/32.0/1.2, CK / CKMB /\n",
      "   Troponin-T:10/4/0.33, Amylase / Lipase:45/34, Differential-Neuts:94.1\n",
      "   %, Band:Units: %\n",
      "   Range: 0-5 %, Lymph:4.2 %, Mono:1.6 %, Eos:Units: %\n",
      "   Range: 0-4 %, Fibrinogen:399 mg/dL, Lactic Acid:1.0 mmol/L, Albumin:2.1\n",
      "   g/dL, Ca++:8.1 mg/dL, Mg++:1.9 mg/dL, PO4:5.5 mg/dL\n",
      "   Assessment and Plan\n",
      "   1. [**Telephone/Fax (3) 617**]: Pt and wife desired to transition to [**Name (NI) 617**] today; palliative care\n",
      "   following.  Review palliative care recs.\n",
      "   2.  Renal failure:  Anuric, s/p HD yesterday, scheduled for HD today\n",
      "   and tomorrow per renal; however, pt and wife now want to stop HD. Cr\n",
      "   down to 4.4 from 5.2 and K+ 4.4 from 5.2.\n",
      "   3.  Pulmonary Edema:  Worsened on CXR from yesterday, no subjective\n",
      "   dyspnea.  No crackles heard on anterior exam as fluid is dependant.\n",
      "   Cause is multifactorial including pseudomonal UTI likely resulting in\n",
      "   sepsis, poor nutritional status, low EF of 40% and aortic stenosis.  Pt\n",
      "   now [**Name (NI) 617**].\n",
      "   4. ESRD:  S/p B renal transplant, on tacrolimus and steriods.  Now [**Name (NI) 617**],\n",
      "   d/c tacrolimus and steroids.\n",
      "   5.  Pseudomonal UTI:  Now [**Name (NI) 617**].\n",
      "   6.  Fever/Hypotension:  Resolved.  Pt now [**Name (NI) 617**], d/c all antibiotics.\n",
      "   7.  Prostate Cancer:  [**Name (NI) 617**].  D/c Lupron.\n",
      "   ICU Care:  PT NOW [**Name (NI) 617**].\n",
      "   Nutrition:\n",
      "   Glycemic Control:\n",
      "   Lines:\n",
      "   Presep Catheter - [**2138-3-17**] 03:30 PM\n",
      "   Prophylaxis:\n",
      "   DVT:\n",
      "   Stress ulcer:\n",
      "   VAP:\n",
      "   Comments:\n",
      "   Communication:  Comments:\n",
      "   Code status: DNR / DNI ; [**Year (4 digits) 617**]\n",
      "   Disposition:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CATEGORY\n",
       "Case Management         967\n",
       "Consult                  98\n",
       "Discharge summary     59652\n",
       "ECG                  209051\n",
       "Echo                  45794\n",
       "General                8301\n",
       "Nursing              223556\n",
       "Nursing/other        822497\n",
       "Nutrition              9418\n",
       "Pharmacy                103\n",
       "Physician            141624\n",
       "Radiology            522279\n",
       "Rehab Services         5431\n",
       "Respiratory           31739\n",
       "Social Work            2670\n",
       "Name: CATEGORY, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dataset_dictionary['NOTEEVENTS']\n",
    "\n",
    "# What are the unique categories?\n",
    "print(np.unique(data['CATEGORY']))\n",
    "\n",
    "# What do some of the notes look like in each category?\n",
    "print(data[data['CATEGORY'] == 'Physician ']['TEXT'].iloc[0])\n",
    "\n",
    "# How many notes are there per category?\n",
    "data.groupby('CATEGORY')['CATEGORY'].count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-desert",
   "metadata": {},
   "source": [
    "# Join the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "grateful-tracker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Discharge summary'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-35-339a9c08c549>:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x['DESCRIPTION'] = ''\n"
     ]
    }
   ],
   "source": [
    "def join_tables(dataset_dictionary, category=['Discharge summary'], all_notes=False):\n",
    "\n",
    "    # Define tables\n",
    "    note_events_base = dataset_dictionary['NOTEEVENTS']\n",
    "    cpt_events_base = dataset_dictionary['CPTEVENTS']\n",
    "    \n",
    "    # Combine text for each subject and encounter\n",
    "    if all_notes == False:\n",
    "        note_events_base = note_events_base[note_events_base.loc[:,'CATEGORY'].isin(category)]\n",
    "        \n",
    "    note_events = note_events_base.groupby(['SUBJECT_ID', 'HADM_ID'], as_index=False)['TEXT'].agg(sum)\n",
    "    \n",
    "    # Create CPT table\n",
    "    cpt_events_base = cpt_events_base.loc[:, ['SUBJECT_ID','HADM_ID', 'CPT_CD', 'SECTIONHEADER', 'DESCRIPTION']]\n",
    "    cpt_events = cpt_events_base.drop_duplicates()\n",
    "    \n",
    "    # Join the datasets\n",
    "    note_cpt = note_events.merge(cpt_events, on = ['SUBJECT_ID','HADM_ID'])\n",
    "    \n",
    "    # Replace any nulls with blanks\n",
    "    x = note_cpt[note_cpt['DESCRIPTION'].isnull()]\n",
    "    x['DESCRIPTION'] = ''\n",
    "    y = note_cpt[note_cpt['DESCRIPTION'].notnull()]\n",
    "    note_cpt = pd.concat([x,y])\n",
    "    \n",
    "    # Combine description and text columns\n",
    "    note_cpt['TEXT'] = note_cpt['TEXT'] + note_cpt['DESCRIPTION']\n",
    "    note_cpt = note_cpt.drop('DESCRIPTION', axis=1)\n",
    "    \n",
    "    return note_cpt\n",
    "    \n",
    "note_cpt = join_tables(dataset_dictionary)\n",
    "# ['Consult','Discharge summary','General', 'Nursing', 'Nursing/other'\\\n",
    "#                                             , 'Physician ','Rehab Services','Respiratory ']\n",
    "\n",
    "# Drop notes with the nan sectionheader\n",
    "drop_ls = note_cpt[note_cpt['SECTIONHEADER'] == 'nan']\n",
    "note_cpt = note_cpt.drop(drop_ls.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-adelaide",
   "metadata": {},
   "source": [
    "# Join the Tables - Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "covered-lecture",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99291    25967\n",
       "99232    23987\n",
       "99233    22791\n",
       "99231    12441\n",
       "99223     9271\n",
       "99239     8775\n",
       "99254     7896\n",
       "99222     6846\n",
       "99238     6342\n",
       "99255     5512\n",
       "99253     5377\n",
       "99292     3864\n",
       "99252     2194\n",
       "99221     1574\n",
       "99251      771\n",
       "99262      575\n",
       "99356      533\n",
       "99261      466\n",
       "99263      268\n",
       "99358      202\n",
       "99235      131\n",
       "99220      102\n",
       "99236       97\n",
       "99367       87\n",
       "99357       59\n",
       "99234       59\n",
       "99219       50\n",
       "99359       34\n",
       "99366       34\n",
       "99274       25\n",
       "99368       22\n",
       "99272       21\n",
       "99218       19\n",
       "99271       17\n",
       "99217       15\n",
       "99225       15\n",
       "99205       12\n",
       "99273       10\n",
       "99361        9\n",
       "99214        9\n",
       "99204        8\n",
       "99362        7\n",
       "99275        7\n",
       "99226        7\n",
       "99406        6\n",
       "99408        6\n",
       "99215        5\n",
       "99224        3\n",
       "99213        2\n",
       "99441        2\n",
       "99373        2\n",
       "99202        1\n",
       "99371        1\n",
       "99203        1\n",
       "99372        1\n",
       "99244        1\n",
       "99407        1\n",
       "99212        1\n",
       "Name: CPT_CD, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the base table against the new table after joins\n",
    "note_cpt[note_cpt['HADM_ID'] == 199993]\n",
    "data = dataset_dictionary['CPTEVENTS']\n",
    "data[data['HADM_ID'] == 199993].loc[:,['SUBJECT_ID','HADM_ID', 'CPT_CD', 'SECTIONHEADER']].drop_duplicates()\n",
    "\n",
    "# Check the length of the new table\n",
    "note_cpt # 223,690 v 222,885\n",
    "\n",
    "# Check value count for E/M CPT codes\n",
    "note_cpt[note_cpt['SECTIONHEADER'] == 'Evaluation and management']['CPT_CD'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-dealing",
   "metadata": {},
   "source": [
    "# Filter the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "pursuant-thumbnail",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(combined_df, threshold):\n",
    "\n",
    "    # Print value counts original\n",
    "    print('Value Counts for the original data:\\n\\n', combined_df['CPT_CD'].value_counts().head(25))\n",
    "\n",
    "    # Filter based on count limit\n",
    "    df = combined_df['CPT_CD'].value_counts()\n",
    "    filtered_ls = list((df[df >= threshold]).index.values)\n",
    "    filtered_df = combined_df[combined_df['CPT_CD'].isin(filtered_ls)]\n",
    "    \n",
    "    # Print value counts filtered\n",
    "    print('Value Counts for the filtered data:\\n\\n', combined_df['CPT_CD'].value_counts().head(25))\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "# Find Counts of CPT Codes per Patient Encounter and filter df\n",
    "def cpt_count_filter(df, og_df, cpt_section_hadm_limit, cpt_hadm_limit):\n",
    "    \n",
    "    # Filter based on limit per SECTIONHEADER & merge\n",
    "    df1 = og_df.groupby(['HADM_ID', 'SECTIONHEADER'])['CPT_CD'].count()\n",
    "    filtered_encntrs = df1[df1 <= cpt_section_hadm_limit]\n",
    "    final_df = df.merge(filtered_encntrs, on=['HADM_ID', 'SECTIONHEADER'])\n",
    "    final_df.drop('CPT_CD_y', axis=1, inplace=True)\n",
    "    \n",
    "    # Filter dataset again based on total number of CPT codes per HADM\n",
    "    df2 = og_df.groupby(['HADM_ID'])['CPT_CD'].count()\n",
    "    filtered_encntrs = df2[df2 <= cpt_hadm_limit]\n",
    "    final_df = final_df.merge(filtered_encntrs, on=['HADM_ID'])\n",
    "    final_df.drop('CPT_CD', axis=1, inplace=True)\n",
    "    \n",
    "    # Rename columns\n",
    "    final_df.columns = ['SUBJECT_ID', 'HADM_ID', 'TEXT', 'CPT_CD', 'SECTIONHEADER']\n",
    "    \n",
    "    print('Value Counts for the filtered data:\\n\\n', final_df['CPT_CD'].value_counts().head(50))\n",
    "\n",
    "    return final_df\n",
    "    \n",
    "# Filter DataFrame to a set amount of CPT codes in each section header #####\n",
    "def cpt_per_section_filter(df, section_limit, sections=['Emerging technology'], all_sections=False):\n",
    "    \n",
    "    # Create list for dataframes\n",
    "    df_ls = []\n",
    "\n",
    "    # Group by and count the number of CPT codes\n",
    "    cts_by_cpt = df.groupby(['SECTIONHEADER', 'CPT_CD'])['CPT_CD'].count()\n",
    "    cts_by_cpt.index.names = ['SECTIONHEADER', 'CPT_CDS']\n",
    "    cts_by_cpt = cts_by_cpt.reset_index()\n",
    "    cts_by_cpt.columns = ['SECTIONHEADER', 'CPT_CD', 'COUNT']\n",
    "\n",
    "    # Sort values by section and CPT code count\n",
    "    cts_by_cpt_s = cts_by_cpt.sort_values(by=['SECTIONHEADER','COUNT'], ascending=False)\n",
    "\n",
    "    # Filter based on the limit of CPT codes wanted for each category\n",
    "    if all_sections == True:\n",
    "        sections = list(set(df['SECTIONHEADER']))\n",
    "        \n",
    "    for i in sections:\n",
    "        top_cts = cts_by_cpt_s[cts_by_cpt_s['SECTIONHEADER'] == i].iloc[:section_limit,:]\n",
    "\n",
    "        # Append to list\n",
    "        df_ls.append(top_cts)\n",
    "\n",
    "    # Combine DataFrames\n",
    "    df_combo = pd.concat(df_ls)\n",
    "\n",
    "    # Join back to source data\n",
    "    final_df = df.merge(df_combo, on=['SECTIONHEADER','CPT_CD'])\n",
    "    \n",
    "    print('\\nThe length of the initial dataset was {} and the new dataset is {}\\n\\n'.format(len(df), len(final_df)))\n",
    "\n",
    "    return final_df\n",
    "\n",
    "def show_section_counts(df):\n",
    "    # Print count of CPT codes by section\n",
    "    cts_by_cpt = df.groupby(['SECTIONHEADER', 'CPT_CD'])['CPT_CD'].count()\n",
    "    cts_by_section = cts_by_cpt.groupby('SECTIONHEADER').count()\n",
    "    print('\\nHere are the counts by section:\\n\\n', cts_by_section)\n",
    "\n",
    "def show_cpt_counts_by_section(df):\n",
    "    cts_by_cpt = df.groupby(['SECTIONHEADER', 'CPT_CD'])['CPT_CD'].count()\n",
    "    print('\\nHere are the counts by CPT by section\\n\\n:')\n",
    "#     print(pd.DataFrame(cts_by_cpt.rename('Count')).reset_index())\n",
    "    for i, x in pd.DataFrame(cts_by_cpt.rename('Count')).reset_index().iterrows():\n",
    "        print(x['SECTIONHEADER'], x['CPT_CD'], x['Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "encouraging-music",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Counts for the filtered data:\n",
      "\n",
      " 94003    12877\n",
      "94002     8212\n",
      "99291     4758\n",
      "99232     2386\n",
      "99233     1924\n",
      "36556     1789\n",
      "99254     1170\n",
      "99231     1080\n",
      "99223     1037\n",
      "90935     1027\n",
      "99222      971\n",
      "99253      865\n",
      "99255      700\n",
      "36620      661\n",
      "99238      485\n",
      "31624      469\n",
      "76942      447\n",
      "33405      436\n",
      "76937      352\n",
      "31645      342\n",
      "99252      334\n",
      "31622      315\n",
      "99292      313\n",
      "99239      312\n",
      "99221      268\n",
      "90801      238\n",
      "62270      225\n",
      "31500      194\n",
      "01996      179\n",
      "99024      169\n",
      "90945      154\n",
      "90937      150\n",
      "36489      146\n",
      "32002      140\n",
      "49080      128\n",
      "61312      124\n",
      "99251      111\n",
      "43246      108\n",
      "93503      107\n",
      "33427      107\n",
      "31600      105\n",
      "33430       93\n",
      "33533       91\n",
      "92960       90\n",
      "47135       89\n",
      "33860       87\n",
      "54150       84\n",
      "32422       83\n",
      "27245       80\n",
      "32000       75\n",
      "Name: CPT_CD, dtype: int64\n",
      "Available sections:\n",
      "\n",
      " {'Pathology and laboratory', 'Evaluation and management', 'Emerging technology', 'Anesthesia', 'Radiology', 'Medicine', 'Surgery'}\n",
      "\n",
      "The length of the initial dataset was 52768 and the new dataset is 44423\n",
      "\n",
      "\n",
      "Value Counts for the original data:\n",
      "\n",
      " 94003    12877\n",
      "94002     8212\n",
      "99291     4758\n",
      "99232     2386\n",
      "99233     1924\n",
      "36556     1789\n",
      "99254     1170\n",
      "99231     1080\n",
      "99223     1037\n",
      "90935     1027\n",
      "99222      971\n",
      "99253      865\n",
      "99255      700\n",
      "36620      661\n",
      "99238      485\n",
      "31624      469\n",
      "76942      447\n",
      "33405      436\n",
      "76937      352\n",
      "31645      342\n",
      "31622      315\n",
      "90801      238\n",
      "62270      225\n",
      "31500      194\n",
      "01996      179\n",
      "Name: CPT_CD, dtype: int64\n",
      "Value Counts for the filtered data:\n",
      "\n",
      " 94003    12877\n",
      "94002     8212\n",
      "99291     4758\n",
      "99232     2386\n",
      "99233     1924\n",
      "36556     1789\n",
      "99254     1170\n",
      "99231     1080\n",
      "99223     1037\n",
      "90935     1027\n",
      "99222      971\n",
      "99253      865\n",
      "99255      700\n",
      "36620      661\n",
      "99238      485\n",
      "31624      469\n",
      "76942      447\n",
      "33405      436\n",
      "76937      352\n",
      "31645      342\n",
      "31622      315\n",
      "90801      238\n",
      "62270      225\n",
      "31500      194\n",
      "01996      179\n",
      "Name: CPT_CD, dtype: int64\n",
      "\n",
      "Here are the counts by section:\n",
      "\n",
      " SECTIONHEADER\n",
      "Anesthesia                    1\n",
      "Evaluation and management    10\n",
      "Medicine                      8\n",
      "Radiology                     2\n",
      "Surgery                      10\n",
      "Name: CPT_CD, dtype: int64\n",
      "\n",
      "Here are the counts by CPT by section\n",
      "\n",
      ":\n",
      "Anesthesia 01996 179\n",
      "Evaluation and management 99222 971\n",
      "Evaluation and management 99223 1037\n",
      "Evaluation and management 99231 1080\n",
      "Evaluation and management 99232 2386\n",
      "Evaluation and management 99233 1924\n",
      "Evaluation and management 99238 485\n",
      "Evaluation and management 99253 865\n",
      "Evaluation and management 99254 1170\n",
      "Evaluation and management 99255 700\n",
      "Evaluation and management 99291 4758\n",
      "Medicine 90801 238\n",
      "Medicine 90935 1027\n",
      "Medicine 90937 150\n",
      "Medicine 90945 154\n",
      "Medicine 93503 107\n",
      "Medicine 94002 8212\n",
      "Medicine 94003 12877\n",
      "Medicine 99024 169\n",
      "Radiology 76937 352\n",
      "Radiology 76942 447\n",
      "Surgery 31500 194\n",
      "Surgery 31622 315\n",
      "Surgery 31624 469\n",
      "Surgery 31645 342\n",
      "Surgery 32002 140\n",
      "Surgery 33405 436\n",
      "Surgery 36489 146\n",
      "Surgery 36556 1789\n",
      "Surgery 36620 661\n",
      "Surgery 62270 225\n"
     ]
    }
   ],
   "source": [
    "# Filter the number of CPT occurrences by section and CPT\n",
    "filtered_df1 = cpt_count_filter(note_cpt, note_cpt, 2, 10)\n",
    "\n",
    "# Show available sections\n",
    "print('Available sections:\\n\\n', set(filtered_df1['SECTIONHEADER']))\n",
    "\n",
    "# Filter to a set amount of CPT codes for each section header - only here to make the code run faster when testing\n",
    "filtered_df2 = cpt_per_section_filter(filtered_df1, 10, all_sections=True)\n",
    "\n",
    "# Filter to those CPT codes that have at least 5 sets of notes or more\n",
    "filtered_df = filter_df(filtered_df2, 100)\n",
    "\n",
    "# Show some dataset stats\n",
    "show_section_counts(filtered_df)\n",
    "show_cpt_counts_by_section(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-juice",
   "metadata": {},
   "source": [
    "# Filter the Data - Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "cleared-darwin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "1984\n",
      "count    42701.000000\n",
      "mean         5.238519\n",
      "std          3.553827\n",
      "min          1.000000\n",
      "25%          3.000000\n",
      "50%          5.000000\n",
      "75%          7.000000\n",
      "max         55.000000\n",
      "Name: CPT_CD, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAANSUlEQVR4nO3df4yk9V3A8ffHu1KFYgFvQ5Af3cMgCfEPuWwUbcsfBRWOylXbNEdspVpzMREFf6TZhsT2T+qPRk2aNmeLRaXQSGl68VKFYmtjYk/3jqPcceABvbaHx922TUqjRor9+Mc828wtOzu78zw7M5/j/UouO/Ps7MyH7zz7ZvaZmd3ITCRJ9fzApAeQJI3GgEtSUQZckooy4JJUlAGXpKI2j/PGtmzZkrOzs+O8SUkqb//+/d/IzJnl28ca8NnZWRYWFsZ5k5JUXkR8daXtHkKRpKIMuCQVZcAlqSgDLklFGXBJKsqAS1JRQwMeEXdHxKmIONS37YKIeDgijjYfz9/YMSVJy63lEfjHgRuWbZsHHsnMK4BHmvOSpDEaGvDM/CLwrWWbdwD3NKfvAd7S7ViSpGFGfSfmhZl5ojn9PHDhoAtGxC5gF8Bll1024s0NNzu/9/unj91104bdjiRNi9ZPYmbvT/oM/LM+mbk7M+cyc25m5mVv5ZckjWjUgJ+MiIsAmo+nuhtJkrQWowZ8D3Brc/pW4DPdjCNJWqu1vIzwPuBfgSsj4nhEvBu4C/i5iDgKXN+clySN0dAnMTPzlgGfuq7jWSRJ6+A7MSWpKAMuSUUZcEkqyoBLUlEGXJKKMuCSVJQBl6SiDLgkFWXAJakoAy5JRRlwSSrKgEtSUQZckooy4JJUlAGXpKIMuCQVZcAlqSgDLklFGXBJKsqAS1JRBlySijLgklSUAZekogy4JBVlwCWpKAMuSUUZcEkqyoBLUlEGXJKKMuCSVJQBl6SiDLgkFdUq4BHxuxFxOCIORcR9EfGDXQ0mSVrdyAGPiIuB3wHmMvMngE3Azq4GkyStru0hlM3AD0XEZuBs4D/bjyRJWouRA56ZzwF/AnwNOAF8OzMfWn65iNgVEQsRsbC4uDj6pJKk07Q5hHI+sAPYCvwocE5EvGP55TJzd2bOZebczMzM6JNKkk7T5hDK9cBXMnMxM78LPAj8bDdjSZKGaRPwrwHXRMTZERHAdcCRbsaSJA3T5hj4PuAB4ADweHNduzuaS5I0xOY2X5yZ7wPe19EskqR18J2YklSUAZekogy4JBVlwCWpKAMuSUUZcEkqyoBLUlEGXJKKMuCSVJQBl6SiDLgkFWXAJakoAy5JRRlwSSrKgEtSUWdkwGfn9056BEnacGdkwCXplcCAS1JRBlySijLgklSUAZekogy4JBVlwCWpKAMuSUUZcEkqyoBLUlEGXJKKMuCSVJQBl6SiDLgkFWXAJakoAy5JRbUKeEScFxEPRMSTEXEkIn6mq8EkSavb3PLr/xz4h8x8W0ScBZzdwUySpDUYOeAR8VrgWuBdAJn5IvBiN2NJkoZpcwhlK7AI/FVEPBoRH42IczqaS5I0RJuAbwa2AR/OzKuB/wLml18oInZFxEJELCwuLra4OUlSvzYBPw4cz8x9zfkH6AX9NJm5OzPnMnNuZmamxc1JkvqNHPDMfB74ekRc2Wy6Dniik6kkSUO1fRXKbwP3Nq9AeRb4tfYjSZLWolXAM/MgMNfNKJKk9fCdmJJUlAGXpKIMuCQVZcAlqSgDLklFGXBJKsqAS1JRBlySijLgklSUAZekogy4JBVlwCWpKAMuSUUZcEkqyoBLUlGvqIDPzu+d9AiS1JlXVMAl6UxiwCWpKAMuSUUZcEkqyoBLUlEGXJKKMuCSVJQBl6SiDLgkFWXAJakoAy5JRRlwSSrKgEtSUQZckooy4JJUlAGXpKIMuCQV1TrgEbEpIh6NiL/vYiBJ0tp08Qj8duBIB9cjSVqHVgGPiEuAm4CPdjOOJGmt2j4C/zPgPcD3Bl0gInZFxEJELCwuLra8ubWbnd/rHzGWdEYbOeAR8WbgVGbuX+1ymbk7M+cyc25mZmbUm5MkLdPmEfjrgZsj4hhwP/CmiPjbTqaSJA01csAz872ZeUlmzgI7gX/KzHd0NpkkaVW+DlySitrcxZVk5heAL3RxXZKktfERuCQVZcAlqSgDLklFGXBJKsqAS1JRBlySijLgklSUAZekogy4JBVlwCWpKAMuSUUZcEkqyoBLUlEGXJKKMuCSVFQnvw98mg36w8az83s5dtdNY55GkrrjI3BJKsqAS1JRBlySijLgklSUAZekogy4JBVlwCWpKAMuSUUZcEkqyoBLUlEGXJKKMuCSVJQBl6SiDLgkFWXAJakoAy5JRY0c8Ii4NCI+HxFPRMThiLi9y8EkSatr8xd5XgJ+PzMPRMS5wP6IeDgzn+hoNknSKkZ+BJ6ZJzLzQHP6O8AR4OKuBpMkra6TY+ARMQtcDexb4XO7ImIhIhYWFxe7uLmpMejvba52+fV+jSQN0jrgEfEa4FPAHZn5wvLPZ+buzJzLzLmZmZm2NydJarQKeES8il68783MB7sZSZK0Fm1ehRLAx4AjmfnB7kaSJK1Fm0fgrwfeCbwpIg42/7Z3NJckaYiRX0aYmf8CRIezSJLWwXdiSlJRBlySijLgklSUAZekogy4JBVlwCWpKAMuSUUZcEkqyoBLUlEGXJKKMuCSVJQBl6SiDLgkFWXAJakoAy5JRY38+8CrWumPCq+07dhdNw3cvpbrXu1yXZmd3zt0nv7PL803ymz9X9vmeoZd97DLLV1m2H+7TjfqfbaWde56fxjVeveJM2Ef8hG4JBVlwCWpKAMuSUUZcEkqyoBLUlEGXJKKMuCSVJQBl6SiDLgkFWXAJakoAy5JRRlwSSrKgEtSUQZckooy4JJUlAGXpKIMuCQV1SrgEXFDRDwVEU9HxHxXQ0mShhs54BGxCfgQcCNwFXBLRFzV1WCSpNW1eQT+U8DTmflsZr4I3A/s6GYsSdIwkZmjfWHE24AbMvM3mvPvBH46M29bdrldwK7m7JXAUyPOugX4xohfu5GmdS6Y3tmca32ca/2mdbZR53pdZs4s37jhf5U+M3cDu9teT0QsZOZcByN1alrngumdzbnWx7nWb1pn63quNodQngMu7Tt/SbNNkjQGbQL+78AVEbE1Is4CdgJ7uhlLkjTMyIdQMvOliLgN+EdgE3B3Zh7ubLKXa30YZoNM61wwvbM51/o41/pN62ydzjXyk5iSpMnynZiSVJQBl6SiSgR8Wt6yHxGXRsTnI+KJiDgcEbc3298fEc9FxMHm3/YJzHYsIh5vbn+h2XZBRDwcEUebj+ePeaYr+9bkYES8EBF3TGq9IuLuiDgVEYf6tq24RtHzF80+9+WI2Dbmuf44Ip5sbvvTEXFes302Iv6nb+0+Mua5Bt53EfHeZr2eiohfGPNcn+yb6VhEHGy2j3O9BvVh4/axzJzqf/SeIH0GuBw4C3gMuGpCs1wEbGtOnwv8B71fI/B+4A8mvE7HgC3Ltv0RMN+cngc+MOH78XngdZNaL+BaYBtwaNgaAduBzwIBXAPsG/NcPw9sbk5/oG+u2f7LTWC9Vrzvmu+Dx4BXA1ub79lN45pr2ef/FPjDCazXoD5s2D5W4RH41LxlPzNPZOaB5vR3gCPAxZOYZY12APc0p+8B3jK5UbgOeCYzvzqpATLzi8C3lm0etEY7gL/Oni8B50XEReOaKzMfysyXmrNfovc+i7EasF6D7ADuz8z/zcyvAE/T+94d61wREcDbgfs24rZXs0ofNmwfqxDwi4Gv950/zhREMyJmgauBfc2m25ofg+4e96GKRgIPRcT+6P36AoALM/NEc/p54MIJzLVkJ6d/U016vZYMWqNp2u9+nd4jtSVbI+LRiPjniHjjBOZZ6b6blvV6I3AyM4/2bRv7ei3rw4btYxUCPnUi4jXAp4A7MvMF4MPAjwE/CZyg9yPcuL0hM7fR++2QvxUR1/Z/Mns/s03kNaPRe6PXzcDfNZumYb1eZpJrNEhE3Am8BNzbbDoBXJaZVwO/B3wiIn54jCNN5X3X5xZOf6Aw9vVaoQ/f1/U+ViHgU/WW/Yh4Fb07597MfBAgM09m5v9l5veAv2SDfnRcTWY+13w8BXy6meHk0o9kzcdT456rcSNwIDNPNjNOfL36DFqjie93EfEu4M3ArzTf+DSHKL7ZnN5P71jzj49rplXuu2lYr83ALwOfXNo27vVaqQ9s4D5WIeBT85b95vjax4AjmfnBvu39x61+CTi0/Gs3eK5zIuLcpdP0ngA7RG+dbm0udivwmXHO1ee0R0WTXq9lBq3RHuBXm1cKXAN8u+/H4A0XETcA7wFuzsz/7ts+E73fxU9EXA5cATw7xrkG3Xd7gJ0R8eqI2NrM9W/jmqtxPfBkZh5f2jDO9RrUBzZyHxvHs7MdPLu7nd4zus8Ad05wjjfQ+/Hny8DB5t924G+Ax5vte4CLxjzX5fReAfAYcHhpjYAfAR4BjgKfAy6YwJqdA3wTeG3ftomsF73/iZwAvkvveOO7B60RvVcGfKjZ5x4H5sY819P0jo8u7WcfaS771uY+PggcAH5xzHMNvO+AO5v1egq4cZxzNds/DvzmssuOc70G9WHD9jHfSi9JRVU4hCJJWoEBl6SiDLgkFWXAJakoAy5JRRlwSSrKgEtSUf8Pw1FNI4HT+wsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPT_CD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SECTIONHEADER</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Anesthesia</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Evaluation and management</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medicine</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Radiology</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Surgery</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           CPT_CD\n",
       "SECTIONHEADER                    \n",
       "Anesthesia                      1\n",
       "Evaluation and management      19\n",
       "Medicine                        9\n",
       "Radiology                       2\n",
       "Surgery                        49"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many unique CPT codes are there in each group? #####\n",
    "print(len(np.unique(filtered_df['CPT_CD'])))\n",
    "print(len(np.unique(note_cpt['CPT_CD'])))\n",
    "\n",
    "##### When not stratifying\n",
    "# 1,991 total codes and 121 codes where == 1 CPT codes\n",
    "# 1,991 total codes and 133 codes where <= 2 CPT codes\n",
    "# 1,991 total codes and 134 codes where <= 3 CPT codes\n",
    "\n",
    "### When stratifying by section header\n",
    "# 1984 total codes and 1610 codes where == 1 CPT codes\n",
    "# Only 374 codes are lost compared to 1870 codes\n",
    "\n",
    "# What is the distribution of CPT code counts?\n",
    "print(note_cpt.groupby('HADM_ID')['CPT_CD'].count().describe())\n",
    "plt.hist(filtered_df['CPT_CD'].value_counts(), bins=range(200))\n",
    "plt.show()\n",
    "\n",
    "# Length of the filtered data\n",
    "len(filtered_df) # 131,592\n",
    "len(note_cpt) # 223,690\n",
    "#### Lost about 90K records due to filtering and 374 CPT codes\n",
    "\n",
    "# What are the counts by the section headers?\n",
    "filtered_df['SECTIONHEADER'].value_counts()\n",
    "\n",
    "# Group by and count the number of CPT codes\n",
    "x = filtered_df.groupby(['SECTIONHEADER', 'CPT_CD'], as_index = False)['CPT_CD'].count()\n",
    "\n",
    "# How many CPT codes are there by section header?\n",
    "x.groupby('SECTIONHEADER').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-september",
   "metadata": {},
   "source": [
    "# Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "unable-minimum",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amartins\\onedrive - intermountain healthcare\\python_pycharm_virt_env\\.venv\\lib\\site-packages\\pandas\\core\\indexing.py:1676: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "def clean_data(text_series):\n",
    "    \n",
    "    # Replace \\n \n",
    "    text_series = text_series.str.replace('\\\\n',' ', regex=True)    \n",
    "\n",
    "    # Remove dates and locations\n",
    "    text_series = text_series.str.replace('\\[\\*\\*(.*?)\\*\\*\\]', ' ', regex=True)\n",
    "    \n",
    "    # Remove topics\n",
    "    data = text_series.str.split('([A-Z\\s]+:)')\n",
    "    for row_num, value in enumerate(data):\n",
    "        text_chunks = [x.strip().replace(':','').replace('\\n', '') for x in value]\n",
    "        for i, x in enumerate(text_chunks):\n",
    "            if 'MEDICATION' in x or 'SOCIAL HISTORY' in x or 'FAMILY HISTORY' in x:\n",
    "                text_chunks[i] = ' '\n",
    "                try:\n",
    "                    text_chunks[i + 1] = ' '\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "        text_series.iloc[row_num] = ' '.join(text_chunks)\n",
    "    \n",
    "    # Replace punctuation\n",
    "    text_series = text_series.str.replace('[' + string.punctuation + ']', ' ', regex=True)\n",
    "    \n",
    "    # Convert to lowercase \n",
    "    text_series = text_series.str.lower()\n",
    "    \n",
    "    # Remove all digits\n",
    "    text_series = text_series.str.replace('\\d',' ', regex=True)\n",
    "    \n",
    "    # Replace plurals, endings with ing, endings with ed, endings with ly\n",
    "#     text_series = text_series.str.replace('s(?=\\s)', ' ', regex=True)\n",
    "#     text_series = text_series.str.replace('ing(?=\\s)', ' ', regex=True)\n",
    "#     text_series = text_series.str.replace('ed(?=\\s)', ' ', regex=True)\n",
    "#     text_series = text_series.str.replace('ly(?=\\s)', ' ', regex=True)\n",
    "    \n",
    "    return text_series\n",
    "\n",
    "# Update Text Column -----\n",
    "filtered_df.loc[:, 'TEXT'] = clean_data(filtered_df['TEXT']).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-mixer",
   "metadata": {},
   "source": [
    "# Label Encode the Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cooked-cloud",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "filtered_df['CPT_CD'] = le.fit_transform(filtered_df['CPT_CD'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "awful-strike",
   "metadata": {},
   "source": [
    "# Check the Counts for Each Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "amended-router",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation and management    13437\n",
      "Medicine                     12086\n",
      "Surgery                       1317\n",
      "Name: SECTIONHEADER, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "94003    7183\n",
       "94002    4506\n",
       "90935     272\n",
       "99024     125\n",
       "Name: CPT_CD, dtype: int64"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(filtered_df['SECTIONHEADER'].value_counts())\n",
    "filtered_df[filtered_df['SECTIONHEADER'] == 'Medicine']['CPT_CD'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-devil",
   "metadata": {},
   "source": [
    "# Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "double-islam",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_dict = {} \n",
    "\n",
    "def split_stratify_df(df):\n",
    "    \n",
    "    for i in set(df['SECTIONHEADER']):\n",
    "        df_x = df[df['SECTIONHEADER'] == i]['TEXT'].values\n",
    "        df_y = df[df['SECTIONHEADER'] == i]['CPT_CD']\n",
    "        tt_dict['X_train_' + i], tt_dict['X_test_' + i], tt_dict['y_train_' + i], tt_dict['y_test_' + i], \\\n",
    "        tt_dict['index_train_' + i], tt_dict['index_test_' + i] = \\\n",
    "        train_test_split(df_x, df_y, range(len(df_y)), test_size = .1, random_state = 42, shuffle=True)\n",
    "\n",
    "split_stratify_df(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "pharmaceutical-cooling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Evaluation and management', 'Anesthesia', 'Radiology', 'Surgery', 'Medicine']\n"
     ]
    }
   ],
   "source": [
    "# Print sections\n",
    "print(list(set(filtered_df['SECTIONHEADER'])))\n",
    "\n",
    "# Select a section\n",
    "section = list(set(filtered_df['SECTIONHEADER']))[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-removal",
   "metadata": {},
   "source": [
    "# Balance the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "quantitative-catalog",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Balanced Record Count per CPT: 10104\n"
     ]
    }
   ],
   "source": [
    "def oversample_df(filtered_df, percentile):\n",
    "    \n",
    "    # Check counts\n",
    "    df_cts = filtered_df['CPT_CD'].value_counts()\n",
    "    record_ct = round(np.percentile(df_cts, percentile))\n",
    "    print('New Balanced Record Count per CPT: {}'.format(record_ct))\n",
    "    \n",
    "    # Create a list of CPT values\n",
    "    df = list(df_cts.index.values)\n",
    "\n",
    "    # Resample\n",
    "    minority_df = []\n",
    "    for i in df:\n",
    "        test_resampled = resample(filtered_df[filtered_df['CPT_CD'] == i], replace=True, n_samples=record_ct, random_state=123)\n",
    "        minority_df.append(test_resampled)\n",
    "    \n",
    "    # Create final dataframe\n",
    "    new_df = pd.concat(minority_df)\n",
    "    new_df['CPT_CD'] = new_df['CPT_CD']\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "# Recombine the training dataset\n",
    "x = pd.Series(tt_dict['X_train_' + section]).reset_index(drop=True)\n",
    "y = pd.Series(tt_dict['y_train_' + section]).reset_index(drop=True)\n",
    "training_df = pd.concat([x,y], axis=1, ignore_index=True)\n",
    "training_df.columns = ['TEXT', 'CPT_CD']\n",
    "\n",
    "# Run the function\n",
    "training_balanced = oversample_df(training_df, 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "threaded-suspension",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training and test datasets again and reassign to the dictionary\n",
    "tt_dict['X_train_' + section] = np.array(training_balanced['TEXT'].values)\n",
    "tt_dict['y_train_' + section] = np.array(training_balanced['CPT_CD'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-steering",
   "metadata": {},
   "source": [
    "# Check for Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "altered-lucas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10104], dtype=int64)"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(training_balanced['CPT_CD'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-comment",
   "metadata": {},
   "source": [
    "# Tokenize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "determined-waters",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected section:  Medicine\n"
     ]
    }
   ],
   "source": [
    "# Define stop words\n",
    "my_stop_words = list(set(stopwords.words('english'))) \\\n",
    "                + ['admission', 'date', 'sex'] \\\n",
    "                + ['needed', 'every', 'seen', 'weeks', 'please', 'ml', 'unit', 'small', 'year', 'old', 'cm', 'non', 'mm', 'however']\n",
    "                # Got the above from my top 100 most predictive words that I wanted to remove\n",
    "\n",
    "def vectorize_df(train_test_dict, section):\n",
    "    \n",
    "    # Import TfidfVectorizer\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words=my_stop_words)\n",
    "\n",
    "    # Transform the training data\n",
    "    tfidf_train = tfidf_vectorizer.fit_transform(train_test_dict['X_train_' + section])\n",
    "\n",
    "    # Transform the test data\n",
    "    tfidf_test = tfidf_vectorizer.transform(train_test_dict['X_test_' + section])\n",
    "    \n",
    "    # Add results to dictionary\n",
    "    vectorized_words = {}\n",
    "    vectorized_words['tfidf_train'] = tfidf_train\n",
    "    vectorized_words['tfidf_test'] = tfidf_test\n",
    "    \n",
    "    return vectorized_words, tfidf_vectorizer\n",
    "\n",
    "# Select a section\n",
    "print('Selected section: ', section)\n",
    "\n",
    "vectorized_words, tfidf_vectorizer = vectorize_df(tt_dict, section)                                                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-grenada",
   "metadata": {},
   "source": [
    "# Run Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "cultural-india",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.504359197907585\n"
     ]
    }
   ],
   "source": [
    "def run_clf(vectorized_words, train_test_dict, section):\n",
    "\n",
    "    # Use Naive Bayes model\n",
    "    nb_classifier = MultinomialNB(alpha=.7)\n",
    "\n",
    "    # Fit and check accuracy\n",
    "    nb_classifier.fit(vectorized_words['tfidf_train'], train_test_dict['y_train_' + section])\n",
    "    pred = nb_classifier.predict(vectorized_words['tfidf_test'])\n",
    "    \n",
    "    print(metrics.accuracy_score(train_test_dict['y_test_' + section], pred))\n",
    "    \n",
    "    return pred, nb_classifier\n",
    "    \n",
    "pred, nb_classifier = run_clf(vectorized_words, tt_dict, section)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-detective",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "forty-treaty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2726537216828479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nTesting CPT per HADM\\n-----------------------------------------\\nTest size: .1\\nRandom Number: 42\\n# of records per CPT: 5\\nMax duplicate CPTs per HADM allowed: 0\\nCategory/Categories: Discharge Summary\\nSection Header: E/M\\n\\n# of CPTs per HADM: 3\\nAccuracy: 0.24383561643835616\\n\\n# of CPTs per HADM: 5\\nAccuracy: 0.22121896162528218\\n\\n# of CPTs per HADM: 10\\nAccuracy: 0.2673684210526316\\n\\nResults: Accuracy seems to increase with more, presumably due to more records\\n-----------------------------------------\\n\\n#####\\n\\nTesting CPT counts per section per HADM\\n-----------------------------------------\\nTest size: .1\\nRandom Number: 42\\n# of records per CPT: 5\\n# of CPTs per HADM: 10\\nCategory/Categories: Discharge Summary\\nSection Header: E/M\\n# of CPTs per section: 10\\n\\nMax CPTs count per section per HADM allowed: 1\\nRecord Ct: 15376\\nBalanced Ct: 3321\\nAccuracy: 0.21846553966189858\\n\\nMax CPTs count per section per HADM allowed: 2\\nRecord Ct: 15376\\nBalanced Ct: 3321\\nAccuracy: 0.21846553966189858\\n\\nMax CPTs count per section per HADM allowed: 5\\nRecord Ct: 83534\\n\\nAccuracy: 0.1390950442901604\\n\\n\\nResults: \\n-----------------------------------------\\n\\n#####\\n\\nTesting # Notes per CPT\\n-----------------------------------------\\nTest size: .1\\nRandom Number: 42\\n# of records per CPT: 5\\n# of CPTs per HADM: 10\\nCategory/Categories: Discharge Summary\\nSection Header: E/M\\nMax CPTs count per section per HADM allowed: 1\\n\\n\\n# of CPTs per section: 5\\nRecord Ct: 15376\\nBalanced Ct: 3321\\nAccuracy: 0.21846553966189858\\n\\n# of CPTs per section: 1000\\nRecord Ct: 12355\\nBalanced Ct: 3761\\nAccuracy: 0.2726537216828479\\n\\nResults: More notes looks like it is more predictive\\n-----------------------------------------\\n\\n'"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check accuracy\n",
    "print(metrics.accuracy_score(tt_dict['y_test_' + section], pred))\n",
    "\n",
    "\n",
    "# Final Results #####\n",
    "# E/M: 0.21846553966189858 - 10 codes\n",
    "# Radiology: .825 - 2 codes\n",
    "# Surgery: 0.4258474576271186 - 10 codes\n",
    "# Medicine: 0.504359197907585 - 8 codes\n",
    "\n",
    "\"\"\"\n",
    "Testing CPT per HADM\n",
    "-----------------------------------------\n",
    "Test size: .1\n",
    "Random Number: 42\n",
    "# of records per CPT: 5\n",
    "Max duplicate CPTs per HADM allowed: 0\n",
    "Category/Categories: Discharge Summary\n",
    "Section Header: E/M\n",
    "\n",
    "# of CPTs per HADM: 3\n",
    "Accuracy: 0.24383561643835616\n",
    "\n",
    "# of CPTs per HADM: 5\n",
    "Accuracy: 0.22121896162528218\n",
    "\n",
    "# of CPTs per HADM: 10\n",
    "Accuracy: 0.2673684210526316\n",
    "\n",
    "Results: Accuracy seems to increase with more, presumably due to more records\n",
    "-----------------------------------------\n",
    "\n",
    "#####\n",
    "\n",
    "Testing CPT counts per section per HADM\n",
    "-----------------------------------------\n",
    "Test size: .1\n",
    "Random Number: 42\n",
    "# of records per CPT: 5\n",
    "# of CPTs per HADM: 10\n",
    "Category/Categories: Discharge Summary\n",
    "Section Header: E/M\n",
    "# of CPTs per section: 10\n",
    "\n",
    "Max CPTs count per section per HADM allowed: 1\n",
    "Record Ct: 15376\n",
    "Balanced Ct: 3321\n",
    "Accuracy: 0.21846553966189858\n",
    "\n",
    "Max CPTs count per section per HADM allowed: 2\n",
    "Record Ct: 15376\n",
    "Balanced Ct: 3321\n",
    "Accuracy: 0.21846553966189858\n",
    "\n",
    "Max CPTs count per section per HADM allowed: 5\n",
    "Record Ct: 83534\n",
    "\n",
    "Accuracy: 0.1390950442901604\n",
    "\n",
    "\n",
    "Results: \n",
    "-----------------------------------------\n",
    "\n",
    "#####\n",
    "\n",
    "Testing # Notes per CPT\n",
    "-----------------------------------------\n",
    "Test size: .1\n",
    "Random Number: 42\n",
    "# of records per CPT: 5\n",
    "# of CPTs per HADM: 10\n",
    "Category/Categories: Discharge Summary\n",
    "Section Header: E/M\n",
    "Max CPTs count per section per HADM allowed: 1\n",
    "\n",
    "\n",
    "# of CPTs per section: 5\n",
    "Record Ct: 15376\n",
    "Balanced Ct: 3321\n",
    "Accuracy: 0.21846553966189858\n",
    "\n",
    "# of CPTs per section: 1000\n",
    "Record Ct: 12355\n",
    "Balanced Ct: 3761\n",
    "Accuracy: 0.2726537216828479\n",
    "\n",
    "Results: More notes looks like it is more predictive\n",
    "-----------------------------------------\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-kenya",
   "metadata": {},
   "source": [
    "# Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "useful-strand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       90801       0.11      0.45      0.18        31\n",
      "       90935       0.26      0.69      0.38        89\n",
      "       90937       0.00      0.00      0.00        14\n",
      "       90945       0.07      0.24      0.11        17\n",
      "       93503       0.03      0.43      0.05         7\n",
      "       94002       0.52      0.51      0.51       788\n",
      "       94003       0.72      0.50      0.59      1330\n",
      "       99024       0.21      1.00      0.34        18\n",
      "\n",
      "    accuracy                           0.50      2294\n",
      "   macro avg       0.24      0.48      0.27      2294\n",
      "weighted avg       0.61      0.50      0.54      2294\n",
      "\n",
      "Training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       90801       0.90      0.92      0.91     10104\n",
      "       90935       0.81      0.77      0.79     10104\n",
      "       90937       0.91      0.99      0.95     10104\n",
      "       90945       0.94      0.98      0.96     10104\n",
      "       93503       0.91      0.94      0.92     10104\n",
      "       94002       0.59      0.54      0.57     10104\n",
      "       94003       0.64      0.55      0.59     10104\n",
      "       99024       0.89      0.98      0.94     10104\n",
      "\n",
      "    accuracy                           0.83     80832\n",
      "   macro avg       0.82      0.83      0.83     80832\n",
      "weighted avg       0.82      0.83      0.83     80832\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create classification report taken from here: https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568\n",
    "print('Test')\n",
    "class_labels = nb_classifier.classes_\n",
    "print(classification_report(tt_dict['y_test_' + section], pred))\n",
    "\n",
    "print('Training')\n",
    "pred_x = nb_classifier.predict(vectorized_words['tfidf_train'])\n",
    "print(classification_report(tt_dict['y_train_' + section], pred_x))\n",
    "\n",
    "# Counts by number of CPT values in test\n",
    "# print(tt_dict['y_test_' + section].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-mining",
   "metadata": {},
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "similar-senator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33427 22.77%\n",
      "[0.04742518 0.04763856 0.04704341 0.14166082 0.22769757 0.21479557\n",
      " 0.10340254 0.07079546 0.06247875 0.03706214]\n"
     ]
    }
   ],
   "source": [
    "def predict_cpt(text):\n",
    "    input_text_clean = clean_data(pd.Series(text))\n",
    "    tfidf_input_test = tfidf_vectorizer.transform(input_text_clean)\n",
    "    print(nb_classifier.predict(tfidf_input_test)[0], str(round(max(nb_classifier.predict_proba(tfidf_input_test)[0]) * 100,2)) + '%')\n",
    "    print(nb_classifier.predict_proba(tfidf_input_test)[0])\n",
    "          \n",
    "text_cpt = 'valvuloplasty mitral valve or subvalvular structures to correct mitral stenosis or subvalvular fibrosis with the patient on a heart–lung machine to reroute the circulation of blood and bypass the heart and lungs. The provider may insert a band or ring around the anulus to correct mitral insufficiency if the valve is leaking due to annular dilatation.'\n",
    "predict_cpt(text_cpt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "built-romance",
   "metadata": {},
   "source": [
    "# Changes from v12_2\n",
    "* Not using cTakes\n",
    "* Evaluating different CPT code sets\n",
    "* Cleaning up the folder and the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-basis",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "## Questions\n",
    "* Run the data for each category with only no filter, one, and three CPT codes for each discharge summary\n",
    "    * ANSWER: It performs better with only 1 CPT per note and 3 had a decrease of 3% in accuracy\n",
    "* Does including all notes/CPT sections improve accuracy?\n",
    "    * ANSWER: No, it decreased the accuracy\n",
    "* Does including some sections improve accuracy when included with discharge summary?\n",
    "    * No, accuracy went from 80% to 71%- at least for the E/M category\n",
    "* Does accuracy improve when there are more notes per CPT code?\n",
    "    * Yes\n",
    "* What is the lowest threshold I can use without decreasing accuracy?\n",
    "    * It seems like I don't need a threshold\n",
    "* Does imbalance correction improve model accuracy?\n",
    "    * Yes, it makes a huge difference\n",
    "* Is undersampling or over-sampling a better method for imbalance correction?\n",
    "    * Oversampling since the lowest records only contain one note - could also try SMOTE and see if that gives better results or not\n",
    "* Use label encoder for the CPT codes\n",
    "    * Does the accuracy improve when using labelencoder?\n",
    "* Is limiting CPT codes to just one excluding CPT codes?\n",
    "    * No\n",
    "* What is the accuracy when filtered to each CPT section individually?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-sharing",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "answering-retro",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import glob\n",
    "import string\n",
    "from sklearn.utils import resample\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-alabama",
   "metadata": {},
   "source": [
    "\n",
    "# Import the MIMIC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "environmental-character",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amartins\\onedrive - intermountain healthcare\\python_pycharm_virt_env\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (4,5,7,11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "c:\\users\\amartins\\onedrive - intermountain healthcare\\python_pycharm_virt_env\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (4,5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "dataset_dictionary = {}\n",
    "\n",
    "for file_path in glob.glob('.\\\\Data\\\\MIMIC Files\\*'):\n",
    "    file_name = file_path.split('\\\\')[3].split('.')[0]\n",
    "    with gzip.open(file_path, mode='r') as file:\n",
    "        dataset_dictionary[file_name] = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-literature",
   "metadata": {},
   "source": [
    "# Assign Datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "delayed-moscow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['CPTEVENTS', 'DIAGNOSES_ICD', 'D_CPT', 'D_ICD_DIAGNOSES', 'D_ICD_PROCEDURES', 'NOTEEVENTS', 'PATIENTS', 'PROCEDURES_ICD'])\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 573146 entries, 0 to 573145\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   ROW_ID            573146 non-null  int64  \n",
      " 1   SUBJECT_ID        573146 non-null  int64  \n",
      " 2   HADM_ID           573146 non-null  int64  \n",
      " 3   COSTCENTER        573146 non-null  object \n",
      " 4   CHARTDATE         101545 non-null  object \n",
      " 5   CPT_CD            573146 non-null  object \n",
      " 6   CPT_NUMBER        573128 non-null  float64\n",
      " 7   CPT_SUFFIX        22 non-null      object \n",
      " 8   TICKET_ID_SEQ     471601 non-null  float64\n",
      " 9   SECTIONHEADER     573146 non-null  object \n",
      " 10  SUBSECTIONHEADER  573125 non-null  object \n",
      " 11  DESCRIPTION       101545 non-null  object \n",
      "dtypes: float64(2), int64(3), object(7)\n",
      "memory usage: 52.5+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 651047 entries, 0 to 651046\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   ROW_ID      651047 non-null  int64  \n",
      " 1   SUBJECT_ID  651047 non-null  int64  \n",
      " 2   HADM_ID     651047 non-null  int64  \n",
      " 3   SEQ_NUM     651000 non-null  float64\n",
      " 4   ICD9_CODE   651000 non-null  object \n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 24.8+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 134 entries, 0 to 133\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   ROW_ID               134 non-null    int64 \n",
      " 1   CATEGORY             134 non-null    int64 \n",
      " 2   SECTIONRANGE         134 non-null    object\n",
      " 3   SECTIONHEADER        134 non-null    object\n",
      " 4   SUBSECTIONRANGE      134 non-null    object\n",
      " 5   SUBSECTIONHEADER     134 non-null    object\n",
      " 6   CODESUFFIX           11 non-null     object\n",
      " 7   MINCODEINSUBSECTION  134 non-null    int64 \n",
      " 8   MAXCODEINSUBSECTION  134 non-null    int64 \n",
      "dtypes: int64(4), object(5)\n",
      "memory usage: 9.5+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14567 entries, 0 to 14566\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   ROW_ID       14567 non-null  int64 \n",
      " 1   ICD9_CODE    14567 non-null  object\n",
      " 2   SHORT_TITLE  14567 non-null  object\n",
      " 3   LONG_TITLE   14567 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 455.3+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3882 entries, 0 to 3881\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   ROW_ID       3882 non-null   int64 \n",
      " 1   ICD9_CODE    3882 non-null   int64 \n",
      " 2   SHORT_TITLE  3882 non-null   object\n",
      " 3   LONG_TITLE   3882 non-null   object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 121.4+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2083180 entries, 0 to 2083179\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Dtype  \n",
      "---  ------       -----  \n",
      " 0   ROW_ID       int64  \n",
      " 1   SUBJECT_ID   int64  \n",
      " 2   HADM_ID      float64\n",
      " 3   CHARTDATE    object \n",
      " 4   CHARTTIME    object \n",
      " 5   STORETIME    object \n",
      " 6   CATEGORY     object \n",
      " 7   DESCRIPTION  object \n",
      " 8   CGID         float64\n",
      " 9   ISERROR      float64\n",
      " 10  TEXT         object \n",
      "dtypes: float64(3), int64(2), object(6)\n",
      "memory usage: 174.8+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 46520 entries, 0 to 46519\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   ROW_ID       46520 non-null  int64 \n",
      " 1   SUBJECT_ID   46520 non-null  int64 \n",
      " 2   GENDER       46520 non-null  object\n",
      " 3   DOB          46520 non-null  object\n",
      " 4   DOD          15759 non-null  object\n",
      " 5   DOD_HOSP     9974 non-null   object\n",
      " 6   DOD_SSN      13378 non-null  object\n",
      " 7   EXPIRE_FLAG  46520 non-null  int64 \n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 2.8+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 240095 entries, 0 to 240094\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count   Dtype\n",
      "---  ------      --------------   -----\n",
      " 0   ROW_ID      240095 non-null  int64\n",
      " 1   SUBJECT_ID  240095 non-null  int64\n",
      " 2   HADM_ID     240095 non-null  int64\n",
      " 3   SEQ_NUM     240095 non-null  int64\n",
      " 4   ICD9_CODE   240095 non-null  int64\n",
      "dtypes: int64(5)\n",
      "memory usage: 9.2 MB\n",
      "None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'to_datetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-1384668da6e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# CPTEVENTS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mdataset_dictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CPTEVENTS'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SECTIONHEADER'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'CPT_CD'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_dictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CPTEVENTS'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SECTIONHEADER'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'CPT_CD'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mdataset_dictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CPTEVENTS'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CHARTDATE'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_dictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CPTEVENTS'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CHARTDATE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\amartins\\onedrive - intermountain healthcare\\python_pycharm_virt_env\\.venv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5460\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5461\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5462\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5464\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'to_datetime'"
     ]
    }
   ],
   "source": [
    "# Check all the datasets exist in the dictionary \n",
    "print(dataset_dictionary.keys())\n",
    "\n",
    "# Check the datatypes and information for each table \n",
    "for i in dataset_dictionary.keys():\n",
    "    print(dataset_dictionary[i].info())\n",
    "\n",
    "# Correct any datatype issues #####\n",
    "\n",
    "# CPTEVENTS\n",
    "dataset_dictionary['CPTEVENTS'].loc[:,['SECTIONHEADER','CPT_CD']] = dataset_dictionary['CPTEVENTS'].loc[:,['SECTIONHEADER','CPT_CD']].astype(str)\n",
    "dataset_dictionary['CPTEVENTS']['CHARTDATE'] = dataset_dictionary['CPTEVENTS']['CHARTDATE'].to_datetime()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historical-raise",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis - CPTEVENTS Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "pediatric-louis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total CPT counts per section\n",
      "\n",
      " SECTIONHEADER\n",
      "Anesthesia                      687\n",
      "Emerging technology              22\n",
      "Evaluation and management    404388\n",
      "Medicine                     114194\n",
      "Pathology and laboratory         53\n",
      "Radiology                      2974\n",
      "Surgery                       50807\n",
      "nan                              21\n",
      "Name: CPT_CD, dtype: int64\n",
      "\n",
      "Total Unique CPT counts per section\n",
      "\n",
      " SECTIONHEADER\n",
      "Anesthesia                      5\n",
      "Emerging technology             8\n",
      "Evaluation and management      58\n",
      "Medicine                       91\n",
      "Pathology and laboratory        4\n",
      "Radiology                      61\n",
      "Surgery                      1784\n",
      "nan                             7\n",
      "Name: CPT_CD, dtype: int64\n",
      "\n",
      " Section Header: Anesthesia \n",
      "\n",
      "count      5.000000\n",
      "mean     137.400000\n",
      "std      243.206291\n",
      "min        2.000000\n",
      "25%       21.000000\n",
      "50%       37.000000\n",
      "75%       56.000000\n",
      "max      571.000000\n",
      "Name: CPT_CD, dtype: float64\n",
      "\n",
      " Section Header: Emerging technology \n",
      "\n",
      "count    8.00000\n",
      "mean     2.75000\n",
      "std      2.54951\n",
      "min      1.00000\n",
      "25%      1.00000\n",
      "50%      1.50000\n",
      "75%      3.50000\n",
      "max      8.00000\n",
      "Name: CPT_CD, dtype: float64\n",
      "\n",
      " Section Header: Evaluation and management \n",
      "\n",
      "count        58.000000\n",
      "mean       6972.206897\n",
      "std       22252.229542\n",
      "min           1.000000\n",
      "25%           7.000000\n",
      "50%          32.500000\n",
      "75%         963.250000\n",
      "max      108434.000000\n",
      "Name: CPT_CD, dtype: float64\n",
      "\n",
      " Section Header: Medicine \n",
      "\n",
      "count       91.000000\n",
      "mean      1254.879121\n",
      "std       9325.079213\n",
      "min          1.000000\n",
      "25%          1.000000\n",
      "50%          5.000000\n",
      "75%         15.000000\n",
      "max      87984.000000\n",
      "Name: CPT_CD, dtype: float64\n",
      "\n",
      " Section Header: Pathology and laboratory \n",
      "\n",
      "count     4.000000\n",
      "mean     13.250000\n",
      "std      19.534158\n",
      "min       1.000000\n",
      "25%       1.000000\n",
      "50%       5.000000\n",
      "75%      17.250000\n",
      "max      42.000000\n",
      "Name: CPT_CD, dtype: float64\n",
      "\n",
      " Section Header: Radiology \n",
      "\n",
      "count      61.000000\n",
      "mean       48.754098\n",
      "std       179.448475\n",
      "min         1.000000\n",
      "25%         1.000000\n",
      "50%         5.000000\n",
      "75%        17.000000\n",
      "max      1050.000000\n",
      "Name: CPT_CD, dtype: float64\n",
      "\n",
      " Section Header: Surgery \n",
      "\n",
      "count    1784.000000\n",
      "mean       28.479260\n",
      "std       168.369641\n",
      "min         1.000000\n",
      "25%         1.000000\n",
      "50%         3.000000\n",
      "75%        11.000000\n",
      "max      4150.000000\n",
      "Name: CPT_CD, dtype: float64\n",
      "\n",
      " Section Header: nan \n",
      "\n",
      "count    7.000000\n",
      "mean     3.000000\n",
      "std      2.236068\n",
      "min      1.000000\n",
      "25%      1.500000\n",
      "50%      2.000000\n",
      "75%      4.000000\n",
      "max      7.000000\n",
      "Name: CPT_CD, dtype: float64\n",
      "\n",
      "Total Unique CPT counts per section\n",
      "\n",
      " SECTIONHEADER\n",
      "Anesthesia                      5\n",
      "Emerging technology             8\n",
      "Evaluation and management      58\n",
      "Medicine                       91\n",
      "Pathology and laboratory        4\n",
      "Radiology                      60\n",
      "Surgery                      1758\n",
      "nan                             7\n",
      "Name: CPT_CD, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# How many CPT codes are in the data for each CPT section? -----\n",
    "data_cpt = dataset_dictionary['CPTEVENTS']\n",
    "print('\\nTotal CPT counts per section\\n\\n', data_cpt.groupby('SECTIONHEADER')['CPT_CD'].count())\n",
    "\n",
    "# How many unique CPT codes are there per CPT section? -----\n",
    "data_nodups = data_cpt.loc[:,['CPT_CD', 'SECTIONHEADER']].drop_duplicates()\n",
    "print('\\nTotal Unique CPT counts per section\\n\\n', data_nodups.groupby('SECTIONHEADER')['CPT_CD'].count())\n",
    "\n",
    "# What is the distribution of counts for each CPT code per section? -----\n",
    "for i in np.unique(data_cpt['SECTIONHEADER']):\n",
    "    print('\\n Section Header:',i,'\\n')\n",
    "    print(data_cpt[data_cpt['SECTIONHEADER'] == i].groupby('CPT_CD')['CPT_CD'].count().describe())\n",
    "    \n",
    "# How many unique CPT codes are there per CPT section when filtered to the Discharge Summary Section in the Note Events Table? -----\n",
    "data_notes = dataset_dictionary['NOTEEVENTS']\n",
    "data_notes = data_notes[data_notes['CATEGORY'] == 'Discharge summary']\n",
    "data_merged = data_notes.merge(data_cpt, on = ['SUBJECT_ID','HADM_ID'])\n",
    "data_nodups = data_merged.loc[:,['CPT_CD', 'SECTIONHEADER']].drop_duplicates()\n",
    "print('\\nTotal Unique CPT counts per section\\n\\n', data_nodups.groupby('SECTIONHEADER')['CPT_CD'].count())\n",
    "\n",
    "# Are there multiple CPT codes per encounter? -----\n",
    "# Answer: Yes\n",
    "\n",
    "data_cpt.groupby('HADM_ID')['CPT_CD'].count()\n",
    "\n",
    "# What percentage of encounters only have one CPT code?\n",
    "# Answer: 8.3%\n",
    "data_grouped = data_cpt.groupby('HADM_ID')['CPT_CD'].count()\n",
    "(data_grouped == 1).sum()/ len(np.unique(data_cpt['HADM_ID']))\n",
    "\n",
    "# What does the distribution look like for number of CPT codes per encounter?\n",
    "data_grouped = data_cpt.groupby('HADM_ID')['CPT_CD'].count()\n",
    "plt.hist(data_grouped, bins=range(21))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-nursing",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis - NOTEEVENTS Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "willing-israel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Case Management ' 'Consult' 'Discharge summary' 'ECG' 'Echo' 'General'\n",
      " 'Nursing' 'Nursing/other' 'Nutrition' 'Pharmacy' 'Physician ' 'Radiology'\n",
      " 'Rehab Services' 'Respiratory ' 'Social Work']\n",
      "Chief Complaint:\n",
      "   24 Hour Events:\n",
      " Continued to be anuric.  Tolerated HD well.  Decision today by pt and\n",
      "   wife to convert to [**Name (NI) 617**].\n",
      "   History obtained from Patient\n",
      "   Allergies:\n",
      "   History obtained from PatientHeparin Agents\n",
      "   Thrombocytopeni\n",
      "   Last dose of Antibiotics:\n",
      "   Piperacillin - [**2138-3-20**] 08:00 PM\n",
      "   Piperacillin/Tazobactam (Zosyn) - [**2138-3-21**] 09:00 AM\n",
      "   Metronidazole - [**2138-3-21**] 10:12 AM\n",
      "   Infusions:\n",
      "   Other ICU medications:\n",
      "   Other medications:\n",
      "   Changes to medical and family history:\n",
      "   Review of systems is unchanged from admission except as noted below\n",
      "   Review of systems:\n",
      "   Flowsheet Data as of  [**2138-3-21**] 02:56 PM\n",
      "   Vital signs\n",
      "   Hemodynamic monitoring\n",
      "   Fluid balance\n",
      "                                                                  24 hours\n",
      "                                                               Since 12 AM\n",
      "   Tmax: 36.6\n",
      "C (97.9\n",
      "   Tcurrent: 36.1\n",
      "C (96.9\n",
      "   HR: 113 (103 - 115) bpm\n",
      "   BP: 106/58(71){91/45(58) - 106/67(76)} mmHg\n",
      "   RR: 23 (16 - 26) insp/min\n",
      "   SpO2: 100%\n",
      "   Heart rhythm: ST (Sinus Tachycardia)\n",
      "   Height: 72 Inch\n",
      "             Total In:\n",
      "                                                                    700 mL\n",
      "                                                                    569 mL\n",
      "   PO:\n",
      "                                                                    200 mL\n",
      "                                                                    220 mL\n",
      "   TF:\n",
      "   IVF:\n",
      "                                                                    500 mL\n",
      "                                                                    349 mL\n",
      "   Blood products:\n",
      "   Total out:\n",
      "                                                                     43 mL\n",
      "                                                                    163 mL\n",
      "   Urine:\n",
      "                                                                     43 mL\n",
      "                                                                     18 mL\n",
      "   NG:\n",
      "   Stool:\n",
      "   Drains:\n",
      "   Balance:\n",
      "                                                                    657 mL\n",
      "                                                                    406 mL\n",
      "   Respiratory support\n",
      "   O2 Delivery Device: None\n",
      "   SpO2: 100%\n",
      "   ABG: ///19/\n",
      "   Physical Examination\n",
      "   General Appearance: No acute distress\n",
      "   Head, Ears, Nose, Throat: Normocephalic\n",
      "   Cardiovascular: (S1: Normal), (S2: Normal), (Murmur: Systolic)\n",
      "   Peripheral Vascular: (Right radial pulse: Not assessed), (Left radial\n",
      "   pulse: Not assessed), (Right DP pulse: Not assessed), (Left DP pulse:\n",
      "   Not assessed)\n",
      "   Respiratory / Chest: (Expansion: Symmetric), (Breath Sounds: Clear : )\n",
      "   Abdominal: Soft, Non-tender, Bowel sounds present\n",
      "   Extremities: Right: 1+, Left: 1+\n",
      "   Musculoskeletal: Unable to stand\n",
      "   Skin:  Not assessed\n",
      "   Neurologic: Attentive, Follows simple commands, Responds to: Not\n",
      "   assessed, Movement: Not assessed, Tone: Not assessed\n",
      "   Labs / Radiology\n",
      "   233 K/uL\n",
      "   8.5 g/dL\n",
      "   173 mg/dL\n",
      "   4.4 mg/dL\n",
      "   19 mEq/L\n",
      "   4.3 mEq/L\n",
      "   87 mg/dL\n",
      "   111 mEq/L\n",
      "   143 mEq/L\n",
      "   27.8 %\n",
      "   5.1 K/uL\n",
      "        [image002.jpg]\n",
      "                             [**2138-3-17**]  07:46 PM\n",
      "                             [**2138-3-18**]  05:42 AM\n",
      "                             [**2138-3-18**]  01:56 PM\n",
      "                             [**2138-3-19**]  05:59 AM\n",
      "                             [**2138-3-19**]  04:41 PM\n",
      "                             [**2138-3-19**]  08:27 PM\n",
      "                             [**2138-3-20**]  04:52 AM\n",
      "                             [**2138-3-20**]  04:38 PM\n",
      "                             [**2138-3-21**]  04:37 AM\n",
      "   WBC\n",
      "   14.8\n",
      "   5.0\n",
      "   6.1\n",
      "   5.8\n",
      "   5.1\n",
      "   Hct\n",
      "   31.8\n",
      "   28.8\n",
      "   28.7\n",
      "   28.0\n",
      "   27.8\n",
      "   Plt\n",
      "   [**Telephone/Fax (3) 745**]85\n",
      "   233\n",
      "   Cr\n",
      "   4.5\n",
      "   4.3\n",
      "   4.5\n",
      "   4.5\n",
      "   4.8\n",
      "   4.9\n",
      "   5.2\n",
      "   4.2\n",
      "   4.4\n",
      "   TropT\n",
      "   0.42\n",
      "   0.35\n",
      "   0.33\n",
      "   Glucose\n",
      "   [**Telephone/Fax (3) 696**]64\n",
      "   163\n",
      "   152\n",
      "   208\n",
      "   173\n",
      "   Other labs: PT / PTT / INR:13.9/32.0/1.2, CK / CKMB /\n",
      "   Troponin-T:10/4/0.33, Amylase / Lipase:45/34, Differential-Neuts:94.1\n",
      "   %, Band:Units: %\n",
      "   Range: 0-5 %, Lymph:4.2 %, Mono:1.6 %, Eos:Units: %\n",
      "   Range: 0-4 %, Fibrinogen:399 mg/dL, Lactic Acid:1.0 mmol/L, Albumin:2.1\n",
      "   g/dL, Ca++:8.1 mg/dL, Mg++:1.9 mg/dL, PO4:5.5 mg/dL\n",
      "   Assessment and Plan\n",
      "   1. [**Telephone/Fax (3) 617**]: Pt and wife desired to transition to [**Name (NI) 617**] today; palliative care\n",
      "   following.  Review palliative care recs.\n",
      "   2.  Renal failure:  Anuric, s/p HD yesterday, scheduled for HD today\n",
      "   and tomorrow per renal; however, pt and wife now want to stop HD. Cr\n",
      "   down to 4.4 from 5.2 and K+ 4.4 from 5.2.\n",
      "   3.  Pulmonary Edema:  Worsened on CXR from yesterday, no subjective\n",
      "   dyspnea.  No crackles heard on anterior exam as fluid is dependant.\n",
      "   Cause is multifactorial including pseudomonal UTI likely resulting in\n",
      "   sepsis, poor nutritional status, low EF of 40% and aortic stenosis.  Pt\n",
      "   now [**Name (NI) 617**].\n",
      "   4. ESRD:  S/p B renal transplant, on tacrolimus and steriods.  Now [**Name (NI) 617**],\n",
      "   d/c tacrolimus and steroids.\n",
      "   5.  Pseudomonal UTI:  Now [**Name (NI) 617**].\n",
      "   6.  Fever/Hypotension:  Resolved.  Pt now [**Name (NI) 617**], d/c all antibiotics.\n",
      "   7.  Prostate Cancer:  [**Name (NI) 617**].  D/c Lupron.\n",
      "   ICU Care:  PT NOW [**Name (NI) 617**].\n",
      "   Nutrition:\n",
      "   Glycemic Control:\n",
      "   Lines:\n",
      "   Presep Catheter - [**2138-3-17**] 03:30 PM\n",
      "   Prophylaxis:\n",
      "   DVT:\n",
      "   Stress ulcer:\n",
      "   VAP:\n",
      "   Comments:\n",
      "   Communication:  Comments:\n",
      "   Code status: DNR / DNI ; [**Year (4 digits) 617**]\n",
      "   Disposition:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CATEGORY\n",
       "Case Management         967\n",
       "Consult                  98\n",
       "Discharge summary     59652\n",
       "ECG                  209051\n",
       "Echo                  45794\n",
       "General                8301\n",
       "Nursing              223556\n",
       "Nursing/other        822497\n",
       "Nutrition              9418\n",
       "Pharmacy                103\n",
       "Physician            141624\n",
       "Radiology            522279\n",
       "Rehab Services         5431\n",
       "Respiratory           31739\n",
       "Social Work            2670\n",
       "Name: CATEGORY, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dataset_dictionary['NOTEEVENTS']\n",
    "\n",
    "# What are the unique categories?\n",
    "print(np.unique(data['CATEGORY']))\n",
    "\n",
    "# What do some of the notes look like in each category?\n",
    "print(data[data['CATEGORY'] == 'Physician ']['TEXT'].iloc[0])\n",
    "\n",
    "# How many notes are there per category?\n",
    "data.groupby('CATEGORY')['CATEGORY'].count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-system",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis - Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "danish-amazon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Counts for the original data:\n",
      "\n",
      " 99291    25967\n",
      "99232    23987\n",
      "99233    22791\n",
      "94003    16395\n",
      "99231    12441\n",
      "94002    11130\n",
      "99223     9271\n",
      "99239     8775\n",
      "99254     7896\n",
      "99222     6846\n",
      "99238     6342\n",
      "99255     5512\n",
      "99253     5377\n",
      "99292     3864\n",
      "36556     3490\n",
      "99252     2194\n",
      "90935     1846\n",
      "33508     1763\n",
      "33533     1719\n",
      "36620     1597\n",
      "99221     1574\n",
      "31624     1317\n",
      "31645     1275\n",
      "31622     1005\n",
      "76937      918\n",
      "Name: CPT_CD, dtype: int64\n",
      "Value Counts for the filtered data:\n",
      "\n",
      " 99291    25967\n",
      "99232    23987\n",
      "99233    22791\n",
      "94003    16395\n",
      "99231    12441\n",
      "94002    11130\n",
      "99223     9271\n",
      "99239     8775\n",
      "99254     7896\n",
      "99222     6846\n",
      "99238     6342\n",
      "99255     5512\n",
      "99253     5377\n",
      "99292     3864\n",
      "36556     3490\n",
      "99252     2194\n",
      "90935     1846\n",
      "33508     1763\n",
      "33533     1719\n",
      "36620     1597\n",
      "99221     1574\n",
      "31624     1317\n",
      "31645     1275\n",
      "31622     1005\n",
      "76937      918\n",
      "Name: CPT_CD, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If I filter to just one CPT code per encounter, am I excluding some CPT codes that always appear with other CPT codes?\n",
    "\n",
    "def filter_df(combined_df, threshold):\n",
    "\n",
    "    # Print value counts original\n",
    "    print('Value Counts for the original data:\\n\\n', combined_df['CPT_CD'].value_counts().head(25))\n",
    "\n",
    "    # Filter based on count limit\n",
    "    df = combined_df['CPT_CD'].value_counts()\n",
    "    filtered_ls = list((df[df >= threshold]).index.values)\n",
    "    filtered_df = combined_df[combined_df['CPT_CD'].isin(filtered_ls)]\n",
    "    \n",
    "    # Print value counts filtered\n",
    "    print('Value Counts for the filtered data:\\n\\n', filtered_df['CPT_CD'].value_counts().head(25))\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "x = filter_df(note_cpt, 1)\n",
    "\n",
    "# There are no CPT codes that are being excluded from the filter\n",
    "set(note_cpt['CPT_CD']) - set(x['CPT_CD'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-desert",
   "metadata": {},
   "source": [
    "# Join the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "grateful-tracker",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_tables(dataset_dictionary, category=['Discharge summary'], all_notes=False):\n",
    "\n",
    "    # Define tables\n",
    "    note_events_base = dataset_dictionary['NOTEEVENTS']\n",
    "    cpt_events_base = dataset_dictionary['CPTEVENTS']\n",
    "    \n",
    "    # Combine text for each subject and encounter\n",
    "    if all_notes == False:\n",
    "        note_events_base = note_events_base[note_events_base.loc[:,'CATEGORY'].isin(category)]\n",
    "\n",
    "    note_events = note_events_base.groupby(['SUBJECT_ID', 'HADM_ID'], as_index=False)['TEXT'].agg(sum)\n",
    "\n",
    "    # Create CPT table\n",
    "    cpt_events_base = cpt_events_base.loc[:, ['SUBJECT_ID','HADM_ID', 'CPT_CD']]\n",
    "    cpt_events = cpt_events_base.drop_duplicates()\n",
    "    \n",
    "    # Join the datasets\n",
    "    note_cpt = note_events.merge(cpt_events, on = ['SUBJECT_ID','HADM_ID'])\n",
    "    \n",
    "    return note_cpt\n",
    "    \n",
    "note_cpt = join_tables(dataset_dictionary)\n",
    "# ['Consult','Discharge summary','General', 'Nursing', 'Nursing/other'\\\n",
    "#                                             , 'Physician ','Rehab Services','Respiratory ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "substantial-cambridge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99291    25967\n",
       "99232    23987\n",
       "99233    22791\n",
       "94003    16395\n",
       "99231    12441\n",
       "94002    11130\n",
       "99223     9271\n",
       "99239     8775\n",
       "99254     7896\n",
       "99222     6846\n",
       "99238     6342\n",
       "99255     5512\n",
       "99253     5377\n",
       "99292     3864\n",
       "36556     3490\n",
       "99252     2194\n",
       "90935     1846\n",
       "33508     1763\n",
       "33533     1719\n",
       "36620     1597\n",
       "99221     1574\n",
       "31624     1317\n",
       "31645     1275\n",
       "31622     1005\n",
       "76937      918\n",
       "31600      898\n",
       "33405      808\n",
       "31500      786\n",
       "76942      784\n",
       "99251      771\n",
       "90945      688\n",
       "33518      663\n",
       "43246      582\n",
       "99262      575\n",
       "33519      573\n",
       "99356      533\n",
       "99261      466\n",
       "62270      408\n",
       "69990      397\n",
       "31646      392\n",
       "90937      381\n",
       "90801      365\n",
       "93503      331\n",
       "32002      274\n",
       "32551      273\n",
       "99263      268\n",
       "33517      259\n",
       "36489      236\n",
       "61510      226\n",
       "49080      224\n",
       "Name: CPT_CD, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "note_cpt['CPT_CD'].value_counts().head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-dealing",
   "metadata": {},
   "source": [
    "# Filter the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "pursuant-thumbnail",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Counts for the filtered data:\n",
      "\n",
      " 94003    1359\n",
      "94002     672\n",
      "99291     553\n",
      "99254     184\n",
      "99253     159\n",
      "99222     131\n",
      "99223     123\n",
      "99232     108\n",
      "99255     105\n",
      "99233      98\n",
      "54150      84\n",
      "99238      69\n",
      "99252      55\n",
      "99231      50\n",
      "33405      48\n",
      "99221      43\n",
      "99251      24\n",
      "33427      21\n",
      "99239      20\n",
      "36556      19\n",
      "33430       9\n",
      "33641       8\n",
      "99220       7\n",
      "99235       7\n",
      "99236       7\n",
      "Name: CPT_CD, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def filter_df(combined_df, threshold):\n",
    "\n",
    "    # Print value counts original\n",
    "    print('Value Counts for the original data:\\n\\n', combined_df['CPT_CD'].value_counts().head(25))\n",
    "\n",
    "    # Filter based on count limit\n",
    "    df = combined_df['CPT_CD'].value_counts()\n",
    "    filtered_ls = list((df[df >= threshold]).index.values)\n",
    "    filtered_df = combined_df[combined_df['CPT_CD'].isin(filtered_ls)]\n",
    "    \n",
    "    # Print value counts filtered\n",
    "    print('Value Counts for the filtered data:\\n\\n', filtered_df['CPT_CD'].value_counts().head(25))\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "# Find Counts of CPT Codes per Patient Encounter and filter df #####\n",
    "def cpt_count_filter(df, og_df, limit):\n",
    "\n",
    "    og_df = og_df.groupby('HADM_ID')['CPT_CD'].count()\n",
    "    filtered_encntrs = og_df[og_df <= limit]\n",
    "    final_df = df.merge(filtered_encntrs, on='HADM_ID')\n",
    "    final_df.drop('CPT_CD_y', axis=1, inplace=True)\n",
    "    final_df.columns = ['SUBJECT_ID', 'HADM_ID', 'TEXT', 'CPT_CD']\n",
    "    \n",
    "    print('Value Counts for the filtered data:\\n\\n', final_df['CPT_CD'].value_counts().head(25))\n",
    "\n",
    "    return final_df\n",
    "\n",
    "filtered_df = cpt_count_filter(note_cpt, note_cpt, 1)\n",
    "# filtered_df = filter_df(filtered_df, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-september",
   "metadata": {},
   "source": [
    "# Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "unable-minimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(text_series):\n",
    "    \n",
    "    # Replace \\n \n",
    "    text_series = text_series.str.replace('\\\\n',' ', regex=True)    \n",
    "\n",
    "    # Remove dates and locations\n",
    "    text_series = text_series.str.replace('\\[\\*\\*(.*?)\\*\\*\\]', ' ', regex=True)\n",
    "    \n",
    "    # Remove topics\n",
    "    data = text_series.str.split('([A-Z\\s]+:)')\n",
    "    for row_num, value in enumerate(data):\n",
    "        text_chunks = [x.strip().replace(':','').replace('\\n', '') for x in value]\n",
    "        for i, x in enumerate(text_chunks):\n",
    "            if 'MEDICATION' in x or 'SOCIAL HISTORY' in x or 'FAMILY HISTORY' in x:\n",
    "                text_chunks[i] = ' '\n",
    "                try:\n",
    "                    text_chunks[i + 1] = ' '\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "        text_series.iloc[row_num] = ' '.join(text_chunks)\n",
    "    \n",
    "    # Replace punctuation\n",
    "    text_series = text_series.str.replace('[' + string.punctuation + ']', ' ', regex=True)\n",
    "    \n",
    "    # Convert to lowercase \n",
    "    text_series = text_series.str.lower()\n",
    "    \n",
    "    # Remove all digits\n",
    "    text_series = text_series.str.replace('\\d',' ', regex=True)\n",
    "    \n",
    "    # Replace plurals, endings with ing, endings with ed, endings with ly\n",
    "#     text_series = text_series.str.replace('s(?=\\s)', ' ', regex=True)\n",
    "#     text_series = text_series.str.replace('ing(?=\\s)', ' ', regex=True)\n",
    "#     text_series = text_series.str.replace('ed(?=\\s)', ' ', regex=True)\n",
    "#     text_series = text_series.str.replace('ly(?=\\s)', ' ', regex=True)\n",
    "    \n",
    "    return text_series\n",
    "\n",
    "# Update Text Column -----\n",
    "filtered_df.loc[:, 'TEXT'] = clean_data(filtered_df['TEXT']).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-removal",
   "metadata": {},
   "source": [
    "# Balance the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "quantitative-catalog",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample_df(filtered_df):\n",
    "    \n",
    "    # Check counts\n",
    "    df_cts = filtered_df['CPT_CD'].value_counts()\n",
    "\n",
    "    # Remove CPT with largest count\n",
    "    df = list(df_cts.index.values)\n",
    "    most_freq_cpt = df[0]\n",
    "    df.remove(most_freq_cpt)\n",
    "\n",
    "    # Resample\n",
    "    minority_df = []\n",
    "    for i in df:\n",
    "        test_resampled = resample(filtered_df[filtered_df['CPT_CD'] == i], replace=True, n_samples=max(df_cts), random_state=123)\n",
    "        minority_df.append(test_resampled)\n",
    "    \n",
    "    # Add back largest group and create final dataframe\n",
    "    minority_df.append(filtered_df[filtered_df['CPT_CD'] == most_freq_cpt])\n",
    "    new_df = pd.concat(minority_df)\n",
    "    new_df['CPT_CD'] = new_df['CPT_CD']\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "filtered_df = oversample_df(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-steering",
   "metadata": {},
   "source": [
    "# Check for Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "altered-lucas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63276    1359\n",
       "21627    1359\n",
       "33877    1359\n",
       "99253    1359\n",
       "32602    1359\n",
       "         ... \n",
       "33427    1359\n",
       "58720    1359\n",
       "99291    1359\n",
       "33533    1359\n",
       "48140    1359\n",
       "Name: CPT_CD, Length: 134, dtype: int64"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df['CPT_CD'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-mixer",
   "metadata": {},
   "source": [
    "# Label Encode the Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "cooked-cloud",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "filtered_df['CPT_CD'] = le.fit_transform(filtered_df['CPT_CD'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-treatment",
   "metadata": {},
   "source": [
    "# Check the CPT code counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "environmental-burner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33416    1359\n",
       "62140    1359\n",
       "44850    1359\n",
       "61697    1359\n",
       "99261    1359\n",
       "         ... \n",
       "61154    1359\n",
       "99231    1359\n",
       "99233    1359\n",
       "99253    1359\n",
       "58720    1359\n",
       "Name: CPT_CD, Length: 134, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df['CPT_CD'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "entire-puppy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99291    25967\n",
       "99232    23987\n",
       "99233    22791\n",
       "94003    16395\n",
       "99231    12441\n",
       "94002    11130\n",
       "99223     9271\n",
       "99239     8775\n",
       "99254     7896\n",
       "99222     6846\n",
       "99238     6342\n",
       "99255     5512\n",
       "99253     5377\n",
       "99292     3864\n",
       "36556     3490\n",
       "99252     2194\n",
       "90935     1846\n",
       "33508     1763\n",
       "33533     1719\n",
       "36620     1597\n",
       "99221     1574\n",
       "31624     1317\n",
       "31645     1275\n",
       "31622     1005\n",
       "76937      918\n",
       "31600      898\n",
       "33405      808\n",
       "31500      786\n",
       "76942      784\n",
       "99251      771\n",
       "90945      688\n",
       "33518      663\n",
       "43246      582\n",
       "99262      575\n",
       "33519      573\n",
       "99356      533\n",
       "99261      466\n",
       "62270      408\n",
       "69990      397\n",
       "31646      392\n",
       "90937      381\n",
       "90801      365\n",
       "93503      331\n",
       "32002      274\n",
       "32551      273\n",
       "99263      268\n",
       "33517      259\n",
       "36489      236\n",
       "61510      226\n",
       "49080      224\n",
       "Name: CPT_CD, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "note_cpt['CPT_CD'].value_counts().head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-devil",
   "metadata": {},
   "source": [
    "# Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "extensive-characterization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List stop words\n",
    "my_stop_words = list(set(stopwords.words('english'))) \\\n",
    "                + ['admission', 'date', 'sex'] \\\n",
    "                + ['needed', 'every', 'seen', 'weeks', 'please', 'ml', 'unit', 'small', 'year', 'old', 'cm', 'non', 'mm', 'however']\n",
    "                # Got the above from my top 100 most predictive words that I wanted to remove\n",
    "\n",
    "# Split the data so number of CPT Codes per record = 1\n",
    "X_train, X_test, y_train, y_test, index_train, index_test = train_test_split(filtered_df['TEXT'].values, filtered_df['CPT_CD'], range(len(filtered_df['CPT_CD'])), test_size = .1, random_state = 42, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-comment",
   "metadata": {},
   "source": [
    "# Tokenize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "determined-waters",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=my_stop_words)\n",
    "\n",
    "# Transform the training data\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-grenada",
   "metadata": {},
   "source": [
    "# Run Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cultural-india",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Naive Bayes model\n",
    "nb_classifier = MultinomialNB(alpha=.7)\n",
    "\n",
    "# Fit and check accuracy\n",
    "nb_classifier.fit(tfidf_train, y_train)\n",
    "pred = nb_classifier.predict(tfidf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-detective",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "forty-treaty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9657349953324913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nChecks on counts of CPT code per encounter\\n-----------------------------------------\\nTest size: .1\\nRandom Number: 42\\n# of records per CPT: 200\\nCategory/Categories: Discharge Summary\\n\\nNo constraints on CPT codes per encounter: 0.5082697201017812\\nOne CPT code per encounter: 0.5510543263737405\\nThree CPT codes or less per encounter: 0.52065226388544\\n\\nResults: Looks like the accuracy is improved quite a bit when using just one CPT per encounter. The downside is less data\\n-----------------------------------------\\n\\n#####\\n\\nChecks on using all notes vs. only the discharge summary section\\n-----------------------------------------\\nTest size: .1\\nRandom Number: 42\\n# of records per CPT: 200\\nNumber of CPT's per record: unrestricted\\n\\nDischarge Summary: .50\\nAll notes: 0.48813608819449517\\n\\nResults: Using all notes lead to a decreased accuracy\\n-----------------------------------------\\n\\n#####\\n\\nUsing ['Consult','Discharge summary','General', 'Nursing', 'Nursing/other', 'Physician ','Rehab Services','Respiratory ']\\ncategories instead of just discharge summary\\n-----------------------------------------\\nTest size: .1\\nRandom Number: 42\\n# of records per CPT: 200\\nNumber of CPT's per record: 1\\n\\nDischarge Summary: .799\\nSelected Categories: 0.7163814180929096\\n\\nResults: Using more notes decreased the score\\n----------------------------------------\\n\\n##### \\n\\nWhat effect does decreasing the note sample size have on accuracy?\\n----------------------------------------\\nTest size: .1\\nRandom Number: 42\\n# of records per CPT: 50\\nNumber of CPT's per record: 1\\n\\nDischarge Summary w/200 notes per CPT: .799\\nDischarge Summary w/50 notes per CPT: 0.7609038360483448\\nDischarge Summary w/40 notes per CPT: 0.7788505747126436\\nDischarge Summary w/20 notes per CPT: 0.8029423151374371\\nDischarge Summary w/10 notes per CPT: 0.8027961736571008\\nDischarge Summary - no threshold for notes per CPT: 0.9673274394596673\\n\\nResults: It looks like a note restriction is unnecessary\\n----------------------------------------\\n\\n#####\\n\\nDoes balancing the data improve the model's accuracy?\\n----------------------------------------\\nTest size: .1\\nRandom Number: 42\\n# of records per CPT: no-restriction\\nNumber of CPT's per record: 1\\n\\nAccuracy without balancing: 0.344578313253012\\nAccuracy with balancing: 0.9673274394596673\\n\\nResults: It definitely helps\\n\\n#####\\n\\nDoes using label encoding affect accuracy?\\n----------------------------------------\\nTest size: .1\\nRandom Number: 42\\n# of records per CPT: no-restriction\\nNumber of CPT's per record: 1\\n\\nAccuracy without labelencoding: 0.9673274394596673\\nAccuracy with labelencoding: 0.9673274394596673\\n\\nResults: No, but it is still a good idea since they are deprecating the ability to have strings as predictors\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check accuracy\n",
    "print(metrics.accuracy_score(y_test, pred))\n",
    "\n",
    "\"\"\"\n",
    "Checks on counts of CPT code per encounter\n",
    "-----------------------------------------\n",
    "Test size: .1\n",
    "Random Number: 42\n",
    "# of records per CPT: 200\n",
    "Category/Categories: Discharge Summary\n",
    "\n",
    "No constraints on CPT codes per encounter: 0.5082697201017812\n",
    "One CPT code per encounter: 0.5510543263737405\n",
    "Three CPT codes or less per encounter: 0.52065226388544\n",
    "\n",
    "Results: Looks like the accuracy is improved quite a bit when using just one CPT per encounter. The downside is less data\n",
    "-----------------------------------------\n",
    "\n",
    "#####\n",
    "\n",
    "Checks on using all notes vs. only the discharge summary section\n",
    "-----------------------------------------\n",
    "Test size: .1\n",
    "Random Number: 42\n",
    "# of records per CPT: 200\n",
    "Number of CPT's per record: unrestricted\n",
    "\n",
    "Discharge Summary: .50\n",
    "All notes: 0.48813608819449517\n",
    "\n",
    "Results: Using all notes lead to a decreased accuracy\n",
    "-----------------------------------------\n",
    "\n",
    "#####\n",
    "\n",
    "Using ['Consult','Discharge summary','General', 'Nursing', 'Nursing/other', 'Physician ','Rehab Services','Respiratory ']\n",
    "categories instead of just discharge summary\n",
    "-----------------------------------------\n",
    "Test size: .1\n",
    "Random Number: 42\n",
    "# of records per CPT: 200\n",
    "Number of CPT's per record: 1\n",
    "\n",
    "Discharge Summary: .799\n",
    "Selected Categories: 0.7163814180929096\n",
    "\n",
    "Results: Using more notes decreased the score\n",
    "----------------------------------------\n",
    "\n",
    "##### \n",
    "\n",
    "What effect does decreasing the note sample size have on accuracy?\n",
    "----------------------------------------\n",
    "Test size: .1\n",
    "Random Number: 42\n",
    "# of records per CPT: 50\n",
    "Number of CPT's per record: 1\n",
    "\n",
    "Discharge Summary w/200 notes per CPT: .799\n",
    "Discharge Summary w/50 notes per CPT: 0.7609038360483448\n",
    "Discharge Summary w/40 notes per CPT: 0.7788505747126436\n",
    "Discharge Summary w/20 notes per CPT: 0.8029423151374371\n",
    "Discharge Summary w/10 notes per CPT: 0.8027961736571008\n",
    "Discharge Summary - no threshold for notes per CPT: 0.9673274394596673\n",
    "\n",
    "Results: It looks like a note restriction is unnecessary\n",
    "----------------------------------------\n",
    "\n",
    "#####\n",
    "\n",
    "Does balancing the data improve the model's accuracy?\n",
    "----------------------------------------\n",
    "Test size: .1\n",
    "Random Number: 42\n",
    "# of records per CPT: no-restriction\n",
    "Number of CPT's per record: 1\n",
    "\n",
    "Accuracy without balancing: 0.344578313253012\n",
    "Accuracy with balancing: 0.9673274394596673\n",
    "\n",
    "Results: It definitely helps\n",
    "\n",
    "#####\n",
    "\n",
    "Does using label encoding affect accuracy?\n",
    "----------------------------------------\n",
    "Test size: .1\n",
    "Random Number: 42\n",
    "# of records per CPT: no-restriction\n",
    "Number of CPT's per record: 1\n",
    "\n",
    "Accuracy without labelencoding: 0.9673274394596673\n",
    "Accuracy with labelencoding: 0.9673274394596673\n",
    "\n",
    "Results: No, but it is still a good idea since they are deprecating the ability to have strings as predictors\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-kenya",
   "metadata": {},
   "source": [
    "# Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "useful-strand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       01996       1.00      1.00      1.00       140\n",
      "       19260       1.00      1.00      1.00       122\n",
      "       19303       0.97      1.00      0.98       121\n",
      "       21627       1.00      1.00      1.00       147\n",
      "       24505       1.00      1.00      1.00       130\n",
      "       27033       1.00      1.00      1.00       123\n",
      "       27130       0.96      1.00      0.98       154\n",
      "       27226       1.00      1.00      1.00       158\n",
      "       27228       1.00      1.00      1.00       153\n",
      "       27236       1.00      1.00      1.00       146\n",
      "       27245       1.00      1.00      1.00       130\n",
      "       27447       1.00      1.00      1.00       135\n",
      "       27506       1.00      1.00      1.00       136\n",
      "       27511       1.00      1.00      1.00       139\n",
      "       27814       1.00      1.00      1.00       126\n",
      "       27880       1.00      1.00      1.00       114\n",
      "       31500       1.00      1.00      1.00       131\n",
      "       31622       0.99      1.00      0.99       140\n",
      "       31624       1.00      1.00      1.00       132\n",
      "       31625       1.00      1.00      1.00       138\n",
      "       31630       1.00      1.00      1.00       164\n",
      "       31635       1.00      1.00      1.00       130\n",
      "       31641       1.00      1.00      1.00       148\n",
      "       31645       1.00      1.00      1.00       119\n",
      "       32500       1.00      1.00      1.00       127\n",
      "       32551       0.56      1.00      0.72       110\n",
      "       32602       1.00      1.00      1.00       153\n",
      "       32650       1.00      1.00      1.00       114\n",
      "       32652       1.00      1.00      1.00       130\n",
      "       32654       1.00      1.00      1.00       142\n",
      "       32657       1.00      1.00      1.00       128\n",
      "       32663       1.00      1.00      1.00       139\n",
      "       33020       1.00      1.00      1.00       145\n",
      "       33025       1.00      1.00      1.00       154\n",
      "       33120       1.00      1.00      1.00       148\n",
      "       33256       1.00      1.00      1.00       157\n",
      "       33265       1.00      1.00      1.00       129\n",
      "       33405       0.69      1.00      0.82       131\n",
      "       33411       1.00      1.00      1.00       152\n",
      "       33416       1.00      1.00      1.00       123\n",
      "       33426       1.00      1.00      1.00       125\n",
      "       33427       0.87      1.00      0.93       110\n",
      "       33430       0.94      1.00      0.97       124\n",
      "       33533       0.98      1.00      0.99       130\n",
      "       33641       0.97      1.00      0.99       144\n",
      "       33863       1.00      1.00      1.00       142\n",
      "       33864       1.00      1.00      1.00       126\n",
      "       33875       1.00      1.00      1.00       130\n",
      "       33877       1.00      1.00      1.00       113\n",
      "       34201       1.00      1.00      1.00       142\n",
      "       35081       1.00      1.00      1.00       136\n",
      "       35082       1.00      1.00      1.00       140\n",
      "       35091       0.99      1.00      1.00       143\n",
      "       35216       1.00      1.00      1.00       129\n",
      "       35221       1.00      1.00      1.00       134\n",
      "       35301       1.00      1.00      1.00       140\n",
      "       35656       1.00      1.00      1.00       125\n",
      "       35666       1.00      1.00      1.00       146\n",
      "       36489       1.00      1.00      1.00       140\n",
      "       36556       0.94      1.00      0.97       144\n",
      "       36620       1.00      1.00      1.00       126\n",
      "       37215       1.00      0.46      0.63       157\n",
      "       37799       1.00      1.00      1.00       144\n",
      "       39520       1.00      1.00      1.00       148\n",
      "       43107       1.00      1.00      1.00       132\n",
      "       43112       0.99      1.00      1.00       149\n",
      "       43118       1.00      1.00      1.00       137\n",
      "       43246       1.00      1.00      1.00       129\n",
      "       43632       1.00      1.00      1.00       136\n",
      "       43644       0.99      1.00      0.99       137\n",
      "       44150       1.00      1.00      1.00       141\n",
      "       44160       1.00      1.00      1.00       164\n",
      "       44850       1.00      1.00      1.00       128\n",
      "       47120       1.00      1.00      1.00       148\n",
      "       47130       1.00      1.00      1.00       142\n",
      "       47420       1.00      1.00      1.00       128\n",
      "       47562       1.00      1.00      1.00       157\n",
      "       47600       1.00      1.00      1.00       156\n",
      "       47780       1.00      1.00      1.00       146\n",
      "       48140       1.00      1.00      1.00       129\n",
      "       49000       1.00      1.00      1.00       138\n",
      "       49080       1.00      1.00      1.00       144\n",
      "       49521       1.00      1.00      1.00       136\n",
      "       54150       0.93      1.00      0.97       140\n",
      "       56620       1.00      1.00      1.00       120\n",
      "       57270       1.00      1.00      1.00       138\n",
      "       58720       1.00      1.00      1.00       140\n",
      "       58952       0.99      1.00      1.00       145\n",
      "       60522       1.00      1.00      1.00       139\n",
      "       60600       1.00      1.00      1.00       143\n",
      "       61154       0.99      1.00      1.00       140\n",
      "       61312       0.87      1.00      0.93       140\n",
      "       61510       1.00      1.00      1.00       116\n",
      "       61697       1.00      1.00      1.00       135\n",
      "       62140       1.00      1.00      1.00       130\n",
      "       62141       1.00      1.00      1.00       127\n",
      "       62223       1.00      1.00      1.00       116\n",
      "       62270       1.00      1.00      1.00       137\n",
      "       63276       1.00      1.00      1.00       115\n",
      "       63280       1.00      1.00      1.00       146\n",
      "       90801       1.00      1.00      1.00       121\n",
      "       90935       1.00      1.00      1.00       124\n",
      "       90945       1.00      1.00      1.00       148\n",
      "       92950       1.00      1.00      1.00       127\n",
      "       92960       1.00      1.00      1.00       124\n",
      "       93280       1.00      1.00      1.00       147\n",
      "       93731       1.00      1.00      1.00       132\n",
      "       93743       1.00      1.00      1.00       154\n",
      "       94002       0.49      0.57      0.53       147\n",
      "       94003       0.68      0.37      0.48       141\n",
      "       99024       0.99      1.00      0.99       147\n",
      "       99219       1.00      1.00      1.00       135\n",
      "       99220       1.00      1.00      1.00       129\n",
      "       99221       0.95      0.93      0.94       121\n",
      "       99222       0.79      0.75      0.77       124\n",
      "       99223       0.91      0.70      0.79       132\n",
      "       99231       0.92      0.78      0.84       126\n",
      "       99232       0.71      0.69      0.70       118\n",
      "       99233       0.99      0.81      0.89       119\n",
      "       99234       1.00      1.00      1.00       144\n",
      "       99235       1.00      1.00      1.00       147\n",
      "       99236       1.00      1.00      1.00       148\n",
      "       99238       0.61      1.00      0.76       141\n",
      "       99239       0.98      1.00      0.99       119\n",
      "       99251       0.97      0.92      0.95       132\n",
      "       99252       0.96      0.85      0.90       154\n",
      "       99253       0.92      0.68      0.78       130\n",
      "       99254       0.90      0.67      0.77       141\n",
      "       99255       0.63      0.77      0.69       121\n",
      "       99261       1.00      1.00      1.00       132\n",
      "       99262       1.00      1.00      1.00       138\n",
      "       99263       1.00      1.00      1.00       134\n",
      "       99291       0.79      0.48      0.60       136\n",
      "       99356       1.00      1.00      1.00       138\n",
      "\n",
      "    accuracy                           0.97     18211\n",
      "   macro avg       0.97      0.97      0.96     18211\n",
      "weighted avg       0.97      0.97      0.96     18211\n",
      "\n",
      "Training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       01996       1.00      1.00      1.00      1219\n",
      "       19260       1.00      1.00      1.00      1237\n",
      "       19303       0.97      1.00      0.98      1238\n",
      "       21627       1.00      1.00      1.00      1212\n",
      "       24505       1.00      1.00      1.00      1229\n",
      "       27033       1.00      1.00      1.00      1236\n",
      "       27130       0.99      1.00      0.99      1205\n",
      "       27226       1.00      1.00      1.00      1201\n",
      "       27228       1.00      1.00      1.00      1206\n",
      "       27236       1.00      1.00      1.00      1213\n",
      "       27245       1.00      1.00      1.00      1229\n",
      "       27447       1.00      1.00      1.00      1224\n",
      "       27506       1.00      1.00      1.00      1223\n",
      "       27511       1.00      1.00      1.00      1220\n",
      "       27814       1.00      1.00      1.00      1233\n",
      "       27880       1.00      1.00      1.00      1245\n",
      "       31500       1.00      1.00      1.00      1228\n",
      "       31622       0.99      1.00      0.99      1219\n",
      "       31624       1.00      1.00      1.00      1227\n",
      "       31625       1.00      1.00      1.00      1221\n",
      "       31630       1.00      1.00      1.00      1195\n",
      "       31635       1.00      1.00      1.00      1229\n",
      "       31641       1.00      1.00      1.00      1211\n",
      "       31645       1.00      1.00      1.00      1240\n",
      "       32500       1.00      1.00      1.00      1232\n",
      "       32551       0.69      1.00      0.82      1249\n",
      "       32602       1.00      1.00      1.00      1206\n",
      "       32650       1.00      1.00      1.00      1245\n",
      "       32652       1.00      1.00      1.00      1229\n",
      "       32654       1.00      1.00      1.00      1217\n",
      "       32657       1.00      1.00      1.00      1231\n",
      "       32663       1.00      1.00      1.00      1220\n",
      "       33020       1.00      1.00      1.00      1214\n",
      "       33025       1.00      1.00      1.00      1205\n",
      "       33120       1.00      1.00      1.00      1211\n",
      "       33256       1.00      1.00      1.00      1202\n",
      "       33265       0.99      1.00      1.00      1230\n",
      "       33405       0.68      1.00      0.81      1228\n",
      "       33411       1.00      1.00      1.00      1207\n",
      "       33416       1.00      1.00      1.00      1236\n",
      "       33426       1.00      1.00      1.00      1234\n",
      "       33427       0.92      1.00      0.96      1249\n",
      "       33430       0.92      1.00      0.96      1235\n",
      "       33533       0.99      1.00      1.00      1229\n",
      "       33641       0.98      1.00      0.99      1215\n",
      "       33863       1.00      1.00      1.00      1217\n",
      "       33864       1.00      1.00      1.00      1233\n",
      "       33875       1.00      1.00      1.00      1229\n",
      "       33877       1.00      1.00      1.00      1246\n",
      "       34201       1.00      1.00      1.00      1217\n",
      "       35081       0.99      1.00      1.00      1223\n",
      "       35082       1.00      1.00      1.00      1219\n",
      "       35091       1.00      1.00      1.00      1216\n",
      "       35216       1.00      1.00      1.00      1230\n",
      "       35221       1.00      1.00      1.00      1225\n",
      "       35301       1.00      1.00      1.00      1219\n",
      "       35656       1.00      1.00      1.00      1234\n",
      "       35666       1.00      1.00      1.00      1213\n",
      "       36489       1.00      1.00      1.00      1219\n",
      "       36556       0.92      1.00      0.96      1215\n",
      "       36620       1.00      1.00      1.00      1233\n",
      "       37215       1.00      0.53      0.69      1202\n",
      "       37799       1.00      1.00      1.00      1215\n",
      "       39520       1.00      1.00      1.00      1211\n",
      "       43107       1.00      1.00      1.00      1227\n",
      "       43112       0.97      1.00      0.99      1210\n",
      "       43118       1.00      1.00      1.00      1222\n",
      "       43246       1.00      1.00      1.00      1230\n",
      "       43632       1.00      1.00      1.00      1223\n",
      "       43644       0.99      1.00      1.00      1222\n",
      "       44150       1.00      1.00      1.00      1218\n",
      "       44160       1.00      1.00      1.00      1195\n",
      "       44850       1.00      1.00      1.00      1231\n",
      "       47120       1.00      1.00      1.00      1211\n",
      "       47130       1.00      1.00      1.00      1217\n",
      "       47420       1.00      1.00      1.00      1231\n",
      "       47562       1.00      1.00      1.00      1202\n",
      "       47600       1.00      1.00      1.00      1203\n",
      "       47780       1.00      1.00      1.00      1213\n",
      "       48140       1.00      1.00      1.00      1230\n",
      "       49000       1.00      1.00      1.00      1221\n",
      "       49080       1.00      1.00      1.00      1215\n",
      "       49521       1.00      1.00      1.00      1223\n",
      "       54150       0.97      1.00      0.98      1219\n",
      "       56620       1.00      1.00      1.00      1239\n",
      "       57270       1.00      1.00      1.00      1221\n",
      "       58720       1.00      1.00      1.00      1219\n",
      "       58952       0.99      1.00      1.00      1214\n",
      "       60522       1.00      1.00      1.00      1220\n",
      "       60600       1.00      1.00      1.00      1216\n",
      "       61154       0.97      1.00      0.99      1219\n",
      "       61312       0.87      1.00      0.93      1219\n",
      "       61510       1.00      1.00      1.00      1243\n",
      "       61697       1.00      1.00      1.00      1224\n",
      "       62140       1.00      1.00      1.00      1229\n",
      "       62141       1.00      1.00      1.00      1232\n",
      "       62223       1.00      1.00      1.00      1243\n",
      "       62270       1.00      1.00      1.00      1222\n",
      "       63276       1.00      1.00      1.00      1244\n",
      "       63280       1.00      1.00      1.00      1213\n",
      "       90801       1.00      1.00      1.00      1238\n",
      "       90935       1.00      1.00      1.00      1235\n",
      "       90945       1.00      1.00      1.00      1211\n",
      "       92950       1.00      1.00      1.00      1232\n",
      "       92960       1.00      1.00      1.00      1235\n",
      "       93280       1.00      1.00      1.00      1212\n",
      "       93731       1.00      1.00      1.00      1227\n",
      "       93743       1.00      1.00      1.00      1205\n",
      "       94002       0.50      0.62      0.55      1212\n",
      "       94003       0.81      0.45      0.58      1218\n",
      "       99024       0.99      1.00      0.99      1212\n",
      "       99219       1.00      1.00      1.00      1224\n",
      "       99220       1.00      1.00      1.00      1230\n",
      "       99221       0.98      0.96      0.97      1238\n",
      "       99222       0.86      0.78      0.82      1235\n",
      "       99223       0.95      0.76      0.84      1227\n",
      "       99231       0.97      0.83      0.89      1233\n",
      "       99232       0.75      0.71      0.73      1241\n",
      "       99233       0.97      0.82      0.89      1240\n",
      "       99234       1.00      1.00      1.00      1215\n",
      "       99235       1.00      1.00      1.00      1212\n",
      "       99236       1.00      1.00      1.00      1211\n",
      "       99238       0.59      1.00      0.74      1218\n",
      "       99239       0.99      1.00      0.99      1240\n",
      "       99251       0.97      0.97      0.97      1227\n",
      "       99252       0.97      0.89      0.93      1205\n",
      "       99253       0.93      0.64      0.76      1229\n",
      "       99254       0.93      0.68      0.78      1218\n",
      "       99255       0.76      0.82      0.79      1238\n",
      "       99261       1.00      1.00      1.00      1227\n",
      "       99262       1.00      1.00      1.00      1221\n",
      "       99263       1.00      1.00      1.00      1225\n",
      "       99291       0.86      0.55      0.67      1223\n",
      "       99356       1.00      1.00      1.00      1221\n",
      "\n",
      "    accuracy                           0.97    163895\n",
      "   macro avg       0.97      0.97      0.97    163895\n",
      "weighted avg       0.97      0.97      0.97    163895\n",
      "\n",
      "44160    164\n",
      "31630    164\n",
      "27226    158\n",
      "47562    157\n",
      "33256    157\n",
      "        ... \n",
      "27880    114\n",
      "32650    114\n",
      "33877    113\n",
      "33427    110\n",
      "32551    110\n",
      "Name: CPT_CD, Length: 134, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create classification report taken from here: https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568\n",
    "print('Test')\n",
    "class_labels = nb_classifier.classes_\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "print('Training')\n",
    "pred_x = nb_classifier.predict(tfidf_train)\n",
    "print(classification_report(y_train, pred_x))\n",
    "\n",
    "# Counts by number of CPT values in test\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "similar-senator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.17499999999999\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.percentile([1,2,3,54],97.5))\n",
    "# ?np.percentile\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# resample([1,2,3,54], replace=True, n_samples=4, random_state=123)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is to combine the data into one file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "### READING IN AND MUNGING THE DATA ###\n",
    "\n",
    "read_files = glob.glob('/Users/andreasmartinson/Documents/training/*')\n",
    "read_files.pop(read_files.index(\"/Users/andreasmartinson/Documents/training/p000001.psv\"))\n",
    "\n",
    "# credit for the basic idea for the code below goes to the following post on stackoverflow: \n",
    "# https://stackoverflow.com/questions/2512386/how-to-merge-200-csv-files-in-python\n",
    "\n",
    "result_file=open(\"/Users/andreasmartinson/Documents/training/result_file.psv\",\"w\")\n",
    "# first file:\n",
    "result_file.write('patient no|')\n",
    "result_file.write('hour no|')\n",
    "hr_ct = '1'\n",
    "\n",
    "for line in open(\"/Users/andreasmartinson/Documents/training/p000001.psv\"):\n",
    "    result_file.write(line)\n",
    "    result_file.write('1|')\n",
    "    result_file.write(hr_ct+'|')\n",
    "    hr_ct = int(hr_ct)\n",
    "    hr_ct +=1\n",
    "    hr_ct = str(hr_ct)\n",
    "\n",
    "# now the rest\n",
    "count = '2'\n",
    "\n",
    "for file in read_files:\n",
    "    hr_ct = '1'\n",
    "    f = open(file)\n",
    "    f.__next__() # skip the header\n",
    "    for line in f:\n",
    "         result_file.write(line)\n",
    "         result_file.write(count+'|')\n",
    "         result_file.write(hr_ct+'|')\n",
    "         hr_ct = int(hr_ct)\n",
    "         hr_ct +=1\n",
    "         hr_ct = str(hr_ct)\n",
    "    f.close() # not really needed\n",
    "    count = int(count)\n",
    "    count += 1\n",
    "    count = str(count)\n",
    "\n",
    "f.close()\n",
    "\n",
    "# end credit to stackoverflow source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PROVIDING DATA STATISTICS ###\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv(\"~/GitHub Projects/ML-6015-Project Docs/training/result_file_original.psv\", sep = '|')\n",
    "\n",
    "## Stats by Hour\n",
    "\n",
    "# print('\\nStatistics by Hour\\n')\n",
    "# data_copy = data[['hour no','HR','O2Sat','Temp','SepsisLabel']]\n",
    "# data_grouped = data_copy.groupby('hour no')\n",
    "\n",
    "# data_HR = data_grouped[['HR']]\n",
    "# data_O2Sat = data_grouped[['O2Sat']]\n",
    "# data_Temp = data_grouped[['Temp']]\n",
    "# data_SepsisLabel = data_grouped[['SepsisLabel']]\n",
    "\n",
    "# print(data_HR.describe())\n",
    "# print(data_O2Sat.describe())\n",
    "# print(data_Temp.describe())\n",
    "# print(data_SepsisLabel.describe())\n",
    "\n",
    "# ## Balance of the data\n",
    "\n",
    "# print('\\nBalance of some of the column data\\n')\n",
    "\n",
    "# print('\\n By Sepsis Label\\n')\n",
    "# print(data['SepsisLabel'].value_counts()) \n",
    "\n",
    "# print('\\nBy Patient No\\n')\n",
    "\n",
    "# print(data['patient no'].value_counts())\n",
    "\n",
    "# ## Count of the data available for those who have sepsis\n",
    "\n",
    "# print('\\nCount of Available Data for Hours People were Diagnosed with Sepsis\\n')\n",
    "# data_sepsis = data.loc[data['SepsisLabel'] == 1]\n",
    "# data_sepsis = data_sepsis[['hour no']]\n",
    "# print(data_sepsis.count())\n",
    "\n",
    "# ## Scatterplot of hour and heart rate\n",
    "\n",
    "# # plt.scatter(data[['hour no']], data[['HR']], alpha=0.5)\n",
    "\n",
    "# print('\\nScatterplot #1\\n')\n",
    "# plt.scatter(data[['hour no']], data[['HR']], alpha=0.5)\n",
    "# plt.xlabel('Hour no')\n",
    "# plt.ylabel('Heart Rate')\n",
    "# plt.show()\n",
    "\n",
    "# ## Scatterplot of temperature and sepsis\n",
    "\n",
    "# print('\\nScatterplot #2\\n')\n",
    "# plt.scatter(data[['Temp']], data[['SepsisLabel']], alpha=0.5)\n",
    "# plt.xlabel('Temperature')\n",
    "# plt.ylabel('Sepsis Label')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Statistics as well as Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# \n",
    "data_filtered = data[['HR', 'hour no', 'SepsisLabel','Lactate','pH','Bilirubin_total','Temp','Age']].dropna()\n",
    "# data_filtered = data_filtered[0:1000]\n",
    "data_pos_sep = data_filtered.loc[data_filtered['SepsisLabel']==1]\n",
    "\n",
    "# States lactate can be indicative: https://labtestsonline.org/tests/lactate\n",
    "# States ph can be indicative: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5997042/\n",
    "\n",
    "# print(data_filtered)\n",
    "\n",
    "\n",
    "#     # Index(['patient no', 'hour no', 'HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP',\n",
    "#     #        'Resp', 'EtCO2', 'BaseExcess', 'HCO3', 'FiO2', 'pH', 'PaCO2', 'SaO2',\n",
    "#     #        'AST', 'BUN', 'Alkalinephos', 'Calcium', 'Chloride', 'Creatinine',\n",
    "#     #        'Bilirubin_direct', 'Glucose', 'Lactate', 'Magnesium', 'Phosphate',\n",
    "#     #        'Potassium', 'Bilirubin_total', 'TroponinI', 'Hct', 'Hgb', 'PTT', 'WBC',\n",
    "#     #        'Fibrinogen', 'Platelets', 'Age', 'Gender', 'Unit1', 'Unit2',\n",
    "#     #        'HospAdmTime', 'ICULOS', 'SepsisLabel'],\n",
    "#     #       dtype='object')\n",
    "\n",
    "# # We are making the assumption that all patients in the dataset eventually got sepsis\n",
    "\n",
    "# # Questions for summary data\n",
    "\n",
    "# # 1 Overall Stats\n",
    "\n",
    "# print(data.shape) # check the shape\n",
    "# print(data.columns) # check the columns\n",
    "# print(data['SepsisLabel'].value_counts()) \n",
    "# print(data.isna().sum())\n",
    "# print(data.dropna().sum()) # There are a lot of na values\n",
    "# print(data_filtered.dropna().sum()) \n",
    "\n",
    "# # 2 Pairplots for the following groups: hour_no, sepsis label, age, HR, platelets\n",
    "\n",
    "    # Pair Plots for selected features\n",
    "\n",
    "# sns.pairplot(data_filtered)\n",
    "\n",
    "# # 3 Distributions\n",
    "\n",
    "    # Distributions for selected features\n",
    "        # Heart Rate Distributions for those\n",
    "# sns.distplot(data_filtered[['HR']].dropna())  \n",
    "# sns.distplot(data_pos_sep[['HR']].dropna())\n",
    "# sns.distplot(data_filtered[['HR']], label=\"HR Before Sepsis Diagnosis\")\n",
    "# sns.distplot(data_pos_sep[['HR']], label=\"HR After Sepsis Diagnosis\")\n",
    "# plt.legend()\n",
    "        # pH Distributions\n",
    "# sns.distplot(data_filtered[['pH']].dropna())  \n",
    "# sns.distplot(data_pos_sep[['pH']].dropna())\n",
    "# sns.distplot(data_filtered[['pH']], label=\"pH Before Sepsis Diagnosis\")\n",
    "# sns.distplot(data_pos_sep[['pH']], label=\"pH After Sepsis Diagnosis\")\n",
    "# plt.legend()\n",
    "        # Lactate Distributions\n",
    "# sns.distplot(data_filtered[['Lactate']].dropna())  \n",
    "# sns.distplot(data_pos_sep[['Lactate']].dropna())\n",
    "# sns.distplot(data_filtered[['Lactate']], label=\"Lactate Before Sepsis Diagnosis\")\n",
    "# sns.distplot(data_pos_sep[['Lactate']], label=\"Lactate After Sepsis Diagnosis\")\n",
    "# plt.legend()\n",
    "        # Temp Distributions\n",
    "# sns.distplot(data_filtered[['Temp']].dropna())  \n",
    "# sns.distplot(data_pos_sep[['Temp']].dropna())\n",
    "# sns.distplot(data_filtered[['Temp']], label=\"Temp Before Sepsis Diagnosis\")\n",
    "# sns.distplot(data_pos_sep[['Temp']], label=\"Temp After Sepsis Diagnosis\")\n",
    "# plt.legend()\n",
    "        # Hour Distribution\n",
    "sns.distplot(data_filtered[['hour no']].dropna())  \n",
    "sns.distplot(data_pos_sep[['hour no']].dropna())\n",
    "sns.distplot(data_filtered[['hour no']], label=\"Hour No Before Sepsis Diagnosis\")\n",
    "sns.distplot(data_pos_sep[['hour no']], label=\"Hour No After Sepsis Diagnosis\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "# ML Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation for Missing Values\n",
    "\n",
    "import impyute as impy\n",
    "data_filtered = data[0:10000]\n",
    "data_imputed = impy.mean(data_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# selecting my data inputs\n",
    "\n",
    "# data_imputed.columns = ['patient no', 'hour no', 'HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP',\n",
    "#            'Resp', 'EtCO2', 'BaseExcess', 'HCO3', 'FiO2', 'pH', 'PaCO2', 'SaO2',\n",
    "#            'AST', 'BUN', 'Alkalinephos', 'Calcium', 'Chloride', 'Creatinine',\n",
    "#            'Bilirubin_direct', 'Glucose', 'Lactate', 'Magnesium', 'Phosphate',\n",
    "#            'Potassium', 'Bilirubin_total', 'TroponinI', 'Hct', 'Hgb', 'PTT', 'WBC',\n",
    "#            'Fibrinogen', 'Platelets', 'Age', 'Gender', 'Unit1', 'Unit2',\n",
    "#            'HospAdmTime', 'ICULOS', 'SepsisLabel']\n",
    "# print(data_imputed)\n",
    "x = data_imputed.iloc[:,0:42]\n",
    "y = data_imputed.iloc[:,-1]\n",
    "print(len(y))\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to rescale the data\n",
    "\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "# x_scaled = scaler.fit_transform(x)\n",
    "# x = pd.DataFrame(x_scaled)\n",
    "x.columns = ['patient no', 'hour no', 'HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP',\n",
    "           'Resp', 'EtCO2', 'BaseExcess', 'HCO3', 'FiO2', 'pH', 'PaCO2', 'SaO2',\n",
    "           'AST', 'BUN', 'Alkalinephos', 'Calcium', 'Chloride', 'Creatinine',\n",
    "           'Bilirubin_direct', 'Glucose', 'Lactate', 'Magnesium', 'Phosphate',\n",
    "           'Potassium', 'Bilirubin_total', 'TroponinI', 'Hct', 'Hgb', 'PTT', 'WBC',\n",
    "           'Fibrinogen', 'Platelets', 'Age', 'Gender', 'Unit1', 'Unit2',\n",
    "           'HospAdmTime', 'ICULOS']\n",
    "x_final = x.drop(['EtCO2','TroponinI'], axis = 1)\n",
    "x_final.isna().sum()\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K Means Clustering (Time Agnostic)\n",
    "\n",
    "# The Algorithm\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_final, y, test_size=0.33, random_state=42)\n",
    "x_train.shape\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = kmeans.predict(x_train)\n",
    "centroids = kmeans.cluster_centers_\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use PCA to be able to graph the points\n",
    "    # There should be 4 columns, 2 for the variables and 2 for the labels\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2) # intialize pca \n",
    "x_train_pca = pca.fit_transform(x_train) # fit and transform data\n",
    "print(x_train_pca)\n",
    "labels_reshape = labels.reshape(-1,1)\n",
    "y_train_array = np.asarray(y_train)\n",
    "y_train_reshape = y_train_array.reshape(-1,1)\n",
    "all_data = np.concatenate((x_train_pca, labels_reshape, y_train_reshape), 1)\n",
    "\n",
    "sns.scatterplot(all_data[:,0],all_data[:,1], hue = all_data[:,3]) # The predicted data\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.set_title(\"Actual Data\")\n",
    "\n",
    "# sns.scatterplot(all_data[:,0],all_data[:,1], hue = all_data[:,3]) # The actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate the algorithm\n",
    "\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "\n",
    "adjusted_rand_score(all_data[:,3],all_data[:,2])\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
